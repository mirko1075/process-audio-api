I'll help you produce comprehensive technical and operational documentation for this Flask project. Let me systematically explore the codebase and then generate the documentation.

Update Todos

Explore codebase structure and key files

Generate docs/architecture.md

Generate docs/deployment_render.md

Generate docs/runbook.md

Generate docs/security-hardening-todo.md

Identify minimal missing information questions
Let me explore the codebase structure first:

Bash List Python files in key directories
IN
find . -type f -name "*.py" | grep -E "(api|services|models|auth|sockets|utils|config)" | head -50

OUT
./.venv/lib/python3.12/site-packages/assemblyai/api.py
./.venv/lib/python3.12/site-packages/cryptography/utils.py
./.venv/lib/python3.12/site-packages/cryptography/hazmat/primitives/asymmetric/utils.py
./.venv/lib/python3.12/site-packages/iniconfig/_parse.py
./.venv/lib/python3.12/site-packages/iniconfig/exceptions.py
./.venv/lib/python3.12/site-packages/iniconfig/_version.py
./.venv/lib/python3.12/site-packages/iniconfig/__init__.py
./.venv/lib/python3.12/site-packages/pandas/tests/resample/test_resample_api.py
./.venv/lib/python3.12/site-packages/pandas/tests/config/__init__.py
./.venv/lib/python3.12/site-packages/pandas/tests/config/test_localization.py
./.venv/lib/python3.12/site-packages/pandas/tests/config/test_config.py
./.venv/lib/python3.12/site-packages/pandas/tests/extension/base/reshaping.py
./.venv/lib/python3.12/site-packages/pandas/tests/interchange/test_utils.py
./.venv/lib/python3.12/site-packages/pandas/tests/window/test_api.py
./.venv/lib/python3.12/site-packages/pandas/tests/generic/test_label_or_level_utils.py
./.venv/lib/python3.12/site-packages/pandas/tests/groupby/test_api.py
./.venv/lib/python3.12/site-packages/pandas/tests/series/test_api.py
./.venv/lib/python3.12/site-packages/pandas/tests/strings/test_api.py
./.venv/lib/python3.12/site-packages/pandas/tests/api/__init__.py
./.venv/lib/python3.12/site-packages/pandas/tests/api/test_types.py
./.venv/lib/python3.12/site-packages/pandas/tests/api/test_api.py
./.venv/lib/python3.12/site-packages/pandas/tests/arrays/categorical/test_api.py
./.venv/lib/python3.12/site-packages/pandas/tests/frame/test_api.py
./.venv/lib/python3.12/site-packages/pandas/tests/tslibs/test_api.py
./.venv/lib/python3.12/site-packages/pandas/tests/internals/test_api.py
./.venv/lib/python3.12/site-packages/pandas/_config/display.py
./.venv/lib/python3.12/site-packages/pandas/_config/__init__.py
./.venv/lib/python3.12/site-packages/pandas/_config/config.py
./.venv/lib/python3.12/site-packages/pandas/_config/localization.py
./.venv/lib/python3.12/site-packages/pandas/_config/dates.py
./.venv/lib/python3.12/site-packages/pandas/tseries/api.py
./.venv/lib/python3.12/site-packages/pandas/api/interchange/__init__.py
./.venv/lib/python3.12/site-packages/pandas/api/typing/__init__.py
./.venv/lib/python3.12/site-packages/pandas/api/indexers/__init__.py
./.venv/lib/python3.12/site-packages/pandas/api/__init__.py
./.venv/lib/python3.12/site-packages/pandas/api/types/__init__.py
./.venv/lib/python3.12/site-packages/pandas/api/extensions/__init__.py
./.venv/lib/python3.12/site-packages/pandas/io/api.py
./.venv/lib/python3.12/site-packages/pandas/core/indexes/api.py
./.venv/lib/python3.12/site-packages/pandas/core/computation/api.py
./.venv/lib/python3.12/site-packages/pandas/core/reshape/api.py
./.venv/lib/python3.12/site-packages/pandas/core/config_init.py
./.venv/lib/python3.12/site-packages/pandas/core/interchange/utils.py
./.venv/lib/python3.12/site-packages/pandas/core/arrays/arrow/_arrow_utils.py
./.venv/lib/python3.12/site-packages/pandas/core/arrays/_utils.py
./.venv/lib/python3.12/site-packages/pandas/core/dtypes/api.py
./.venv/lib/python3.12/site-packages/pandas/core/api.py
./.venv/lib/python3.12/site-packages/pandas/core/indexers/utils.py
./.venv/lib/python3.12/site-packages/pandas/core/sparse/api.py
./.venv/lib/python3.12/site-packages/pandas/core/internals/api.py
Globpattern: "**/*.py"
Found 101 files
Bash List application Python files excluding venv
IN
find . -type f -name "*.py" -not -path "./.venv/*" -not -path "./venv_test/*" | sort

OUT
./api/auth.py
./app.py
./core/__init__.py
./flask_app/__init__.py
./flask_app/api/__init__.py
./flask_app/api/auth.py
./flask_app/api/health.py
./flask_app/api/postprocessing.py
./flask_app/api/protected.py
./flask_app/api/transcription.py
./flask_app/api/translation.py
./flask_app/api/utilities.py
./flask_app/auth/__init__.py
./flask_app/auth/auth0.py
./flask_app/clients/__init__.py
./flask_app/clients/assemblyai.py
./flask_app/clients/deepgram.py
./flask_app/clients/deepseek.py
./flask_app/clients/google.py
./flask_app/clients/openai.py
./flask_app/clients/video_processor.py
./flask_app/services/__init__.py
./flask_app/services/postprocessing.py
./flask_app/services/session_manager.py
./flask_app/services/transcription.py
./flask_app/services/translation.py
./flask_app/services/video_transcription.py
./flask_app/sockets/__init__.py
./flask_app/sockets/audio_stream.py
./flask_app/sockets/audio_stream_auth0.py
./models/__init__.py
./models/user.py
./scripts/init_db.py
./test_endpoints.py
./tests/__init__.py
./tests/test_api_endpoints.py
./tests/test_auth0.py
./tests/test_auth_system.py
./tests/test_clients.py
./tests/test_config_utils.py
./tests/test_deepgram_diarization.py
./tests/test_health.py
./tests/test_video_transcription.py
./tests/test_websocket_language.py
./utils/__init__.py
./utils/auth.py
./utils/config.py
./utils/exceptions.py
./utils/logging.py
./wsgi.py
mcp__gateway__dispatch
IN
{
  "serverId": "code-trm",
  "tool": "trm.read",
  "args": {
    "sid": "29886a52-c50b-4077-9e9b-b1c6016efacd",
    "paths": [
      "flask_app/api/health.py",
      "flask_app/api/transcription.py",
      "flask_app/api/translation.py",
      "flask_app/api/postprocessing.py",
      "flask_app/api/utilities.py",
      "flask_app/api/protected.py",
      "flask_app/api/auth.py",
      "api/auth.py"
    ]
  }
}
OUT
{
"files": {
"flask_app/api/health.py": {
"content": """"Health check API blueprint."""\nfrom flask import Blueprint, jsonify\nimport logging\n\nbp = Blueprint('health', name)\nlogger = logging.getLogger(name)\n\n\n@bp.route('/health', methods=['GET'])\ndef health_check():\n    """Health check endpoint to verify service is running."""\n    logger.info("Health check requested")\n    \n    return jsonify({\n        "status": "healthy",\n        "service": "Audio Transcription API",\n        "version": "1.0.0"\n    })\n\n\n@bp.route('/', methods=['GET'])\ndef root():\n    """Root endpoint with API information."""\n    return jsonify({\n        "service": "Audio Transcription API",\n        "version": "1.0.0",\n        "status": "running",\n        "endpoints": {\n            "health": "/health",\n            "transcription": {\n                "deepgram": "/transcriptions/deepgram",\n                "whisper": "/transcriptions/whisper",\n                "assemblyai": "/transcriptions/assemblyai"\n            },\n            "translation": {\n                "openai": "/translations/openai",\n                "google": "/translations/google"\n            },\n            "postprocessing": {\n                "sentiment": "/sentiment",\n                "documents": "/documents/{format}",\n                "reports": "/reports/{format}"\n            }\n        }\n    })",
"metadata": {
"lineCount": 45,
"sizeBytes": 1292,
"lastModified": "2025-10-15T22:46:17.779Z"
}
},
"flask_app/api/transcription.py": {
"content": """"Transcription API blueprint - Flask best practices style."""\nimport logging\nfrom flask import Blueprint, request, jsonify, current_app, g\nfrom werkzeug.exceptions import BadRequest\n\nfrom flask_app.services.transcription import DeepgramService, WhisperService, AssemblyAIService\nfrom utils.auth import require_any_auth, log_usage\nfrom utils.exceptions import TranscriptionError\n\n\nbp = Blueprint('transcription', name)\nlogger = logging.getLogger(name)\n\n\n@bp.route('/deepgram', methods=['POST'])\n@require_any_auth\ndef deepgram_transcription():\n    """Transcribe audio using Deepgram Nova-2 model with enhanced options.\n    \n    Accepts multipart/form-data with:\n    - audio: Audio file (required)\n    - language: Language code (optional, default: 'en')\n    - model: Deepgram model (optional, default: 'nova-2')\n    - diarize: Enable speaker diarization (optional, default: 'false')\n    - punctuate: Enable smart punctuation (optional, default: 'true')\n    - paragraphs: Enable paragraph detection (optional, default: 'false')\n    """\n    logger.info(f"Deepgram transcription request from user {g.current_user.id} via {g.auth_method}")\n    \n    # Validate audio file\n    if 'audio' not in request.files:\n        raise BadRequest('No audio file provided')\n        \n    audio_file = request.files['audio']\n    if audio_file.filename == '':\n        raise BadRequest('No audio file selected')\n    \n    # Get optional parameters\n    language = request.form.get('language', 'en')\n    model = request.form.get('model', 'nova-2')\n    diarize = request.form.get('diarize', 'false').lower() == 'true'\n    punctuate = request.form.get('punctuate', 'true').lower() == 'true'\n    paragraphs = request.form.get('paragraphs', 'false').lower() == 'true'\n    \n    logger.info(f"Processing Deepgram transcription: language={language}, model={model}, diarize={diarize}")\n    \n    try:\n        # Use service to handle transcription with enhanced options\n        service = DeepgramService()\n        result = service.transcribe(\n            audio_file, \n            language=language, \n            model=model,\n            diarize=diarize,\n            punctuate=punctuate,\n            paragraphs=paragraphs\n        )\n        \n        # Add processing metadata\n        processing_info = {\n            "service": "deepgram",\n            "model_used": model,\n            "language_requested": language,\n            "diarization_enabled": diarize,\n            "paragraphs_enabled": paragraphs\n        }\n        \n        # Merge processing info with result\n        final_result = {**result, "processing_info": processing_info}\n        \n        logger.info(f"Deepgram transcription completed successfully (speakers: {result.get('diarization', {}).get('speakers_detected', 'N/A')})")\n        return jsonify(final_result)\n        \n    except TranscriptionError as e:\n        logger.error(f"Deepgram transcription error: {e}")\n        return jsonify({'error': str(e)}), 400\n    except Exception as e:\n        logger.error(f"Unexpected error in Deepgram transcription: {e}")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n@bp.route('/whisper', methods=['POST'])\n@require_any_auth\ndef whisper_transcription():\n    """Transcribe audio using OpenAI Whisper with automatic chunking.\n    \n    Accepts multipart/form-data with:\n    - audio: Audio file\n    - language: Language code (optional, default: 'en')\n    \n    Automatically handles large files by chunking them into smaller segments.\n    """\n    logger.info("Whisper transcription request received")\n    \n    # Validate audio file\n    if 'audio' not in request.files:\n        raise BadRequest('No audio file provided')\n        \n    audio_file = request.files['audio']\n    if audio_file.filename == '':\n        raise BadRequest('No audio file selected')\n    \n    # Get optional parameters\n    language = request.form.get('language', 'en')\n    \n    logger.info(f"Processing Whisper transcription: language={language}")\n    \n    try:\n        # Use service to handle transcription with automatic chunking\n        service = WhisperService()\n        result = service.transcribe(audio_file, language=language)\n        \n        logger.info("Whisper transcription completed successfully")\n        \n        # Log chunking info if applicable\n        if result.get('processing_method') == 'chunked':\n            logger.info(f"Processed {result.get('total_chunks')} chunks")\n        \n        return jsonify(result)\n        \n    except TranscriptionError as e:\n        logger.error(f"Whisper transcription error: {e}")\n        return jsonify({'error': str(e)}), 400\n    except Exception as e:\n        logger.error(f"Unexpected error in Whisper transcription: {e}")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n@bp.route('/assemblyai', methods=['POST'])\n@require_any_auth\ndef assemblyai_transcription():\n    """Transcribe audio using AssemblyAI.\n    \n    Accepts multipart/form-data with:\n    - audio: Audio file\n    - language: Language code (optional, default: 'en')\n    """\n    logger.info("AssemblyAI transcription request received")\n    \n    # Validate audio file\n    if 'audio' not in request.files:\n        raise BadRequest('No audio file provided')\n        \n    audio_file = request.files['audio']\n    if audio_file.filename == '':\n        raise BadRequest('No audio file selected')\n    \n    # Get optional parameters\n    language = request.form.get('language', 'en')\n    \n    logger.info(f"Processing AssemblyAI transcription: language={language}")\n    \n    try:\n        # Use service to handle transcription\n        service = AssemblyAIService()\n        result = service.transcribe(audio_file, language=language)\n        \n        logger.info("AssemblyAI transcription completed successfully")\n        return jsonify(result)\n        \n    except TranscriptionError as e:\n        logger.error(f"AssemblyAI transcription error: {e}")\n        return jsonify({'error': str(e)}), 400\n    except Exception as e:\n        logger.error(f"Unexpected error in AssemblyAI transcription: {e}")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n# Error handlers specific to this blueprint\n@bp.errorhandler(413)\ndef file_too_large(error):\n    """Handle file too large errors."""\n    logger.warning("File too large error - this should be handled by chunking")\n    return jsonify({\n        'error': 'File too large. Note: Whisper endpoint automatically handles large files with chunking.'\n    }), 413\n\n\n@bp.route('/transcribe-and-translate', methods=['POST'])\n@require_any_auth\ndef transcribe_and_translate():\n    """Combined transcription and translation endpoint.\n    \n    Accepts multipart/form-data with:\n    - audio: Audio file\n    - translate: Whether to translate (true/false, optional, default: false)\n    - transcript_model: Transcription model ('deepgram', 'whisper', optional, default: 'deepgram')\n    - translation_model: Translation model ('google', 'openai', optional, default: 'google')\n    - language: Source language code (optional, default: 'en')\n    - target_language: Target language code (optional, default: 'en')\n    """\n    logger.info("Combined transcribe and translate request received")\n    \n    # Validate audio file\n    if 'audio' not in request.files:\n        raise BadRequest('No audio file provided')\n        \n    audio_file = request.files['audio']\n    if audio_file.filename == '':\n        raise BadRequest('No audio file selected')\n    \n    # Get parameters\n    translate = request.form.get('translate', 'false').lower() == 'true'\n    transcript_model = request.form.get('transcript_model', 'deepgram')\n    translation_model = request.form.get('translation_model', 'google')\n    language = request.form.get('language', 'en')\n    target_language = request.form.get('target_language', 'en')\n    \n    # Validate translation model\n    if translate and translation_model not in ['google', 'openai']:\n        raise BadRequest('Invalid translation model. Must be "google" or "openai"')\n    \n    logger.info(f"Processing combined request: transcript_model={transcript_model}, translate={translate}")\n    \n    try:\n        # Step 1: Transcribe audio using specified model\n        if transcript_model == 'whisper':\n            service = WhisperService()\n            transcription_result = service.transcribe(audio_file, language=language)\n        elif transcript_model == 'assemblyai':\n            service = AssemblyAIService()\n            transcription_result = service.transcribe(audio_file, language=language)\n        else:  # Default to deepgram\n            service = DeepgramService()\n            transcription_result = service.transcribe(audio_file, language=language)\n        \n        # Extract transcript text\n        transcript = transcription_result.get('transcript', '')\n        formatted_transcript_array = transcription_result.get('formatted_transcript_array', [])\n        \n        # Step 2: Translate if requested\n        translated_text = None\n        if translate and transcript:\n            logger.info(f"Translating transcript using {translation_model}")\n            \n            if translation_model == 'openai':\n                from flask_app.services.translation import OpenAITranslationService\n                translation_service = OpenAITranslationService()\n                translation_result = translation_service.translate(transcript, language, target_language)\n                translated_text = translation_result.get('translated_text')\n            else:  # Default to google\n                from flask_app.services.translation import GoogleTranslationService\n                translation_service = GoogleTranslationService()\n                translation_result = translation_service.translate(transcript, target_language)\n                translated_text = translation_result.get('translated_text')\n        \n        # Prepare response\n        result = {\n            'formatted_transcript_array': formatted_transcript_array,\n            'transcript': transcript,\n            'translated_text': translated_text\n        }\n        \n        logger.info("Combined transcribe and translate completed successfully")\n        return jsonify(result)\n        \n    except TranscriptionError as e:\n        logger.error(f"Transcription error: {e}")\n        return jsonify({'error': str(e)}), 400\n    except Exception as e:\n        logger.error(f"Unexpected error in combined transcribe and translate: {e}")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n@bp.route('/video', methods=['POST'])\n@require_any_auth\ndef video_transcription():\n    """Transcribe video from URL or uploaded file using Whisper.\n    \n    Accepts either:\n    1. JSON with video_url for processing YouTube/web videos\n    2. multipart/form-data with video file upload\n    \n    Optional parameters:\n    - language: Language code (optional, auto-detect if not provided)\n    - model_size: Whisper model size (tiny, base, small, medium, large, default: base)\n    """\n    logger.info("Video transcription request received")\n    \n    try:\n        from flask_app.services.video_transcription import VideoTranscriptionService\n        service = VideoTranscriptionService()\n        \n        # Check if request contains video URL or file upload\n        if request.content_type and 'application/json' in request.content_type:\n            # Process video URL\n            data = request.get_json()\n            if not data or 'video_url' not in data:\n                raise BadRequest('video_url is required for JSON requests')\n            \n            video_url = data['video_url']\n            language = data.get('language')  # None for auto-detect\n            model_size = data.get('model_size', 'base')\n            \n            logger.info(f"Processing video URL: {video_url}, language={language}, model={model_size}")\n            result = service.transcribe_from_url(video_url, language=language, model_size=model_size)\n            \n        elif 'video' in request.files:\n            # Process uploaded video file\n            video_file = request.files['video']\n            if video_file.filename == '':\n                raise BadRequest('No video file selected')\n            \n            language = request.form.get('language')  # None for auto-detect\n            model_size = request.form.get('model_size', 'base')\n            \n            logger.info(f"Processing uploaded video: {video_file.filename}, language={language}, model={model_size}")\n            result = service.transcribe_from_file(video_file, language=language, model_size=model_size)\n            \n        else:\n            raise BadRequest('Either video_url (JSON) or video file (multipart) is required')\n        \n        logger.info("Video transcription completed successfully")\n        return jsonify(result)\n        \n    except BadRequest as e:\n        logger.error(f"Bad request in video transcription: {e.description}")\n        return jsonify({'error': e.description}), 400\n    except TranscriptionError as e:\n        logger.error(f"Video transcription error: {e}")\n        return jsonify({'error': str(e)}), 400\n    except Exception as e:\n        logger.error(f"Unexpected error in video transcription: {e}")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n@bp.errorhandler(BadRequest)\ndef handle_bad_request(error):\n    """Handle bad request errors."""\n    logger.warning(f"Bad request: {error.description}")\n    return jsonify({'error': error.description}), 400",
"metadata": {
"lineCount": 331,
"sizeBytes": 13423,
"lastModified": "2025-12-04T21:15:05.257Z"
}
},
"flask_app/api/translation.py": {
"content": """"Translation API blueprint - Flask best practices style."""\nimport logging\nfrom flask import Blueprint, request, jsonify\nfrom werkzeug.exceptions import BadRequest\n\nfrom flask_app.services.translation import OpenAITranslationService, GoogleTranslationService, DeepSeekTranslationService\nfrom utils.auth import require_api_key\nfrom utils.exceptions import TranslationError\n\n\nbp = Blueprint('translation', name)\nlogger = logging.getLogger(name)\n\n\n@bp.route('/openai', methods=['POST'])\n@require_api_key\ndef openai_translation():\n    """Translate text using OpenAI GPT with automatic text chunking.\n    \n    Accepts JSON with:\n    - text: Text to translate\n    - source_language: Source language code (optional, default: 'auto')\n    - target_language: Target language code (required)\n    \n    Automatically handles long texts by chunking them into smaller segments.\n    """\n    logger.info("OpenAI translation request received")\n    \n    # Validate JSON request\n    if not request.is_json:\n        raise BadRequest('Request must be JSON')\n    \n    data = request.get_json()\n    \n    # Validate required fields\n    if 'text' not in data:\n        raise BadRequest('Missing required field: text')\n    if 'target_language' not in data:\n        raise BadRequest('Missing required field: target_language')\n    \n    text = data['text']\n    source_language = data.get('source_language', 'auto')\n    target_language = data['target_language']\n    \n    # Validate text is not empty\n    if not text.strip():\n        raise BadRequest('Text cannot be empty')\n    \n    logger.info(f"Processing OpenAI translation: {source_language} -> {target_language} (text length: {len(text)})")\n    \n    try:\n        # Use service to handle translation with automatic chunking\n        service = OpenAITranslationService()\n        result = service.translate(text, source_language, target_language)\n        \n        logger.info("OpenAI translation completed successfully")\n        \n        # Log chunking info if applicable\n        if 'chunks_processed' in result:\n            logger.info(f"Processed {result['chunks_processed']} text chunks")\n        \n        return jsonify(result)\n        \n    except TranslationError as e:\n        logger.error(f"OpenAI translation error: {e}")\n        return jsonify({'error': str(e)}), 400\n    except Exception as e:\n        logger.error(f"Unexpected error in OpenAI translation: {e}")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n@bp.route('/google', methods=['POST'])\n@require_api_key\ndef google_translation():\n    """Translate text using Google Cloud Translation API.\n    \n    Accepts JSON with:\n    - text: Text to translate\n    - target_language: Target language code (required)\n    \n    Note: Google Cloud Translation API must be enabled for your project.\n    """\n    logger.info("Google translation request received")\n    \n    # Validate JSON request\n    if not request.is_json:\n        raise BadRequest('Request must be JSON')\n    \n    data = request.get_json()\n    \n    # Validate required fields\n    if 'text' not in data:\n        raise BadRequest('Missing required field: text')\n    if 'target_language' not in data:\n        raise BadRequest('Missing required field: target_language')\n    \n    text = data['text']\n    target_language = data['target_language']\n    \n    # Validate text is not empty\n    if not text.strip():\n        raise BadRequest('Text cannot be empty')\n    \n    logger.info(f"Processing Google translation to {target_language} (text length: {len(text)})")\n    \n    try:\n        # Use service to handle translation\n        service = GoogleTranslationService()\n        result = service.translate(text, target_language)\n        \n        logger.info("Google translation completed successfully")\n        return jsonify(result)\n        \n    except TranslationError as e:\n        logger.error(f"Google translation error: {e}")\n        return jsonify({'error': str(e)}), 400\n    except Exception as e:\n        logger.error(f"Unexpected error in Google translation: {e}")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n@bp.route('/deepseek', methods=['POST'])\n@require_api_key\ndef deepseek_translation():\n    """Translate text using DeepSeek API.\n    \n    Accepts form data with:\n    - text: Text to translate\n    - source_language: Source language code (optional, default: 'auto')\n    - target_language: Target language code (optional, default: 'en')\n    - fileName: File name for external integrations (optional)\n    - duration: Duration for external integrations (optional)\n    - driveId: Drive ID for external integrations (optional)\n    - groupId: Group ID for external integrations (optional)\n    - folderId: Folder ID for external integrations (optional)\n    - fileId: File ID for external integrations (optional)\n    - projectName: Project name for external integrations (optional)\n    - isDev: Development mode flag (optional)\n    - isLocal: Local mode flag (optional)\n    """\n    logger.info("DeepSeek translation request received")\n    \n    # Get required parameters\n    text = request.form.get('text')\n    if not text:\n        raise BadRequest('Missing text parameter')\n    \n    # Get optional parameters\n    source_language = request.form.get('source_language', 'auto')\n    target_language = request.form.get('target_language', 'en')\n    \n    # External integration parameters\n    file_name = request.form.get('fileName')\n    duration = request.form.get('duration')\n    drive_id = request.form.get('driveId')\n    group_id = request.form.get('groupId')\n    folder_id = request.form.get('folderId')\n    file_id = request.form.get('fileId')\n    project_name = request.form.get('projectName')\n    is_dev = request.form.get('isDev', 'false')\n    is_local = request.form.get('isLocal', 'false')\n    \n    logger.info(f"Processing DeepSeek translation: {source_language} -> {target_language}")\n    \n    try:\n        # Use service to handle translation\n        service = DeepSeekTranslationService()\n        result = service.translate(\n            text=text,\n            source_language=source_language,\n            target_language=target_language,\n            # External integration parameters\n            file_name=file_name,\n            duration=duration,\n            drive_id=drive_id,\n            group_id=group_id,\n            folder_id=folder_id,\n            file_id=file_id,\n            project_name=project_name,\n            is_dev=is_dev,\n            is_local=is_local\n        )\n        \n        logger.info("DeepSeek translation completed successfully")\n        return jsonify(result)\n        \n    except TranslationError as e:\n        logger.error(f"DeepSeek translation error: {e}")\n        return jsonify({'error': str(e)}), 400\n    except Exception as e:\n        logger.error(f"Unexpected error in DeepSeek translation: {e}")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n# Error handlers specific to this blueprint\n@bp.errorhandler(BadRequest)\ndef handle_bad_request(error):\n    """Handle bad request errors."""\n    logger.warning(f"Bad request: {error.description}")\n    return jsonify({'error': error.description}), 400",
"metadata": {
"lineCount": 200,
"sizeBytes": 7138,
"lastModified": "2025-10-15T22:46:17.779Z"
}
},
"flask_app/api/postprocessing.py": {
"content": """"Post-processing API blueprint - Flask best practices style."""\nimport logging\nfrom flask import Blueprint, request, jsonify, send_file\nfrom werkzeug.exceptions import BadRequest\n\nfrom flask_app.services.postprocessing import SentimentService, DocumentService\nfrom utils.auth import require_api_key\nfrom utils.exceptions import TranslationError\n\n\nbp = Blueprint('postprocessing', name)\nlogger = logging.getLogger(name)\n\n\n@bp.route('/sentiment', methods=['POST'])\n@require_api_key\ndef sentiment_analysis():\n    """Analyze sentiment of text.\n    \n    Accepts JSON with:\n    - text: Text to analyze\n    """\n    logger.info("Sentiment analysis request received")\n    \n    # Validate JSON request\n    if not request.is_json:\n        raise BadRequest('Request must be JSON')\n    \n    data = request.get_json()\n    \n    # Validate required fields\n    if 'text' not in data:\n        raise BadRequest('Missing required field: text')\n    \n    text = data['text']\n    \n    # Validate text is not empty\n    if not text.strip():\n        raise BadRequest('Text cannot be empty')\n    \n    logger.info(f"Processing sentiment analysis (text length: {len(text)})")\n    \n    try:\n        # Use service to analyze sentiment\n        service = SentimentService()\n        result = service.analyze(text)\n        \n        logger.info("Sentiment analysis completed successfully")\n        return jsonify(result)\n        \n    except Exception as e:\n        logger.error(f"Sentiment analysis error: {e}")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n@bp.route('/documents/<format>', methods=['POST'])\n@require_api_key\ndef generate_document(format):\n    """Generate document in specified format.\n    \n    Accepts JSON with:\n    - text: Text content for document\n    - title: Document title (optional)\n    \n    Supported formats: word, pdf\n    """\n    logger.info(f"Document generation request received: format={format}")\n    \n    # Validate format\n    if format not in ['word', 'pdf']:\n        raise BadRequest('Unsupported format. Use: word, pdf')\n    \n    # Validate JSON request\n    if not request.is_json:\n        raise BadRequest('Request must be JSON')\n    \n    data = request.get_json()\n    \n    # Validate required fields\n    if 'text' not in data:\n        raise BadRequest('Missing required field: text')\n    \n    text = data['text']\n    title = data.get('title', 'Transcription Report')\n    \n    # Validate text is not empty\n    if not text.strip():\n        raise BadRequest('Text cannot be empty')\n    \n    logger.info(f"Generating {format} document: {title}")\n    \n    try:\n        # Use service to generate document\n        service = DocumentService()\n        \n        if format == 'word':\n            file_path = service.generate_word(text, title)\n            mimetype = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'\n            filename = f"{title.replace(' ', '')}.docx"\n        elif format == 'pdf':\n            file_path = service.generate_pdf(text, title)\n            mimetype = 'application/pdf'\n            filename = f"{title.replace(' ', '')}.pdf"\n        \n        logger.info(f"Document generated successfully: {filename}")\n        \n        return send_file(\n            file_path,\n            mimetype=mimetype,\n            as_attachment=True,\n            download_name=filename\n        )\n        \n    except Exception as e:\n        logger.error(f"Document generation error: {e}")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n@bp.route('/reports/<format>', methods=['POST'])\n@require_api_key\ndef generate_report(format):\n    """Generate analysis report in specified format.\n    \n    Accepts JSON with:\n    - transcript: Transcript text\n    - analysis: Analysis data (sentiment, keywords, etc.)\n    - title: Report title (optional)\n    \n    Supported formats: excel\n    """\n    logger.info(f"Report generation request received: format={format}")\n    \n    # Validate format\n    if format not in ['excel']:\n        raise BadRequest('Unsupported format. Use: excel')\n    \n    # Validate JSON request\n    if not request.is_json:\n        raise BadRequest('Request must be JSON')\n    \n    data = request.get_json()\n    \n    # Validate required fields\n    if 'transcript' not in data:\n        raise BadRequest('Missing required field: transcript')\n    \n    transcript = data['transcript']\n    analysis = data.get('analysis', {})\n    title = data.get('title', 'Transcription Analysis Report')\n    \n    # Validate transcript is not empty\n    if not transcript.strip():\n        raise BadRequest('Transcript cannot be empty')\n    \n    logger.info(f"Generating {format} report: {title}")\n    \n    try:\n        # Use service to generate report\n        service = DocumentService()\n        file_path = service.generate_excel_report(transcript, analysis, title)\n        \n        filename = f"{title.replace(' ', '_')}.xlsx"\n        \n        logger.info(f"Report generated successfully: {filename}")\n        \n        return send_file(\n            file_path,\n            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n            as_attachment=True,\n            download_name=filename\n        )\n        \n    except Exception as e:\n        logger.error(f"Report generation error: {e}")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n# Error handlers specific to this blueprint\n@bp.errorhandler(BadRequest)\ndef handle_bad_request(error):\n    """Handle bad request errors."""\n    logger.warning(f"Bad request: {error.description}")\n    return jsonify({'error': error.description}), 400",
"metadata": {
"lineCount": 183,
"sizeBytes": 5590,
"lastModified": "2025-10-15T22:46:17.779Z"
}
},
"flask_app/api/utilities.py": {
"content": """"Utilities API blueprint - Flask best practices style."""\nimport logging\nimport os\nimport tempfile\nimport subprocess\nimport json\nfrom flask import Blueprint, request, jsonify, send_file\nfrom werkzeug.exceptions import BadRequest\nfrom io import BytesIO\nimport datetime\n\nfrom utils.auth import require_api_key\n\n# Optional Google Sheets integration\ntry:\n    import gspread\n    from oauth2client.service_account import ServiceAccountCredentials\n    GOOGLE_SHEETS_AVAILABLE = True\nexcept ImportError:\n    GOOGLE_SHEETS_AVAILABLE = False\n    gspread = None\n    ServiceAccountCredentials = None\n\n\nbp = Blueprint('utilities', name)\nlogger = logging.getLogger(name)\n\n# Google Sheets configuration\nGOOGLE_CREDENTIALS_PATH = os.getenv("GOOGLE_APPLICATION_CREDENTIALS", "google/google-credentials.json")\nRATE_PER_MINUTE = 12 / 60  # €12 per hour = €0.20 per minute\n\n# Initialize Google Sheets client if available\ngoogle_client = None\nif GOOGLE_SHEETS_AVAILABLE:\n    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]\n    try:\n        creds = ServiceAccountCredentials.from_json_keyfile_name(GOOGLE_CREDENTIALS_PATH, scope)\n        google_client = gspread.authorize(creds)\n        logger.info("Google Sheets client initialized successfully")\n    except Exception as e:\n        logger.warning(f"Google Sheets client initialization failed: {e}")\n        google_client = None\nelse:\n    logger.warning("Google Sheets functionality not available - gspread module not installed")\n\n\n@bp.route('/audio-duration', methods=['POST'])\n@require_api_key\ndef get_audio_duration():\n    """Get the duration of an uploaded audio file.\n    \n    Accepts multipart/form-data with:\n    - audio: Audio file\n    \n    Returns:\n    - duration_minutes: Duration in minutes\n    """\n    logger.info("Audio duration request received")\n    \n    # Validate audio file\n    if 'audio' not in request.files:\n        raise BadRequest('No audio file provided')\n        \n    audio_file = request.files['audio']\n    if audio_file.filename == '':\n        raise BadRequest('No audio file selected')\n    \n    try:\n        # Save uploaded audio file temporarily\n        with tempfile.NamedTemporaryFile(delete=False, suffix=".m4a") as temp_file:\n            audio_file.seek(0)  # Reset file pointer\n            temp_file.write(audio_file.read())\n            temp_file_path = temp_file.name\n\n        # Use ffprobe to get the duration\n        result = subprocess.run(\n            [\n                "ffprobe",\n                "-v", "error",\n                "-show_entries", "format=duration",\n                "-of", "json",\n                temp_file_path\n            ],\n            capture_output=True,\n            text=True\n        )\n\n        # Clean up temp file\n        os.remove(temp_file_path)\n\n        if result.returncode != 0:\n            logger.error(f"FFprobe failed: {result.stderr}")\n            return jsonify({"error": "Failed to analyze audio file"}), 400\n\n        duration_data = json.loads(result.stdout)\n        seconds = float(duration_data["format"]["duration"])\n        minutes = round(seconds / 60, 2)\n\n        logger.info(f"Audio duration calculated: {minutes} minutes")\n        return jsonify({\n            "message": "Audio processed successfully",\n            "duration_minutes": minutes\n        })\n\n    except Exception as e:\n        logger.error(f"Error calculating audio duration: {e}")\n        return jsonify({"error": f"Error reading audio duration: {str(e)}"}), 500\n\n\n@bp.route('/log-usage', methods=['POST'])\n@require_api_key\ndef log_audio_usage():\n    """Log audio usage for billing purposes.\n    \n    Accepts form data with:\n    - user_code: User identifier\n    - fileName: Name of the processed file\n    - duration: Duration in minutes\n    \n    Returns:\n    - Billing information\n    """\n    logger.info("Audio usage logging request received")\n    \n    # Get required parameters\n    user_code = request.form.get("user_code")\n    filename = request.form.get("fileName")\n    duration = request.form.get("duration")\n\n    if not user_code or not filename or not duration:\n        raise BadRequest("Missing required parameters: user_code, fileName, or duration")\n\n    try:\n        # Validate duration\n        try:\n            duration_float = float(duration)\n        except ValueError:\n            raise BadRequest(f"Invalid duration value: {duration}")\n\n        # Log the data to Google Sheets\n        result = _log_audio_processing(user_code, filename, duration_float)\n\n        if result is None:\n            logger.warning("Google Sheets logging failed - continuing without logging")\n            # Continue without failing if Google Sheets is not available\n\n        # Calculate costs\n        cost_per_minute = RATE_PER_MINUTE\n        total_cost = duration_float * cost_per_minute\n\n        logger.info(f"Usage logged: {filename} - {duration_float} min - €{total_cost:.2f}")\n        \n        return jsonify({\n            "message": "File processed successfully",\n            "user_code": user_code,\n            "filename": filename,\n            "duration": duration_float,\n            "cost_per_minute": f"{cost_per_minute:.2f}",\n            "total_cost": f"{total_cost:.2f}",\n            "Billed": 'YES'\n        })\n\n    except Exception as e:\n        logger.error(f"Error logging audio usage: {e}")\n        return jsonify({"error": str(e)}), 500\n\n\n@bp.route('/text-file', methods=['POST'])\ndef create_text_file():\n    """Create a text file from input text.\n    \n    Accepts form data with:\n    - text: Text content\n    - filename: Desired filename (optional, default: 'output.txt')\n    \n    Returns:\n    - Text file download\n    """\n    logger.info("Text file creation request received")\n    \n    # Get parameters\n    text = request.form.get('text', '')\n    filename = request.form.get('filename', 'output.txt')\n    \n    if not text:\n        raise BadRequest('No text content provided')\n    \n    # Ensure filename has .txt extension\n    if not filename.endswith('.txt'):\n        filename += '.txt'\n    \n    try:\n        # Create text file in memory\n        file_obj = BytesIO()\n        file_obj.write(text.encode('utf-8'))\n        file_obj.seek(0)\n\n        logger.info(f"Text file created: {filename}")\n        \n        # Return the file\n        return send_file(\n            file_obj,\n            mimetype='text/plain',\n            as_attachment=True,\n            download_name=filename\n        )\n\n    except Exception as e:\n        logger.error(f"Error creating text file: {e}")\n        return jsonify({"error": str(e)}), 500\n\n\ndef _get_or_create_sheet(user_code: str):\n    """Get or create a Google Sheet for the user."""\n    if not GOOGLE_SHEETS_AVAILABLE or not google_client:\n        logger.warning("Google Sheets not available")\n        return None\n        \n    sheet_name = f"{user_code}_usage_audio_translate"\n    logger.info(f"Getting/creating sheet: {sheet_name}")\n\n    try:\n        # Try to open existing sheet\n        sheet = google_client.open(sheet_name).sheet1\n        logger.info(f"Found existing sheet: {sheet_name}")\n    except gspread.exceptions.SpreadsheetNotFound:\n        try:\n            # Create new sheet\n            logger.info(f"Creating new sheet: {sheet_name}")\n            sheet = google_client.create(sheet_name).sheet1\n            # Add headers\n            sheet.append_row(["Data e Ora", "Nome File", "Durata (minuti)", "Costo Unitario (€)", "Costo Totale (€)", "Billed"])\n            logger.info(f"Created new sheet with headers: {sheet_name}")\n        except Exception as e:\n            logger.error(f"Error creating sheet: {e}")\n            return None\n\n    return sheet\n\n\ndef _log_audio_processing(user_code: str, filename: str, duration: float):\n    """Log audio processing to Google Sheets."""\n    try:\n        sheet = get_or_create_sheet(user_code)\n        if not sheet:\n            return None\n\n        now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")\n        cost_per_minute = RATE_PER_MINUTE\n        total_cost = duration * cost_per_minute\n\n        # Log to Google Sheets\n        logger.info(f"Logging to Google Sheets: {now}, {filename}, {duration}, {cost_per_minute}, {total_cost}")\n        sheet.append_row([now, filename, duration, f"{cost_per_minute:.2f}", f"{total_cost:.2f}", 'YES'])\n        \n        logger.info(f"Successfully logged to Google Sheets: {filename} - {duration} min - €{total_cost:.2f}")\n        return True\n\n    except Exception as e:\n        logger.error(f"Error logging to Google Sheets: {e}")\n        return None\n\n\n# Error handlers specific to this blueprint\n@bp.errorhandler(BadRequest)\ndef handle_bad_request(error):\n    """Handle bad request errors."""\n    logger.warning(f"Bad request: {error.description}")\n    return jsonify({'error': error.description}), 400",
"metadata": {
"lineCount": 269,
"sizeBytes": 8783,
"lastModified": "2025-10-15T22:46:17.779Z"
}
},
"flask_app/api/protected.py": {
"content": """"Protected API routes requiring Auth0 authentication."""\nfrom flask import Blueprint, jsonify, request\nfrom flask_app.auth.auth0 import require_auth, get_user_info, Auth0Error\nimport logging\n\nlogger = logging.getLogger(name)\n\nbp = Blueprint('protected', name)\n\n\n@bp.route('/api/me', methods=['GET'])\n@require_auth\ndef get_current_user():\n    """Get current authenticated user information.\n\n    Returns user data from JWT token payload.\n\n    Returns:\n        JSON response with user information\n\n    Example:\n        GET /api/me\n        Authorization: Bearer <token>\n\n        Response:\n        {\n            "user": {\n                "sub": "auth0|123456789",\n                "email": "user@example.com",\n                "email_verified": true,\n                ...\n            }\n        }\n    """\n    try:\n        # User data is already attached to request by @require_auth decorator\n        user_data = request.user\n\n        return jsonify({\n            'user': user_data,\n            'user_id': request.user_id\n        }), 200\n\n    except Exception as e:\n        logger.error(f"Error in /api/me: {e}")\n        return jsonify({\n            'error': 'internal_error',\n            'message': 'Failed to retrieve user information'\n        }), 500\n\n\n@bp.route('/api/userinfo', methods=['GET'])\n@require_auth\ndef get_userinfo():\n    """Get detailed user information from Auth0 userinfo endpoint.\n\n    Fetches extended user profile from Auth0's /userinfo endpoint.\n\n    Returns:\n        JSON response with detailed user profile\n\n    Example:\n        GET /api/userinfo\n        Authorization: Bearer <token>\n\n        Response:\n        {\n            "sub": "auth0|123456789",\n            "email": "user@example.com",\n            "name": "John Doe",\n            "picture": "https://...",\n            ...\n        }\n    """\n    try:\n        # Use the token already validated by @require_auth decorator\n        # No need to extract it again from the header\n        token = request.auth_token\n\n        # Fetch user info from Auth0\n        user_info = get_user_info(token)\n\n        return jsonify(user_info), 200\n\n    except Auth0Error as e:\n        logger.error(f"Auth0 error in /api/userinfo: {e.message}")\n        return jsonify({\n            'error': 'auth0_error',\n            'message': e.message\n        }), e.status_code\n    except Exception as e:\n        logger.error(f"Error in /api/userinfo: {e}")\n        return jsonify({\n            'error': 'internal_error',\n            'message': 'Failed to retrieve user information'\n        }), 500\n\n\n@bp.route('/api/protected/test', methods=['GET'])\n@require_auth\ndef protected_test():\n    """Test endpoint to verify authentication is working.\n\n    Simple test endpoint that requires authentication.\n\n    Returns:\n        JSON response confirming authentication\n\n    Example:\n        GET /api/protected/test\n        Authorization: Bearer <token>\n\n        Response:\n        {\n            "message": "Authentication successful",\n            "user_id": "auth0|123456789"\n        }\n    """\n    return jsonify({\n        'message': 'Authentication successful',\n        'user_id': request.user_id,\n        'authenticated': True\n    }), 200\n",
"metadata": {
"lineCount": 124,
"sizeBytes": 3180,
"lastModified": "2026-01-17T15:07:11.188Z"
}
},
"flask_app/api/auth.py": {
"content": """"Authentication API blueprint for mobile app login.\n\n⚠️  SECURITY WARNING - DEPRECATED ENDPOINTS\n=====================================\nThe endpoints in this module provide session-based authentication WITHOUT\nreal credential verification. This is a SECURITY VULNERABILITY in production.\n\nThese endpoints should ONLY be used in development/testing environments with\nthe ALLOW_INSECURE_SESSION_AUTH=true flag.\n\nFor production:\n- Use Auth0 JWT tokens exclusively\n- Remove or disable these endpoints\n- Implement proper authentication if session tokens are required\n\nSee COPILOT_SUGGESTIONS_RESOLVED.md for security recommendations.\n"""\nimport logging\nimport os\nfrom flask import Blueprint, request, jsonify\nfrom flask_app.services.session_manager import get_session_manager\n\nbp = Blueprint('mobile_auth', name)\nlogger = logging.getLogger(name)\n\n# Get session manager instance\nsession_manager = get_session_manager()\n\n# Security: Check if insecure auth is enabled\nALLOW_INSECURE_SESSION_AUTH = os.getenv('ALLOW_INSECURE_SESSION_AUTH', 'false').lower() == 'true'\n\nif not ALLOW_INSECURE_SESSION_AUTH:\n    logger.warning(\n        "⚠️  Mobile auth endpoints are DEPRECATED and DISABLED in secure mode. "\n        "Set ALLOW_INSECURE_SESSION_AUTH=true only in development/testing."\n    )\n\n\n@bp.route('/login', methods=['POST'])\ndef login():\n    """[DEPRECATED - INSECURE] Simulate login and generate session token.\n    \n    ⚠️  SECURITY WARNING: This endpoint does NOT verify credentials!\n    It generates tokens for ANY username without authentication.\n    \n    This is a CRITICAL SECURITY VULNERABILITY and should NOT be used in production.\n    \n    Use Auth0 authentication instead for production environments.\n\n    Accepts JSON with:\n    - username: User identifier\n    - password: User password (NOT VALIDATED - SECURITY ISSUE)\n\n    Returns:\n    - auth_token: Session token for WebSocket authentication\n    - user_id: User identifier\n    - expires_at: Token expiration timestamp\n    """\n    # Block endpoint in production (secure mode)\n    if not ALLOW_INSECURE_SESSION_AUTH:\n        logger.warning("Attempt to use deprecated /mobile-auth/login endpoint in secure mode")\n        return jsonify({\n            'error': 'endpoint_disabled',\n            'message': 'This endpoint is disabled in production. Use Auth0 authentication.',\n            'details': 'Set ALLOW_INSECURE_SESSION_AUTH=true only in development/testing.'\n        }), 403\n\n    logger.warning("⚠️  Using INSECURE mobile auth endpoint - development mode only!")\n    logger.info("Login request received")\n\n    data = request.get_json()\n    if not data or 'username' not in data:\n        logger.warning("Login failed: missing username")\n        return jsonify({'error': 'Username is required'}), 400\n\n    username = data.get('username')\n    \n    # ⚠️  SECURITY ISSUE: No password validation!\n    # This allows ANYONE to create a session for ANY username\n    \n    # Create session using session manager\n    session_data = session_manager.create_session(username, expires_hours=24)\n\n    logger.warning(f"INSECURE session created for user: {username} (no credential check)")\n\n    return jsonify({\n        **session_data,\n        'message': 'Login successful (DEVELOPMENT MODE - NO REAL AUTH)',\n        'warning': 'This endpoint does not verify credentials. Use Auth0 for production.'\n    }), 200\n\n\n@bp.route('/logout', methods=['POST'])\ndef logout():\n    """[DEPRECATED - INSECURE] Invalidate session token.\n    \n    ⚠️  This endpoint is deprecated. Only enabled in development mode.\n\n    Accepts JSON with:\n    - auth_token: Session token to invalidate\n    """\n    if not ALLOW_INSECURE_SESSION_AUTH:\n        return jsonify({\n            'error': 'endpoint_disabled',\n            'message': 'This endpoint is disabled in production.'\n        }), 403\n    \n    data = request.get_json()\n    auth_token = data.get('auth_token') if data else None\n\n    if session_manager.invalidate_session(auth_token):\n        return jsonify({'message': 'Logout successful'}), 200\n\n    return jsonify({'message': 'Invalid or expired token'}), 401\n\n\n@bp.route('/verify', methods=['POST'])\ndef verify_token():\n    """[DEPRECATED - INSECURE] Verify if a session token is valid.\n    \n    ⚠️  This endpoint is deprecated. Only enabled in development mode.\n\n    Accepts JSON with:\n    - auth_token: Session token to verify\n    """\n    if not ALLOW_INSECURE_SESSION_AUTH:\n        return jsonify({\n            'error': 'endpoint_disabled',\n            'message': 'This endpoint is disabled in production.'\n        }), 403\n    \n    data = request.get_json()\n    auth_token = data.get('auth_token') if data else None\n\n    session_info = session_manager.get_session_info(auth_token)\n    \n    if session_info:\n        return jsonify({\n            'valid': True,\n            'user_id': session_info['user_id'],\n            'username': session_info['username']\n        }), 200\n\n    return jsonify({'valid': False, 'message': 'Invalid token'}), 401\n\n\ndef is_valid_session(auth_token: str) -> bool:\n    """Check if a session token is valid (used by WebSocket handler).\n    \n    ⚠️  Only works when ALLOW_INSECURE_SESSION_AUTH=true\n    """\n    if not ALLOW_INSECURE_SESSION_AUTH:\n        return False\n    return session_manager.validate_session(auth_token)\n\n\ndef get_session_info(auth_token: str) -> dict:\n    """Get session information for a valid token.\n    \n    ⚠️  Only works when ALLOW_INSECURE_SESSION_AUTH=true\n    """\n    if not ALLOW_INSECURE_SESSION_AUTH:\n        return None\n    return session_manager.get_session_info(auth_token)\n",
"metadata": {
"lineCount": 165,
"sizeBytes": 5605,
"lastModified": "2026-01-17T15:07:11.187Z"
}
},
"api/auth.py": {
"content": """"Authentication endpoints for user management."""\n\nimport logging\nimport re\nfrom flask import Blueprint, request, jsonify, g\nfrom sqlalchemy.exc import IntegrityError\nfrom utils.exceptions import InvalidRequestError\n\nlogger = logging.getLogger(name)\nbp = Blueprint('auth', name)\n\n\ndef validate_password(password):\n    """\n    Validate password meets security requirements.\n    \n    Args:\n        password (str): Password to validate\n        \n    Raises:\n        InvalidRequestError: If password doesn't meet requirements\n        \n    Returns:\n        bool: True if password is valid\n    """\n    if not password:\n        raise InvalidRequestError("Password is required")\n    \n    if len(password) < 8:\n        raise InvalidRequestError("Password must be at least 8 characters long")\n    \n    # Additional security checks (recommended)\n    if len(password.strip()) != len(password):\n        raise InvalidRequestError("Password cannot start or end with whitespace")\n    \n    # Check for at least one letter and one number (recommended for stronger passwords)\n    if not re.search(r'[a-zA-Z]', password):\n        raise InvalidRequestError("Password must contain at least one letter")\n    \n    if not re.search(r'\d', password):\n        raise InvalidRequestError("Password must contain at least one number")\n    \n    return True\n\n\ndef validate_email(email):\n    """\n    Validate email format.\n    \n    Args:\n        email (str): Email to validate\n        \n    Raises:\n        InvalidRequestError: If email format is invalid\n        \n    Returns:\n        bool: True if email is valid\n    """\n    if not email:\n        raise InvalidRequestError("Email is required")\n    \n    email_pattern = r'^[a-zA-Z0-9.%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'\n    if not re.match(email_pattern, email):\n        raise InvalidRequestError("Invalid email format")\n    \n    return True\n\n@bp.route('/register', methods=['POST'])\ndef register():\n    """Register new user account."""\n    try:\n        from flask_jwt_extended import create_access_token\n        from models.user import User\n        from models import db\n        \n        data = request.get_json()\n        \n        # Validation\n        required_fields = ['email', 'password']\n        for field in required_fields:\n            if not data.get(field):\n                return jsonify({'error': f'Missing required field: {field}'}), 400\n        \n        email = data['email'].lower().strip()\n        password = data['password']\n        \n        # Validate email format\n        try:\n            validate_email(email)\n        except InvalidRequestError as e:\n            return jsonify({'error': str(e)}), 400\n        \n        # Validate password before proceeding\n        try:\n            validate_password(password)\n        except InvalidRequestError as e:\n            return jsonify({'error': str(e)}), 400\n        \n        # Check if user exists\n        if User.query.filter_by(email=email).first():\n            return jsonify({'error': 'Email already registered'}), 400\n        \n        # Create user\n        user = User(\n            email=email,\n            first_name=data.get('first_name', ''),\n            last_name=data.get('last_name', ''),\n            company=data.get('company', ''),\n            plan=data.get('plan', 'free')\n        )\n        user.set_password(password)\n        \n        db.session.add(user)\n        db.session.commit()\n        \n        # Generate first API key\n        api_key_value = user.generate_api_key("Default API Key")\n        \n        # Create JWT token\n        access_token = create_access_token(identity=user.id)\n        \n        logger.info(f"New user registered: {email}")\n        \n        return jsonify({\n            'message': 'User registered successfully',\n            'user': user.to_dict(),\n            'access_token': access_token,\n            'api_key': api_key_value  # Show only once!\n        }), 201\n        \n    except IntegrityError:\n        db.session.rollback()\n        return jsonify({'error': 'Email already registered'}), 400\n    except Exception as e:\n        db.session.rollback()\n        logger.error(f"Registration error: {str(e)}")\n        return jsonify({'error': 'Registration failed'}), 500\n\n@bp.route('/login', methods=['POST'])\ndef login():\n    """User login with email and password."""\n    try:\n        from flask_jwt_extended import create_access_token\n        from models.user import User\n        from models import db\n        from datetime import datetime\n        \n        data = request.get_json()\n        \n        email = data.get('email', '').lower().strip()\n        password = data.get('password', '')\n        \n        if not email or not password:\n            return jsonify({'error': 'Email and password required'}), 400\n        \n        # Find user\n        user = User.query.filter_by(email=email).first()\n        \n        if not user or not user.check_password(password):\n            return jsonify({'error': 'Invalid email or password'}), 401\n        \n        if not user.is_active:\n            return jsonify({'error': 'Account deactivated'}), 401\n        \n        # Update last login\n        user.last_login = datetime.utcnow()\n        db.session.commit()\n        \n        # Create JWT token\n        access_token = create_access_token(identity=user.id)\n        \n        logger.info(f"User logged in: {email}")\n        \n        return jsonify({\n            'message': 'Login successful',\n            'user': user.to_dict(),\n            'access_token': access_token\n        })\n        \n    except Exception as e:\n        logger.error(f"Login error: {str(e)}")\n        return jsonify({'error': 'Login failed'}), 500\n\n@bp.route('/profile', methods=['GET'])\ndef get_profile():\n    """Get current user profile."""\n    try:\n        from flask_jwt_extended import verify_jwt_in_request, get_jwt_identity\n        from models.user import User\n        \n        verify_jwt_in_request()\n        user_id = get_jwt_identity()\n        user = User.query.get(user_id)\n        \n        if not user:\n            return jsonify({'error': 'User not found'}), 404\n        \n        return jsonify({\n            'user': user.to_dict(),\n            'api_keys': [key.to_dict() for key in user.api_keys if key.is_active]\n        })\n        \n    except Exception as e:\n        logger.error(f"Profile error: {str(e)}")\n        return jsonify({'error': 'Authentication required'}), 401\n\n@bp.route('/api-keys', methods=['POST'])\ndef create_api_key():\n    """Generate new API key for current user."""\n    try:\n        from flask_jwt_extended import verify_jwt_in_request, get_jwt_identity\n        from models.user import User\n        \n        verify_jwt_in_request()\n        user_id = get_jwt_identity()\n        user = User.query.get(user_id)\n        \n        if not user:\n            return jsonify({'error': 'User not found'}), 404\n        \n        data = request.get_json()\n        name = data.get('name', 'API Key')\n        \n        # Generate new key\n        api_key_value = user.generate_api_key(name)\n        \n        logger.info(f"New API key created for user {user.email}: {name}")\n        \n        return jsonify({\n            'message': 'API key created successfully',\n            'api_key': api_key_value,  # Show only once!\n            'name': name\n        }), 201\n        \n    except Exception as e:\n        logger.error(f"API key creation error: {str(e)}")\n        return jsonify({'error': 'Failed to create API key'}), 500\n\n@bp.route('/api-keys/int:key_id', methods=['DELETE'])\ndef delete_api_key(key_id):\n    """Deactivate an API key."""\n    try:\n        from flask_jwt_extended import verify_jwt_in_request, get_jwt_identity\n        from models.user import ApiKey\n        from models import db\n        \n        verify_jwt_in_request()\n        user_id = get_jwt_identity()\n        \n        api_key = ApiKey.query.filter_by(\n            id=key_id,\n            user_id=user_id\n        ).first()\n        \n        if not api_key:\n            return jsonify({'error': 'API key not found'}), 404\n        \n        api_key.is_active = False\n        db.session.commit()\n        \n        logger.info(f"API key deactivated: {key_id}")\n        \n        return jsonify({'message': 'API key deactivated'})\n        \n    except Exception as e:\n        logger.error(f"API key deletion error: {str(e)}")\n        return jsonify({'error': 'Failed to deactivate API key'}), 500",
"metadata": {
"lineCount": 267,
"sizeBytes": 8367,
"lastModified": "2025-12-05T19:14:13.458Z"
}
}
}
}

mcp__gateway__dispatch
IN
{
  "serverId": "code-trm",
  "tool": "trm.read",
  "args": {
    "sid": "29886a52-c50b-4077-9e9b-b1c6016efacd",
    "paths": [
      "flask_app/services/transcription.py",
      "flask_app/services/translation.py",
      "flask_app/services/video_transcription.py",
      "flask_app/services/postprocessing.py"
    ]
  }
}
OUT
{
"files": {
"flask_app/services/transcription.py": {
"content": """"Transcription services for various AI providers."""\nimport tempfile\nimport os\nimport logging\nfrom typing import Dict, Any, BinaryIO\nfrom werkzeug.datastructures import FileStorage\n\nfrom flask_app.clients.deepgram import DeepgramClient\nfrom flask_app.clients.openai import OpenAIClient  \nfrom flask_app.clients.assemblyai import AssemblyAIClient\nfrom utils.exceptions import TranscriptionError\n\n\nlogger = logging.getLogger(name)\n\n\nclass TranscriptionService:\n    """Base transcription service with common functionality."""\n    \n    @staticmethod\n    def save_temp_file(audio_file: FileStorage) -> str:\n        """Save uploaded file to temporary location and return path."""\n        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')\n        try:\n            audio_file.save(temp_file.name)\n            return temp_file.name\n        except Exception as exc:\n            # Clean up if save failed\n            if os.path.exists(temp_file.name):\n                os.unlink(temp_file.name)\n            raise TranscriptionError(f"Failed to save audio file: {str(exc)}") from exc\n    \n    @staticmethod\n    def cleanup_temp_file(file_path: str) -> None:\n        """Clean up temporary file safely."""\n        try:\n            if file_path and os.path.exists(file_path):\n                os.unlink(file_path)\n        except Exception as exc:\n            logger.warning(f"Failed to clean up temp file {file_path}: {exc}")\n\n\nclass DeepgramService(TranscriptionService):\n    """Service for Deepgram transcription using Nova-2 model."""\n    \n    def init(self):\n        self.client = DeepgramClient()\n        logger.info("Deepgram transcription service initialized")\n    \n    def transcribe(self, audio_file: FileStorage, language: str = 'en', \n                  model: str = 'nova-2', diarize: bool = False, \n                  punctuate: bool = True, paragraphs: bool = False) -> Dict[str, Any]:\n        """Transcribe audio file using Deepgram Nova-2 with enhanced options.\n        \n        Args:\n            audio_file: Uploaded audio file\n            language: Language code (default: 'en')\n            model: Deepgram model to use (default: 'nova-2')\n            diarize: Enable speaker diarization (default: False)\n            punctuate: Enable smart punctuation (default: True)\n            paragraphs: Enable paragraph detection (default: False)\n            \n        Returns:\n            Transcription result with metadata and optional diarization data\n        """\n        logger.info(f"Starting Deepgram transcription (language: {language}, model: {model}, diarize: {diarize})")\n        \n        try:\n            # Read file content\n            file_bytes = audio_file.read()\n            audio_file.seek(0)  # Reset file pointer for potential reuse\n            \n            # Use client to transcribe with enhanced options\n            result = self.client.transcribe(\n                audio_data=file_bytes,\n                language=language,\n                model=model,\n                diarize=diarize,\n                punctuate=punctuate,\n                paragraphs=paragraphs\n            )\n            \n            logger.info(f"Deepgram transcription completed successfully (speakers: {result.get('diarization', {}).get('speakers_detected', 'N/A')})")\n            return result\n            \n        except Exception as exc:\n            logger.error(f"Deepgram transcription failed: {exc}")\n            raise TranscriptionError(f"Deepgram transcription failed: {str(exc)}") from exc\n\n\nclass WhisperService(TranscriptionService):\n    """Service for OpenAI Whisper transcription with automatic chunking."""\n    \n    def init(self):\n        self.client = OpenAIClient()\n        logger.info("OpenAI Whisper transcription service initialized")\n    \n    def transcribe(self, audio_file: FileStorage, language: str = 'en') -> Dict[str, Any]:\n        """Transcribe audio file using OpenAI Whisper with automatic chunking.\n        \n        Args:\n            audio_file: Uploaded audio file\n            language: Language code (default: 'en')\n            \n        Returns:\n            Transcription result with chunking metadata if applicable\n        """\n        logger.info(f"Starting Whisper transcription (language: {language})")\n        \n        temp_path = None\n        try:\n            # Save to temporary file (required for audio processing)\n            temp_path = self.save_temp_file(audio_file)\n            \n            # Use client to transcribe with automatic chunking\n            result = self.client.transcribe_with_chunking(\n                audio_path=temp_path,\n                language=language\n            )\n            \n            logger.info("Whisper transcription completed successfully")\n            return result\n            \n        except Exception as exc:\n            logger.error(f"Whisper transcription failed: {exc}")\n            raise TranscriptionError(f"Whisper transcription failed: {str(exc)}") from exc\n        finally:\n            # Always clean up temp file\n            if temp_path:\n                self.cleanup_temp_file(temp_path)\n\n\nclass AssemblyAIService(TranscriptionService):\n    """Service for AssemblyAI transcription."""\n    \n    def init(self):\n        self.client = AssemblyAIClient()\n        logger.info("AssemblyAI transcription service initialized")\n    \n    def transcribe(self, audio_file: FileStorage, language: str = 'en') -> Dict[str, Any]:\n        """Transcribe audio file using AssemblyAI.\n        \n        Args:\n            audio_file: Uploaded audio file\n            language: Language code (default: 'en')\n            \n        Returns:\n            Transcription result with metadata\n        """\n        logger.info(f"Starting AssemblyAI transcription (language: {language})")\n        \n        temp_path = None\n        try:\n            # Save to temporary file\n            temp_path = self.save_temp_file(audio_file)\n            \n            # Use client to transcribe\n            result = self.client.transcribe(\n                audio_path=temp_path,\n                language=language\n            )\n            \n            logger.info("AssemblyAI transcription completed successfully")\n            return result\n            \n        except Exception as exc:\n            logger.error(f"AssemblyAI transcription failed: {exc}")\n            raise TranscriptionError(f"AssemblyAI transcription failed: {str(exc)}") from exc\n        finally:\n            # Always clean up temp file\n            if temp_path:\n                self.cleanup_temp_file(temp_path)",
"metadata": {
"lineCount": 172,
"sizeBytes": 6537,
"lastModified": "2025-12-04T21:15:05.259Z"
}
},
"flask_app/services/translation.py": {
"content": """"Translation services using Flask best practices."""\nimport logging\nimport requests\nfrom typing import Dict, Any, Optional\n\nfrom flask_app.clients.openai import OpenAIClient\nfrom flask_app.clients.google import GoogleClient\nfrom flask_app.clients.deepseek import DeepSeekClient\nfrom utils.exceptions import TranslationError\n\n\nlogger = logging.getLogger(name)\n\n\nclass TranslationService:\n    """Base translation service with common functionality."""\n    pass\n\n\nclass OpenAITranslationService(TranslationService):\n    """Service for OpenAI GPT-based translation with automatic text chunking."""\n    \n    def init(self):\n        self.client = OpenAIClient()\n        logger.info("OpenAI translation service initialized")\n    \n    def translate(self, text: str, source_language: str, target_language: str) -> Dict[str, Any]:\n        """Translate text using OpenAI GPT with automatic chunking for long texts.\n        \n        Args:\n            text: Text to translate\n            source_language: Source language code\n            target_language: Target language code\n            \n        Returns:\n            Translation result with chunking metadata if applicable\n        """\n        logger.info(f"Starting OpenAI translation: {source_language} -> {target_language}")\n        \n        if not text.strip():\n            raise TranslationError("Text cannot be empty")\n        \n        try:\n            result = self.client.translate_text(text, source_language, target_language)\n            logger.info("OpenAI translation completed successfully")\n            return result\n            \n        except Exception as exc:\n            logger.error(f"OpenAI translation failed: {exc}")\n            raise TranslationError(f"OpenAI translation failed: {str(exc)}") from exc\n\n\nclass GoogleTranslationService(TranslationService):\n    """Service for Google Cloud Translation API."""\n    \n    def init(self):\n        self.client = GoogleClient()\n        logger.info("Google translation service initialized")\n    \n    def translate(self, text: str, target_language: str) -> Dict[str, Any]:\n        """Translate text using Google Cloud Translation API.\n        \n        Args:\n            text: Text to translate\n            target_language: Target language code\n            \n        Returns:\n            Translation result\n        """\n        logger.info(f"Starting Google translation to {target_language}")\n        \n        if not text.strip():\n            raise TranslationError("Text cannot be empty")\n        \n        try:\n            result = self.client.translate_text(text, target_language)\n            logger.info("Google translation completed successfully")\n            return result\n            \n        except Exception as exc:\n            logger.error(f"Google translation failed: {exc}")\n            raise TranslationError(f"Google translation failed: {str(exc)}") from exc\n\n\nclass DeepSeekTranslationService:\n    """Service for DeepSeek translation with external integration support."""\n    \n    def init(self):\n        """Initialize the DeepSeek translation service."""\n        self.client = DeepSeekClient()\n    \n    def translate(\n        self,\n        text: str,\n        source_language: str = 'auto',\n        target_language: str = 'en',\n        file_name: Optional[str] = None,\n        duration: Optional[str] = None,\n        drive_id: Optional[str] = None,\n        group_id: Optional[str] = None,\n        folder_id: Optional[str] = None,\n        file_id: Optional[str] = None,\n        project_name: Optional[str] = None,\n        is_dev: str = 'false',\n        is_local: str = 'false'\n    ) -> Dict[str, Any]:\n        """Translate text using DeepSeek with optional external integration.\n        \n        Args:\n            text: Text to translate\n            source_language: Source language code\n            target_language: Target language code\n            file_name: File name for external integrations\n            duration: Duration for external integrations\n            drive_id: Drive ID for external integrations\n            group_id: Group ID for external integrations\n            folder_id: Folder ID for external integrations\n            file_id: File ID for external integrations\n            project_name: Project name for external integrations\n            is_dev: Development mode flag\n            is_local: Local mode flag\n            \n        Returns:\n            Translation result or external integration confirmation\n        """\n        try:\n            logger.info(f"Starting DeepSeek translation: {source_language} -> {target_language}")\n            \n            # Perform translation using DeepSeek client\n            translated_text = self.client.translate(text, source_language, target_language)\n            \n            logger.info("DeepSeek translation completed")\n            \n            # Handle external integration\n            if is_local == "true":\n                return {'translated_text': translated_text}\n            \n            # Send to external webhook if not local\n            return self._send_to_external_webhook(\n                translated_text=translated_text,\n                transcription=text,\n                file_name=file_name,\n                duration=duration,\n                drive_id=drive_id,\n                group_id=group_id,\n                folder_id=folder_id,\n                file_id=file_id,\n                project_name=project_name,\n                is_dev=is_dev\n            )\n            \n        except Exception as e:\n            logger.error(f"DeepSeek translation failed: {e}")\n            return {'error': f'Translation failed: {str(e)}'}\n    \n    def _send_to_external_webhook(\n        self,\n        translated_text: str,\n        transcription: str,\n        file_name: Optional[str],\n        duration: Optional[str],\n        drive_id: Optional[str],\n        group_id: Optional[str],\n        folder_id: Optional[str],\n        file_id: Optional[str],\n        project_name: Optional[str],\n        is_dev: str\n    ) -> Dict[str, Any]:\n        """Send translation results to external webhook."""\n        try:\n            # Determine webhook URL based on environment\n            if is_dev == "true":\n                url = "https://hook.eu2.make.com/62p3xl6a7nnr14y89i6av1bxapyvxpxn\"\n            else:\n                url = "https://hook.eu2.make.com/xjxlm9ehhdn16mhtfnp77sxpgidvagqe\"\n            \n            logger.info(f"Sending DeepSeek translation to webhook: {url}")\n            \n            # Prepare data for webhook\n            data = {\n                "translation": translated_text,\n                "transcription": transcription,\n                "fileName": file_name,\n                "duration": duration,\n                "driveId": drive_id,\n                "groupId": group_id,\n                "folderId": folder_id,\n                "fileId": file_id,\n                "projectName": project_name\n            }\n            \n            # Send to webhook\n            response = requests.post(url, data=data, timeout=30)\n            \n            if response.status_code != 200:\n                logger.error(f"Webhook request failed: {response.status_code} - {response.text}")\n                return {'error': 'Failed to send request to external service'}\n            \n            logger.info("Successfully sent translation to external webhook")\n            return {'message': 'Request sent to external service'}\n            \n        except requests.RequestException as e:\n            logger.error(f"Webhook request error: {e}")\n            return {'error': 'Failed to communicate with external service'}\n        except Exception as e:\n            logger.error(f"Unexpected error in webhook integration: {e}")\n            return {'error': 'External integration failed'}",
"metadata": {
"lineCount": 207,
"sizeBytes": 7759,
"lastModified": "2025-10-15T22:46:17.780Z"
}
},
"flask_app/services/video_transcription.py": {
"content": """"Video transcription service using Whisper with video processing capabilities."""\nimport re\nimport logging\nfrom typing import Dict, Any, Optional\nfrom werkzeug.datastructures import FileStorage\n\nfrom flask_app.clients.video_processor import get_video_processor\nfrom utils.exceptions import TranscriptionError\n\nlogger = logging.getLogger(name)\n\n\nclass VideoTranscriptionService:\n    """Service for transcribing videos from URLs or files."""\n    \n    def init(self):\n        """Initialize the video transcription service."""\n        self.video_processor = get_video_processor()\n        logger.info("Video transcription service initialized")\n    \n    def transcribe_from_url(self, video_url: str, language: Optional[str] = None,\n                           model_size: str = "base") -> Dict[str, Any]:\n        """Transcribe video from URL using Whisper.\n        \n        Args:\n            video_url: URL of the video to transcribe\n            language: Language code (None for auto-detect)\n            model_size: Whisper model size\n            \n        Returns:\n            Transcription result with video metadata\n        """\n        try:\n            logger.info(f"Starting video URL transcription (model: {model_size}, language: {language or 'auto'})")\n            \n            # Validate URL\n            if not video_url or not video_url.strip():\n                raise TranscriptionError("Video URL cannot be empty")\n            \n            # Validate model size\n            valid_models = ["tiny", "base", "small", "medium", "large"]\n            if model_size not in valid_models:\n                raise TranscriptionError(f"Invalid model size. Must be one of: {', '.join(valid_models)}")\n            \n            # Process video URL\n            result = self.video_processor.process_video_url(\n                video_url=video_url.strip(),\n                language=language,\n                model_size=model_size\n            )\n            \n            # Format response for API consistency\n            formatted_result = self._format_response(result)\n            \n            logger.info("Video URL transcription completed successfully")\n            return formatted_result\n            \n        except TranscriptionError:\n            # Re-raise our custom errors\n            raise\n        except Exception as exc:\n            logger.error(f"Video URL transcription failed: {exc}")\n            raise TranscriptionError(f"Video URL transcription failed: {str(exc)}") from exc\n    \n    def transcribe_from_file(self, video_file: FileStorage, language: Optional[str] = None,\n                            model_size: str = "base") -> Dict[str, Any]:\n        """Transcribe uploaded video file using Whisper.\n        \n        Args:\n            video_file: Uploaded video file\n            language: Language code (None for auto-detect)\n            model_size: Whisper model size\n            \n        Returns:\n            Transcription result with file metadata\n        """\n        try:\n            logger.info(f"Starting video file transcription (model: {model_size}, language: {language or 'auto'})")\n            \n            # Validate file\n            if not video_file or video_file.filename == '':\n                raise TranscriptionError("No video file provided")\n            \n            # Validate model size\n            valid_models = ["tiny", "base", "small", "medium", "large"]\n            if model_size not in valid_models:\n                raise TranscriptionError(f"Invalid model size. Must be one of: {', '.join(valid_models)}")\n            \n            # Read file data\n            video_data = video_file.read()\n            if not video_data:\n                raise TranscriptionError("Video file is empty")\n            \n            # Validate file size (limit to 100MB for uploaded files)\n            max_size = 100 * 1024 * 1024  # 100MB\n            if len(video_data) > max_size:\n                raise TranscriptionError(f"Video file too large. Maximum size: {max_size // (1024*1024)}MB")\n            \n            # Process video file\n            result = self.video_processor.process_video_file(\n                video_data=video_data,\n                filename=video_file.filename,\n                language=language,\n                model_size=model_size\n            )\n            \n            # Format response for API consistency\n            formatted_result = self._format_response(result)\n            \n            logger.info("Video file transcription completed successfully")\n            return formatted_result\n            \n        except TranscriptionError:\n            # Re-raise our custom errors\n            raise\n        except Exception as exc:\n            logger.error(f"Video file transcription failed: {exc}")\n            raise TranscriptionError(f"Video file transcription failed: {str(exc)}") from exc\n    \n    def _format_response(self, result: Dict[str, Any]) -> Dict[str, Any]:\n        """Format the transcription result for API response.\n        \n        Args:\n            result: Raw transcription result from video processor\n            \n        Returns:\n            Formatted API response\n        """\n        # Base response structure\n        formatted = {\n            "transcript": result.get("transcript", ""),\n            "confidence": result.get("confidence", 0.0),\n            "detected_language": result.get("detected_language", "unknown"),\n            "model": result.get("model", "whisper"),\n            "service": "whisper-video",\n            "word_count": result.get("word_count", 0),\n            "transcription_time": result.get("transcription_time", 0.0)\n        }\n        \n        # Add source-specific metadata\n        if result.get("source") == "video_url":\n            formatted.update({\n                "source": "video_url",\n                "video_url": result.get("video_url"),\n                "video_title": result.get("video_title"),\n                "video_duration": result.get("video_duration", 0),\n                "video_uploader": result.get("video_uploader")\n            })\n        elif result.get("source") == "video_file":\n            formatted.update({\n                "source": "video_file",\n                "filename": result.get("filename"),\n                "file_size": result.get("file_size", 0),\n                "video_duration": result.get("video_duration", 0)\n            })\n        \n        # Add segments if available\n        if "segments" in result:\n            formatted["segments"] = result["segments"]\n        \n        # Add formatted transcript array for consistency with other endpoints\n        if result.get("transcript"):\n            # Split transcript into sentences using capturing group to preserve punctuation\n            # Use capturing group to preserve sentence-ending punctuation\n            parts = re.split(r'([.!?]+)', result["transcript"])\n            \n            # Reconstruct sentences with their punctuation\n            sentences = []\n            for i in range(0, len(parts) - 1, 2):\n                sentence = parts[i].strip()\n                if sentence:  # Only add non-empty sentences\n                    # Add punctuation if it exists\n                    if i + 1 < len(parts) and parts[i + 1]:\n                        sentence += parts[i + 1]\n                    sentences.append(sentence)\n            \n            # Handle case where transcript doesn't end with punctuation\n            if len(parts) % 2 == 1 and parts[-1].strip():\n                sentences.append(parts[-1].strip())\n            \n            formatted["formatted_transcript_array"] = [\n                {"text": sentence} \n                for sentence in sentences \n                if sentence.strip()\n            ]\n        else:\n            formatted["formatted_transcript_array"] = []\n        \n        return formatted",
"metadata": {
"lineCount": 189,
"sizeBytes": 7801,
"lastModified": "2025-12-04T21:15:05.259Z"
}
},
"flask_app/services/postprocessing.py": {
"content": """"Post-processing services for sentiment analysis and document generation."""\nimport logging\nimport tempfile\nimport os\nfrom typing import Dict, Any\n\n# Temporarily simplified imports for testing\n# from core.postprocessing.sentiment import run_sentiment_analysis\n# from core.postprocessing.docx_generator import create_word_document\n# from core.postprocessing.pdf_generator import create_pdf_document\n# from core.postprocessing.excel_generator import create_excel_report\n\n\nlogger = logging.getLogger(name)\n\n\nclass SentimentService:\n    """Service for sentiment analysis."""\n    \n    def init(self):\n        logger.info("Sentiment analysis service initialized")\n    \n    def analyze(self, text: str) -> Dict[str, Any]:\n        """Analyze sentiment of text.\n        \n        Args:\n            text: Text to analyze\n            \n        Returns:\n            Sentiment analysis result\n        """\n        logger.info(f"Starting sentiment analysis (text length: {len(text)})")\n        \n        try:\n            # Temporary placeholder implementation\n            result = {\n                "sentiment": "positive",\n                "confidence": 0.85,\n                "scores": {\n                    "positive": 0.85,\n                    "negative": 0.10,\n                    "neutral": 0.05\n                }\n            }\n            logger.info("Sentiment analysis completed successfully")\n            return result\n            \n        except Exception as exc:\n            logger.error(f"Sentiment analysis failed: {exc}")\n            raise\n\n\nclass DocumentService:\n    """Service for document generation."""\n    \n    def init(self):\n        logger.info("Document generation service initialized")\n    \n    def generate_word(self, text: str, title: str = "Transcription Report") -> str:\n        """Generate Word document.\n        \n        Args:\n            text: Document content\n            title: Document title\n            \n        Returns:\n            Path to generated document\n        """\n        logger.info(f"Generating Word document: {title}")\n        \n        try:\n            # Temporary placeholder - create a simple text file\n            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.docx', mode='w')\n            temp_file.write(f"Title: {title}\n\n{text}")\n            temp_file.close()\n            \n            logger.info(f"Word document generated: {temp_file.name}")\n            return temp_file.name\n            \n        except Exception as exc:\n            logger.error(f"Word document generation failed: {exc}")\n            raise\n    \n    def generate_pdf(self, text: str, title: str = "Transcription Report") -> str:\n        """Generate PDF document.\n        \n        Args:\n            text: Document content\n            title: Document title\n            \n        Returns:\n            Path to generated document\n        """\n        logger.info(f"Generating PDF document: {title}")\n        \n        try:\n            # Temporary placeholder - create a simple text file\n            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.pdf', mode='w')\n            temp_file.write(f"Title: {title}\n\n{text}")\n            temp_file.close()\n            \n            logger.info(f"PDF document generated: {temp_file.name}")\n            return temp_file.name\n            \n        except Exception as exc:\n            logger.error(f"PDF document generation failed: {exc}")\n            raise\n    \n    def generate_excel_report(self, transcript: str, analysis: Dict[str, Any], \n                            title: str = "Transcription Analysis Report") -> str:\n        """Generate Excel analysis report.\n        \n        Args:\n            transcript: Transcript text\n            analysis: Analysis data\n            title: Report title\n            \n        Returns:\n            Path to generated report\n        """\n        logger.info(f"Generating Excel report: {title}")\n        \n        try:\n            # Temporary placeholder - create a simple text file\n            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx', mode='w')\n            temp_file.write(f"Title: {title}\n\nTranscript:\n{transcript}\n\nAnalysis:\n{analysis}")\n            temp_file.close()\n            \n            logger.info(f"Excel report generated: {temp_file.name}")\n            return temp_file.name\n            \n        except Exception as exc:\n            logger.error(f"Excel report generation failed: {exc}")\n            raise",
"metadata": {
"lineCount": 134,
"sizeBytes": 4469,
"lastModified": "2025-10-15T22:46:17.780Z"
}
}
}
}

mcp__gateway__dispatch
IN
{
  "serverId": "code-trm",
  "tool": "trm.read",
  "args": {
    "sid": "29886a52-c50b-4077-9e9b-b1c6016efacd",
    "paths": [
      "flask_app/auth/auth0.py",
      "flask_app/sockets/audio_stream.py",
      "flask_app/sockets/audio_stream_auth0.py",
      "models/user.py",
      "utils/config.py",
      "utils/auth.py",
      "utils/exceptions.py"
    ]
  }
}
OUT
{
"files": {
"flask_app/auth/auth0.py": {
"content": """"Auth0 JWT authentication for Flask API and SocketIO WebSocket."""\nimport os\nimport logging\nfrom functools import wraps\nfrom typing import Dict, Optional, Callable\nimport requests\nfrom flask import request, jsonify, g\nimport jwt\nfrom jwt import PyJWKClient\nfrom werkzeug.exceptions import Unauthorized\n\nlogger = logging.getLogger(name)\n\n# Auth0 Configuration from environment\nAUTH0_DOMAIN = os.getenv('AUTH0_DOMAIN')\nAUTH0_AUDIENCE = os.getenv('AUTH0_AUDIENCE')\nALGORITHMS = ["RS256"]\n\n# Timeout for Auth0 API requests (in seconds)\nAUTH0_REQUEST_TIMEOUT = int(os.getenv('AUTH0_REQUEST_TIMEOUT', '30'))\n\n# Security: Feature flag to allow insecure session token fallback\n# WARNING: This should ONLY be enabled in development/testing environments\n# In production, this MUST be set to 'false' or omitted entirely\nALLOW_INSECURE_SESSION_AUTH = os.getenv('ALLOW_INSECURE_SESSION_AUTH', 'false').lower() == 'true'\n\nif ALLOW_INSECURE_SESSION_AUTH:\n    logger.warning(\n        "⚠️  SECURITY WARNING: ALLOW_INSECURE_SESSION_AUTH is enabled! "\n        "Session token fallback allows unauthenticated access. "\n        "This should NEVER be enabled in production."\n    )\n\n# Cache PyJWKClient instance to avoid repeated JWKS downloads\n_jwks_client = None\n\n\ndef get_jwks_client():\n    """Get cached PyJWKClient instance for JWKS key retrieval.\n    \n    Returns:\n        Cached PyJWKClient instance\n    """\n    global jwks_client\n    if jwks_client is None:\n        jwks_client = PyJWKClient(get_jwks_url())\n    return jwks_client\n\n\nclass Auth0Error(Exception):\n    """Custom exception for Auth0 authentication errors."""\n    def init(self, message: str, status_code: int = 401):\n        self.message = message\n        self.status_code = status_code\n        super().init(self.message)\n\n\ndef get_jwks_url() -> str:\n    """Get JWKS URL from Auth0 domain."""\n    if not AUTH0_DOMAIN:\n        raise Auth0Error("AUTH0_DOMAIN not configured", 500)\n    return f"https://{AUTH0_DOMAIN}/.well-known/jwks.json"\n\n\ndef get_token_from_header() -> Optional[str]:\n    """Extract JWT token from Authorization header.\n\n    Returns:\n        Token string or None if not found\n    """\n    auth_header = request.headers.get('Authorization', None)\n\n    if not auth_header:\n        return None\n\n    parts = auth_header.split()\n\n    if parts[0].lower() != 'bearer':\n        raise Auth0Error('Authorization header must start with Bearer')\n    elif len(parts) == 1:\n        raise Auth0Error('Token not found')\n    elif len(parts) > 2:\n        raise Auth0Error('Authorization header must be Bearer token')\n\n    return parts[1]\n\n\ndef verify_jwt(token: str) -> Dict:\n    """Verify and decode Auth0 JWT token with RS256 algorithm.\n\n    Downloads JWKS from Auth0, validates:\n    - Issuer (iss)\n    - Audience (aud)\n    - Algorithm (RS256)\n    - Expiration (exp)\n    - Signature\n\n    Args:\n        token: JWT token string\n\n    Returns:\n        Decoded token payload as dict\n\n    Raises:\n        Auth0Error: If token is invalid or verification fails\n    """\n    if not AUTH0_DOMAIN:\n        raise Auth0Error("AUTH0_DOMAIN environment variable not set", 500)\n\n    if not AUTH0_AUDIENCE:\n        raise Auth0Error("AUTH0_AUDIENCE environment variable not set", 500)\n\n    try:\n        # Get JWKS URL\n        jwks_url = get_jwks_url()\n\n        # Get cached PyJWKClient instance (avoids repeated JWKS downloads)\n        jwks_client = get_jwks_client()\n\n        # Get the signing key from JWT header\n        signing_key = jwks_client.get_signing_key_from_jwt(token)\n\n        # Decode and validate token\n        payload = jwt.decode(\n            token,\n            signing_key.key,\n            algorithms=ALGORITHMS,\n            audience=AUTH0_AUDIENCE,\n            issuer=f"https://{AUTH0_DOMAIN}/"\n        )\n\n        logger.info(f"Token verified successfully for user: {payload.get('sub')}")\n        return payload\n\n    except jwt.ExpiredSignatureError:\n        raise Auth0Error("Token has expired")\n    except jwt.InvalidAudienceError:\n        raise Auth0Error("Invalid audience")\n    except jwt.InvalidIssuerError:\n        raise Auth0Error("Invalid issuer")\n    except jwt.InvalidSignatureError:\n        raise Auth0Error("Invalid signature")\n    except jwt.InvalidTokenError as e:\n        raise Auth0Error(f"Invalid token: {str(e)}")\n    except Exception as e:\n        logger.exception(f"Token verification error: {e}")\n        raise Auth0Error("Token verification failed")\n\n\ndef require_auth(f: Callable) -> Callable:\n    """Decorator for Flask routes requiring Auth0 authentication.\n\n    Usage:\n        @app.route('/api/protected')\n        @require_auth\n        def protected_route():\n            user = request.user  # Access decoded token payload\n            return {'user': user}\n\n    The decorated function will have access to:\n    - request.user: Full decoded JWT payload\n    - request.user_id: User ID from 'sub' claim\n    """\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        try:\n            # Get token from Authorization header\n            token = get_token_from_header()\n\n            if not token:\n                return jsonify({\n                    'error': 'Authorization header is required',\n                    'message': 'Please provide a valid Bearer token'\n                }), 401\n\n            # Verify and decode token\n            payload = verify_jwt(token)\n\n            # Attach user info and token to request object\n            request.user = payload\n            request.user_id = payload.get('sub')\n            request.auth_token = token  # Store the validated token for reuse\n\n            # Also store in Flask's g object for access in nested functions\n            g.user = payload\n            g.user_id = payload.get('sub')\n            g.auth_token = token  # Store token in g as well\n\n            return f(*args, **kwargs)\n\n        except Auth0Error as e:\n            logger.warning(f"Authentication failed: {e.message}")\n            return jsonify({\n                'error': 'authentication_failed',\n                'message': e.message\n            }), e.status_code\n        except Exception as e:\n            logger.error(f"Unexpected error in auth decorator: {e}")\n            return jsonify({\n                'error': 'internal_error',\n                'message': 'An unexpected error occurred'\n            }), 500\n\n    return decorated_function\n\n\ndef verify_websocket_token(token: str) -> Dict:\n    """Verify Auth0 token for WebSocket connections.\n\n    This is a convenience wrapper around verify_jwt for WebSocket handlers.\n\n    Args:\n        token: JWT token from WebSocket auth handshake\n\n    Returns:\n        Decoded token payload\n\n    Raises:\n        Auth0Error: If token is invalid\n\n    Usage in SocketIO:\n        @socketio.on('connect', namespace='/audio-stream')\n        def handle_connect(auth):\n            try:\n                token = auth.get('token')\n                user = verify_websocket_token(token)\n                # Connection allowed\n                return True\n            except Auth0Error as e:\n                # Connection rejected\n                return False\n    """\n    if not token:\n        raise Auth0Error("Token is required for WebSocket connection")\n\n    return verify_jwt(token)\n\n\ndef get_user_info(access_token: str) -> Dict:\n    """Get user profile information from Auth0 userinfo endpoint.\n\n    Args:\n        access_token: Valid Auth0 access token\n\n    Returns:\n        User profile data as dict\n\n    Raises:\n        Auth0Error: If request fails\n    """\n    if not AUTH0_DOMAIN:\n        raise Auth0Error("AUTH0_DOMAIN not configured", 500)\n\n    userinfo_url = f"https://{AUTH0_DOMAIN}/userinfo"\n\n    try:\n        response = requests.get(\n            userinfo_url,\n            headers={'Authorization': f'Bearer {access_token}'},\n            timeout=AUTH0_REQUEST_TIMEOUT\n        )\n        response.raise_for_status()\n        return response.json()\n\n    except requests.RequestException as e:\n        logger.error(f"Failed to fetch user info: {e}")\n        raise Auth0Error(f"Failed to fetch user info: {str(e)}")\n\n\n# Error handler for Auth0 errors\ndef register_auth_error_handlers(app):\n    """Register error handlers for Auth0 authentication errors.\n\n    Call this in your app factory to enable automatic error handling.\n\n    Usage:\n        from flask_app.auth.auth0 import register_auth_error_handlers\n        register_auth_error_handlers(app)\n    """\n    @app.errorhandler(Auth0Error)\n    def handle_auth_error(error):\n        return jsonify({\n            'error': 'authentication_error',\n            'message': error.message\n        }), error.status_code\n\n    @app.errorhandler(Unauthorized)\n    def handle_unauthorized(error):\n        return jsonify({\n            'error': 'unauthorized',\n            'message': 'Authentication required'\n        }), 401\n",
"metadata": {
"lineCount": 293,
"sizeBytes": 8814,
"lastModified": "2026-01-17T15:07:11.188Z"
}
},
"flask_app/sockets/audio_stream.py": {
"content": """"WebSocket handler for real-time audio streaming and transcription."""\nimport logging\nimport base64\nfrom flask_socketio import emit\nfrom datetime import datetime\n\nfrom deepgram import (\n    DeepgramClient,\n    LiveTranscriptionEvents,\n    LiveOptions\n)\nfrom utils.config import get_app_config\nfrom flask_app.api.auth import is_valid_session, get_session_info\n\nlogger = logging.getLogger(name)\n\n# Store active connections\nactive_connections = {}\n\n\ndef init_audio_stream_handlers(socketio):\n    """Initialize WebSocket event handlers for audio streaming.\n\n    Args:\n        socketio: Flask-SocketIO instance\n    """\n\n    @socketio.on('connect', namespace='/audio-stream')\n    def handle_connect(auth):\n        """Handle new WebSocket connection with authentication."""\n        try:\n            # Extract token from auth parameter\n            if not auth or 'token' not in auth:\n                logger.warning("Connection rejected: No authentication token provided")\n                return False\n\n            token = auth['token']\n\n            # Validate session token\n            if not is_valid_session(token):\n                logger.warning(f"Connection rejected: Invalid or expired token")\n                return False\n\n            session_info = get_session_info(token)\n            user_id = session_info['user_id']\n\n            logger.info(f"WebSocket connected: user_id={user_id}")\n\n            # Initialize Deepgram streaming connection\n            try:\n                config = get_app_config()\n                dg_client = DeepgramClient(config.deepgram.api_key)\n                dg_connection = dg_client.listen.live.v("1")\n\n                # Store connection info (token validated but not stored for security)\n                from flask import request\n                active_connections[request.sid] = {\n                    'user_id': user_id,\n                    'dg_connection': dg_connection,\n                    'connected_at': datetime.utcnow().isoformat(),\n                    'is_deepgram_open': False\n                }\n\n                # Setup Deepgram event handlers\n                def on_message(self, result, **kwargs):\n                    """Handle transcription results from Deepgram."""\n                    try:\n                        sentence = result.channel.alternatives[0].transcript\n\n                        if len(sentence) == 0:\n                            return\n\n                        # Check if this is a final result\n                        is_final = result.is_final\n\n                        # Send transcription back to client\n                        emit('transcription', {\n                            'transcript': sentence,\n                            'is_final': is_final,\n                            'timestamp': datetime.utcnow().isoformat(),\n                            'confidence': result.channel.alternatives[0].confidence\n                        }, namespace='/audio-stream')\n\n                        logger.debug(f"Transcription sent: {sentence[:50]}... (final={is_final})")\n\n                    except Exception as e:\n                        logger.error(f"Error processing Deepgram message: {e}")\n\n                def on_metadata(self, metadata, **kwargs):\n                    """Handle metadata from Deepgram."""\n                    logger.debug(f"Deepgram metadata received: {metadata}")\n\n                def on_error(self, error, **kwargs):\n                    """Handle errors from Deepgram."""\n                    logger.error(f"Deepgram error: {error}")\n                    emit('error', {\n                        'message': 'Transcription service error',\n                        'timestamp': datetime.utcnow().isoformat()\n                    }, namespace='/audio-stream')\n\n                def on_open(self, open, **kwargs):\n                    """Handle Deepgram connection open."""\n                    logger.info("Deepgram connection opened")\n                    from flask import request\n                    if request.sid in active_connections:\n                        active_connections[request.sid]['is_deepgram_open'] = True\n\n                def on_close(self, close, **kwargs):\n                    """Handle Deepgram connection close."""\n                    logger.info("Deepgram connection closed")\n                    from flask import request\n                    if request.sid in active_connections:\n                        active_connections[request.sid]['is_deepgram_open'] = False\n\n                # Register Deepgram event handlers\n                dg_connection.on(LiveTranscriptionEvents.Transcript, on_message)\n                dg_connection.on(LiveTranscriptionEvents.Metadata, on_metadata)\n                dg_connection.on(LiveTranscriptionEvents.Error, on_error)\n                dg_connection.on(LiveTranscriptionEvents.Open, on_open)\n                dg_connection.on(LiveTranscriptionEvents.Close, on_close)\n\n                # Start Deepgram connection with options\n                options = LiveOptions(\n                    model="nova-2",\n                    language="it",  # Italian language\n                    smart_format=True,\n                    punctuate=True,\n                    interim_results=True,\n                    encoding="linear16",\n                    sample_rate=16000\n                )\n\n                if dg_connection.start(options) is False:\n                    logger.error("Failed to start Deepgram connection")\n                    return False\n\n                # Send connection success message\n                emit('connected', {\n                    'message': 'Successfully connected to audio streaming service',\n                    'user_id': user_id,\n                    'timestamp': datetime.utcnow().isoformat()\n                }, namespace='/audio-stream')\n\n                return True\n\n            except Exception as e:\n                logger.error(f"Failed to initialize Deepgram: {e}")\n                emit('error', {\n                    'message': 'Failed to initialize transcription service',\n                    'timestamp': datetime.utcnow().isoformat()\n                }, namespace='/audio-stream')\n                return False\n\n        except Exception as e:\n            logger.error(f"Connection error: {e}")\n            return False\n\n\n    @socketio.on('audio_chunk', namespace='/audio-stream')\n    def handle_audio_chunk(data):\n        """Handle incoming audio chunk from client.\n\n        Expected data format:\n        {\n            "audio_chunk": "base64_encoded_audio_data",\n            "timestamp": "ISO8601_timestamp"\n        }\n        """\n        from flask import request\n\n        if request.sid not in active_connections:\n            logger.warning(f"Audio chunk received from unknown connection: {request.sid}")\n            emit('error', {\n                'message': 'Connection not initialized',\n                'timestamp': datetime.utcnow().isoformat()\n            }, namespace='/audio-stream')\n            return\n\n        try:\n            # Extract audio data\n            audio_base64 = data.get('audio_chunk')\n            if not audio_base64:\n                logger.warning("Received empty audio chunk")\n                return\n\n            # Decode base64 audio\n            audio_bytes = base64.b64decode(audio_base64)\n\n            # Get Deepgram connection\n            connection_info = active_connections[request.sid]\n            dg_connection = connection_info['dg_connection']\n\n            # Check if Deepgram connection is open\n            if not connection_info.get('is_deepgram_open'):\n                logger.warning("Deepgram connection not open, buffering audio")\n                return\n\n            # Send audio to Deepgram\n            dg_connection.send(audio_bytes)\n\n            logger.debug(f"Audio chunk sent to Deepgram: {len(audio_bytes)} bytes")\n\n        except base64.binascii.Error as e:\n            logger.error(f"Invalid base64 audio data: {e}")\n            emit('error', {\n                'message': 'Invalid audio data format',\n                'timestamp': datetime.utcnow().isoformat()\n            }, namespace='/audio-stream')\n        except Exception as e:\n            logger.error(f"Error processing audio chunk: {e}")\n            emit('error', {\n                'message': 'Error processing audio data',\n                'timestamp': datetime.utcnow().isoformat()\n            }, namespace='/audio-stream')\n\n\n    @socketio.on('stop_streaming', namespace='/audio-stream')\n    def handle_stop_streaming():\n        """Handle stop streaming request from client."""\n        from flask import request\n\n        if request.sid not in active_connections:\n            return\n\n        try:\n            connection_info = active_connections[request.sid]\n            user_id = connection_info['user_id']\n\n            # Close Deepgram connection\n            dg_connection = connection_info['dg_connection']\n            if connection_info.get('is_deepgram_open'):\n                dg_connection.finish()\n                connection_info['is_deepgram_open'] = False\n\n            logger.info(f"Streaming stopped for user: {user_id}")\n\n            emit('streaming_stopped', {\n                'message': 'Streaming stopped successfully',\n                'timestamp': datetime.utcnow().isoformat()\n            }, namespace='/audio-stream')\n\n        except Exception as e:\n            logger.error(f"Error stopping stream: {e}")\n\n\n    @socketio.on('disconnect', namespace='/audio-stream')\n    def handle_disconnect():\n        """Handle WebSocket disconnection."""\n        from flask import request\n\n        if request.sid in active_connections:\n            try:\n                connection_info = active_connections[request.sid]\n                user_id = connection_info['user_id']\n\n                # Close Deepgram connection\n                dg_connection = connection_info['dg_connection']\n                if connection_info.get('is_deepgram_open'):\n                    dg_connection.finish()\n                    connection_info['is_deepgram_open'] = False\n\n                # Remove from active connections\n                del active_connections[request.sid]\n\n                logger.info(f"WebSocket disconnected: user_id={user_id}")\n\n            except Exception as e:\n                logger.error(f"Error during disconnect cleanup: {e}")\n                # Still remove the connection even if cleanup fails\n                if request.sid in active_connections:\n                    del active_connections[request.sid]\n        else:\n            logger.warning(f"Disconnect from unknown connection: {request.sid}")\n",
"metadata": {
"lineCount": 274,
"sizeBytes": 10564,
"lastModified": "2026-01-17T15:07:11.189Z"
}
},
"flask_app/sockets/audio_stream_auth0.py": {
"content": """"WebSocket handler for real-time audio streaming with Auth0 authentication.\n\nThis module provides WebSocket handlers that support BOTH:\n1. Auth0 JWT tokens (primary)\n2. Session tokens (fallback for mobile app compatibility)\n\nFeatures:\n- Dynamic language selection via query parameter\n- Deepgram Nova-2 real-time transcription\n- Multi-language support (30+ languages)\n"""\nimport logging\nimport base64\nfrom flask_socketio import emit\nfrom datetime import datetime\n\nfrom deepgram import (\n    DeepgramClient,\n    LiveTranscriptionEvents,\n    LiveOptions\n)\nfrom utils.config import get_app_config\nfrom flask_app.auth.auth0 import verify_websocket_token, Auth0Error, ALLOW_INSECURE_SESSION_AUTH\nfrom flask_app.api.auth import is_valid_session, get_session_info\n\nlogger = logging.getLogger(name)\n\n# Supported languages for Deepgram Nova-2 transcription\n# Complete list of languages supported by Deepgram's Nova-2 model\nSUPPORTED_LANGUAGES = [\n    "en",  # English\n    "es",  # Spanish\n    "fr",  # French\n    "it",  # Italian\n    "de",  # German\n    "pt",  # Portuguese\n    "nl",  # Dutch\n    "hi",  # Hindi\n    "ja",  # Japanese\n    "ko",  # Korean\n    "zh",  # Chinese\n    "sv",  # Swedish\n    "no",  # Norwegian\n    "da",  # Danish\n    "fi",  # Finnish\n    "pl",  # Polish\n    "ru",  # Russian\n    "tr",  # Turkish\n    "ar",  # Arabic\n    "el",  # Greek\n    "he",  # Hebrew\n    "cs",  # Czech\n    "uk",  # Ukrainian\n    "ro",  # Romanian\n    "hu",  # Hungarian\n    "id",  # Indonesian\n    "ms",  # Malay\n    "th",  # Thai\n    "vi",  # Vietnamese\n]\n\n# Default language if not specified or invalid\nDEFAULT_LANGUAGE = "en"\n\n# Store active connections\nactive_connections = {}\n\n\ndef authenticate_websocket(auth: dict) -> dict:\n    """Authenticate WebSocket connection with Auth0 JWT (required in production).\n\n    In production, ONLY Auth0 JWT tokens are accepted for security.\n    Session token fallback is available ONLY when ALLOW_INSECURE_SESSION_AUTH=true\n    (development/testing only).\n\n    Args:\n        auth: Authentication dict from SocketIO connection\n\n    Returns:\n        dict with user_id and auth_type\n\n    Raises:\n        Exception if authentication fails\n    """\n    if not auth or 'token' not in auth:\n        raise Exception("No authentication token provided")\n\n    token = auth['token']\n\n    # Try Auth0 JWT first (REQUIRED in production)\n    try:\n        payload = verify_websocket_token(token)\n        return {\n            'user_id': payload.get('sub'),\n            'email': payload.get('email'),\n            'auth_type': 'auth0',\n            'payload': payload\n        }\n    except Auth0Error as e:\n        logger.debug(f"Auth0 JWT verification failed: {e.message}")\n\n    # Fallback to session token ONLY if explicitly enabled (DEV ONLY)\n    if ALLOW_INSECURE_SESSION_AUTH:\n        logger.warning(\n            "⚠️  Using insecure session token fallback - this should NOT be enabled in production!"\n        )\n        try:\n            if is_valid_session(token):\n                session_info = get_session_info(token)\n                return {\n                    'user_id': session_info['user_id'],\n                    'username': session_info.get('username'),\n                    'auth_type': 'session',\n                    'payload': session_info\n                }\n        except Exception as e:\n            logger.debug(f"Session token verification failed: {e}")\n    else:\n        logger.info(\n            "Session token fallback disabled (secure mode). "\n            "Only Auth0 JWT tokens are accepted."\n        )\n\n    # Authentication failed\n    raise Exception(\n        "Invalid or expired authentication token. "\n        "Please provide a valid Auth0 JWT token."\n    )\n\n\ndef init_audio_stream_handlers(socketio):\n    """Initialize WebSocket event handlers for audio streaming with Auth0.\n\n    Args:\n        socketio: Flask-SocketIO instance\n    """\n\n    @socketio.on('connect', namespace='/audio-stream')\n    def handle_connect(auth):\n        """Handle new WebSocket connection with Auth0 or session authentication.\n        \n        Supports dynamic language selection via query parameter:\n        - wss://.../audio-stream?lang=it\n        - Defaults to 'en' if not provided or invalid\n        """\n        try:\n            # Authenticate connection\n            user_info = authenticate_websocket(auth)\n            user_id = user_info['user_id']\n            auth_type = user_info['auth_type']\n\n            logger.info(f"WebSocket connected: user_id={user_id}, auth_type={auth_type}")\n\n            # Initialize Deepgram streaming connection\n            try:\n                config = get_app_config()\n                dg_client = DeepgramClient(config.deepgram.api_key)\n                dg_connection = dg_client.listen.live.v("1")\n\n                # Extract and validate language from query parameters\n                from flask import request\n                requested_lang = request.args.get('lang', DEFAULT_LANGUAGE)\n                \n                # Validate language - default to English if invalid\n                if requested_lang not in SUPPORTED_LANGUAGES:\n                    logger.warning(\n                        f"Invalid language '{requested_lang}' requested by user {user_id}. "\n                        f"Defaulting to '{DEFAULT_LANGUAGE}'"\n                    )\n                    language = DEFAULT_LANGUAGE\n                else:\n                    language = requested_lang\n                \n                logger.info(f"Language set to '{language}' for user {user_id}")\n\n                # Store connection info\n                active_connections[request.sid] = {\n                    'user_id': user_id,\n                    'auth_type': auth_type,\n                    'user_info': user_info,\n                    # token validated but not stored for security\n                    'dg_connection': dg_connection,\n                    'language': language,  # Store selected language\n                    'connected_at': datetime.utcnow().isoformat(),\n                    'is_deepgram_open': False\n                }\n\n                # Setup Deepgram event handlers\n                def on_message(self, result, **kwargs):\n                    """Handle transcription results from Deepgram."""\n                    try:\n                        sentence = result.channel.alternatives[0].transcript\n\n                        if len(sentence) == 0:\n                            return\n\n                        # Check if this is a final result\n                        is_final = result.is_final\n\n                        # Get confidence score\n                        confidence = result.channel.alternatives[0].confidence if hasattr(\n                            result.channel.alternatives[0], 'confidence'\n                        ) else 0.0\n\n                        # Send transcription back to client\n                        emit('transcription', {\n                            'transcript': sentence,\n                            'is_final': is_final,\n                            'confidence': confidence,\n                            'timestamp': datetime.utcnow().isoformat()\n                        }, namespace='/audio-stream')\n\n                        logger.debug(f"Transcription sent: {sentence[:50]}... (is_final={is_final})")\n\n                    except Exception as e:\n                        logger.error(f"Error processing transcription result: {e}")\n                        emit('error', {\n                            'message': 'Error processing transcription',\n                            'timestamp': datetime.utcnow().isoformat()\n                        }, namespace='/audio-stream')\n\n                def on_error(self, error, **kwargs):\n                    """Handle errors from Deepgram."""\n                    logger.error(f"Deepgram error: {error}")\n                    emit('error', {\n                        'message': 'Transcription service error',\n                        'timestamp': datetime.utcnow().isoformat()\n                    }, namespace='/audio-stream')\n\n                # Register event handlers\n                dg_connection.on(LiveTranscriptionEvents.Transcript, on_message)\n                dg_connection.on(LiveTranscriptionEvents.Error, on_error)\n\n                # Configure Deepgram options with dynamic language\n                options = LiveOptions(\n                    model="nova-2",\n                    language=language,  # Use dynamically selected language\n                    smart_format=True,\n                    punctuate=True,\n                    interim_results=True,\n                    encoding="linear16",\n                    sample_rate=16000\n                )\n\n                # Start Deepgram connection\n                if dg_connection.start(options):\n                    active_connections[request.sid]['is_deepgram_open'] = True\n                    logger.info(f"Deepgram connection started for user: {user_id} with language: {language}")\n                else:\n                    logger.error("Failed to start Deepgram connection")\n                    return False\n\n                # Emit success message with language confirmation\n                emit('connected', {\n                    'message': 'Successfully connected to audio streaming service',\n                    'user_id': user_id,\n                    'auth_type': auth_type,\n                    'language': language,  # Confirm language to client\n                    'timestamp': datetime.utcnow().isoformat()\n                }, namespace='/audio-stream')\n\n                return True\n\n            except Exception as e:\n                logger.error(f"Error initializing Deepgram connection: {e}")\n                emit('error', {\n                    'message': f'Failed to initialize transcription service: {str(e)}',\n                    'timestamp': datetime.utcnow().isoformat()\n                }, namespace='/audio-stream')\n                return False\n\n        except Exception as e:\n            logger.warning(f"Connection rejected: {str(e)}")\n            emit('error', {\n                'message': f'Connection rejected: {str(e)}',\n                'timestamp': datetime.utcnow().isoformat()\n            }, namespace='/audio-stream')\n            return False\n\n    @socketio.on('audio_chunk', namespace='/audio-stream')\n    def handle_audio_chunk(data):\n        """Handle incoming audio chunk for transcription."""\n        from flask import request\n\n        if request.sid not in active_connections:\n            logger.warning("Audio chunk received from unknown connection")\n            emit('error', {\n                'message': 'Connection not initialized',\n                'timestamp': datetime.utcnow().isoformat()\n            }, namespace='/audio-stream')\n            return\n\n        try:\n            connection_info = active_connections[request.sid]\n            dg_connection = connection_info['dg_connection']\n\n            # Extract audio data\n            audio_chunk = data.get('audio_chunk')\n            if not audio_chunk:\n                logger.warning("Empty audio chunk received")\n                return\n\n            # Decode Base64 audio data\n            try:\n                audio_bytes = base64.b64decode(audio_chunk)\n            except Exception as e:\n                logger.error(f"Failed to decode audio data: {e}")\n                emit('error', {\n                    'message': 'Invalid audio data format',\n                    'timestamp': datetime.utcnow().isoformat()\n                }, namespace='/audio-stream')\n                return\n\n            # Send to Deepgram\n            if connection_info.get('is_deepgram_open'):\n                dg_connection.send(audio_bytes)\n                logger.debug(f"Sent {len(audio_bytes)} bytes to Deepgram")\n            else:\n                logger.warning("Deepgram connection not open, cannot send audio")\n                emit('error', {\n                    'message': 'Transcription service not ready',\n                    'timestamp': datetime.utcnow().isoformat()\n                }, namespace='/audio-stream')\n\n        except Exception as e:\n            logger.error(f"Error processing audio chunk: {e}")\n            emit('error', {\n                'message': 'Error processing audio data',\n                'timestamp': datetime.utcnow().isoformat()\n            }, namespace='/audio-stream')\n\n    @socketio.on('stop_streaming', namespace='/audio-stream')\n    def handle_stop_streaming():\n        """Stop audio streaming and close Deepgram connection."""\n        from flask import request\n\n        if request.sid not in active_connections:\n            logger.warning("Stop streaming called for unknown connection")\n            return\n\n        try:\n            connection_info = active_connections[request.sid]\n            user_id = connection_info['user_id']\n\n            # Close Deepgram connection\n            dg_connection = connection_info['dg_connection']\n            if connection_info.get('is_deepgram_open'):\n                dg_connection.finish()\n                connection_info['is_deepgram_open'] = False\n\n            logger.info(f"Streaming stopped for user: {user_id}")\n\n            emit('streaming_stopped', {\n                'message': 'Streaming stopped successfully',\n                'timestamp': datetime.utcnow().isoformat()\n            }, namespace='/audio-stream')\n\n        except Exception as e:\n            logger.error(f"Error stopping streaming: {e}")\n\n    @socketio.on('disconnect', namespace='/audio-stream')\n    def handle_disconnect():\n        """Handle WebSocket disconnection and cleanup."""\n        from flask import request\n\n        if request.sid in active_connections:\n            connection_info = active_connections[request.sid]\n            user_id = connection_info['user_id']\n            try:\n                # Close Deepgram connection\n                dg_connection = connection_info['dg_connection']\n                if connection_info.get('is_deepgram_open'):\n                    dg_connection.finish()\n                    connection_info['is_deepgram_open'] = False\n                logger.info(f"WebSocket disconnected: user_id={user_id}")\n            except Exception as e:\n                logger.error(f"Error during disconnect cleanup: {e}")\n            finally:\n                # Always remove from active connections to prevent memory leaks\n                del active_connections[request.sid]\n",
"metadata": {
"lineCount": 381,
"sizeBytes": 14370,
"lastModified": "2026-01-17T15:07:11.190Z"
}
},
"models/user.py": {
"content": """"User model with API key support for authentication."""\n\nimport secrets\nimport hashlib\nfrom datetime import datetime, timedelta\nfrom . import db, bcrypt\n\nclass User(db.Model):\n    """User model for SaaS authentication."""\n    \n    tablename = 'users'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    email = db.Column(db.String(120), unique=True, nullable=False, index=True)\n    password_hash = db.Column(db.String(128), nullable=False)\n    \n    # Profile info\n    first_name = db.Column(db.String(50), nullable=True)\n    last_name = db.Column(db.String(50), nullable=True)\n    company = db.Column(db.String(100), nullable=True)\n    \n    # SaaS fields\n    plan = db.Column(db.String(20), default='free')  # free, pro, enterprise\n    is_active = db.Column(db.Boolean, default=True)\n    email_verified = db.Column(db.Boolean, default=False)\n    \n    # Timestamps\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    last_login = db.Column(db.DateTime, nullable=True)\n    \n    # Usage tracking\n    api_calls_month = db.Column(db.Integer, default=0)\n    audio_minutes_month = db.Column(db.Float, default=0.0)\n    \n    # Relationships\n    api_keys = db.relationship('ApiKey', backref='user', lazy=True, cascade='all, delete-orphan')\n    usage_logs = db.relationship('UsageLog', backref='user', lazy=True)\n    \n    def set_password(self, password):\n        """Set encrypted password."""\n        self.password_hash = bcrypt.generate_password_hash(password).decode('utf-8')\n    \n    def check_password(self, password):\n        """Check password against hash."""\n        return bcrypt.check_password_hash(self.password_hash, password)\n    \n    def generate_api_key(self, name="Default API Key"):\n        """Generate new API key for this user."""\n        # Format: usr<user_id><random_token>\n        random_token = secrets.token_urlsafe(32)\n        key_value = f"usr{self.id}{random_token}"\n        \n        # Hash for storage\n        key_hash = hashlib.sha256(key_value.encode()).hexdigest()\n        \n        api_key = ApiKey(\n            user_id=self.id,\n            name=name,\n            key_hash=key_hash,\n            key_prefix=f"usr_{self.id}"\n        )\n        \n        db.session.add(api_key)\n        db.session.commit()\n        \n        return key_value  # Return unhashed key only once\n    \n    def to_dict(self):\n        """Convert user to dictionary."""\n        return {\n            'id': self.id,\n            'email': self.email,\n            'first_name': self.first_name,\n            'last_name': self.last_name,\n            'company': self.company,\n            'plan': self.plan,\n            'is_active': self.is_active,\n            'email_verified': self.email_verified,\n            'created_at': self.created_at.isoformat() if self.created_at else None,\n            'last_login': self.last_login.isoformat() if self.last_login else None,\n            'api_calls_month': self.api_calls_month,\n            'audio_minutes_month': self.audio_minutes_month\n        }\n\n\nclass ApiKey(db.Model):\n    """API Keys for external integrations."""\n    \n    tablename = 'api_keys'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)\n    \n    name = db.Column(db.String(100), nullable=False)  # "Make.com Integration"\n    key_hash = db.Column(db.String(64), nullable=False, index=True)  # SHA256 hash\n    key_prefix = db.Column(db.String(20), nullable=False)  # usr_123 for display\n    \n    # Status\n    is_active = db.Column(db.Boolean, default=True)\n    \n    # Usage tracking\n    last_used = db.Column(db.DateTime, nullable=True)\n    usage_count = db.Column(db.Integer, default=0)\n    \n    # Security\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    expires_at = db.Column(db.DateTime, nullable=True)  # Optional expiration\n    \n    @staticmethod\n    def verify_key(key_value):\n        """Verify API key and return associated user."""\n        if not key_value or not key_value.startswith('usr_'):\n            return None\n        \n        # Hash the provided key\n        key_hash = hashlib.sha256(key_value.encode()).hexdigest()\n        \n        # Find active key\n        api_key = ApiKey.query.filter_by(\n            key_hash=key_hash,\n            is_active=True\n        ).first()\n        \n        if not api_key:\n            return None\n        \n        # Check expiration\n        if api_key.expires_at and api_key.expires_at < datetime.utcnow():\n            return None\n        \n        # Update usage\n        api_key.last_used = datetime.utcnow()\n        api_key.usage_count += 1\n        db.session.commit()\n        \n        return api_key.user\n    \n    def to_dict(self):\n        """Convert API key to dictionary (without sensitive data)."""\n        return {\n            'id': self.id,\n            'name': self.name,\n            'key_preview': f"{self.key_prefix}**",\n            'is_active': self.is_active,\n            'created_at': self.created_at.isoformat() if self.created_at else None,\n            'last_used': self.last_used.isoformat() if self.last_used else None,\n            'usage_count': self.usage_count,\n            'expires_at': self.expires_at.isoformat() if self.expires_at else None\n        }\n\n\nclass UsageLog(db.Model):\n    """Track API usage for billing."""\n    \n    tablename = 'usage_logs'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)\n    \n    # Service info\n    service = db.Column(db.String(50), nullable=False)  # 'deepgram', 'whisper', etc.\n    endpoint = db.Column(db.String(100), nullable=False)  # '/transcriptions/deepgram'\n    \n    # Usage data\n    audio_duration_seconds = db.Column(db.Float, nullable=True)\n    tokens_used = db.Column(db.Integer, nullable=True)\n    characters_processed = db.Column(db.Integer, nullable=True)\n    \n    # Cost tracking\n    cost_usd = db.Column(db.Float, nullable=True)\n    \n    # Metadata\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    ip_address = db.Column(db.String(45), nullable=True)\n    user_agent = db.Column(db.String(255), nullable=True)\n    \n    def to_dict(self):\n        """Convert usage log to dictionary."""\n        return {\n            'id': self.id,\n            'service': self.service,\n            'endpoint': self.endpoint,\n            'audio_duration_seconds': self.audio_duration_seconds,\n            'tokens_used': self.tokens_used,\n            'characters_processed': self.characters_processed,\n            'cost_usd': self.cost_usd,\n            'created_at': self.created_at.isoformat() if self.created_at else None,\n            'ip_address': self.ip_address\n        }",
"metadata": {
"lineCount": 189,
"sizeBytes": 6712,
"lastModified": "2025-12-04T21:15:05.260Z"
}
},
"utils/config.py": {
"content": """"Application configuration utilities."""\nfrom future import annotations\n\nfrom dataclasses import dataclass, field\nfrom functools import lru_cache\nfrom typing import Optional\nimport os\n\nfrom dotenv import load_dotenv\n\n\nload_dotenv()\n\n\n@dataclass(frozen=True)\nclass DeepgramSettings:\n    api_key: str\n    model: str = "nova-2"\n    language: str = "en"\n\n\n@dataclass(frozen=True)\nclass OpenAISettings:\n    api_key: str\n    model: str = "gpt-4o-mini"\n\n\n@dataclass(frozen=True)\nclass AssemblyAISettings:\n    api_key: str\n    upload_url: str = "https://api.assemblyai.com/v2/upload\"\n    transcript_url: str = "https://api.assemblyai.com/v2/transcript\"\n\n\n@dataclass(frozen=True)\nclass GoogleCloudSettings:\n    credentials_path: str\n\n\n@dataclass(frozen=True)\nclass AppConfig:\n    api_key: str\n    deepgram: DeepgramSettings\n    openai: OpenAISettings\n    assemblyai: Optional[AssemblyAISettings] = None\n    google_cloud: Optional[GoogleCloudSettings] = None\n    allowed_origins: tuple[str, ...] = field(default_factory=lambda: ("",))\n\n\n@lru_cache(maxsize=1)\ndef get_app_config() -> AppConfig:\n    missing = [\n        name\n        for name in ("API_KEY", "DEEPGRAM_API_KEY", "OPENAI_API_KEY")\n        if not os.getenv(name)\n    ]\n    if missing:\n        raise ValueError(\n            "Missing required environment variables: " + ", ".join(missing)\n        )\n\n    assemblyai_key = os.getenv("ASSEMBLYAI_API_KEY")\n    google_credentials = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")\n\n    return AppConfig(\n        api_key=os.environ["API_KEY"],\n        deepgram=DeepgramSettings(\n            api_key=os.environ["DEEPGRAM_API_KEY"],\n            model=os.getenv("DEEPGRAM_MODEL", "nova-2"),\n            language=os.getenv("DEEPGRAM_LANGUAGE", "en"),\n        ),\n        openai=OpenAISettings(\n            api_key=os.environ["OPENAI_API_KEY"],\n            model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),\n        ),\n        assemblyai=(\n            AssemblyAISettings(api_key=assemblyai_key)\n            if assemblyai_key\n            else None\n        ),\n        google_cloud=(\n            GoogleCloudSettings(credentials_path=google_credentials)\n            if google_credentials\n            else None\n        ),\n        allowed_origins=tuple(\n            origin.strip()\n            for origin in os.getenv("ALLOWED_ORIGINS", "").split(",")\n        ),\n    )\n",
"metadata": {
"lineCount": 91,
"sizeBytes": 2350,
"lastModified": "2025-10-15T22:46:17.782Z"
}
},
"utils/auth.py": {
"content": """"Authentication system with JWT and API Key support."""\n\nfrom functools import wraps\nfrom flask import request, jsonify, g, current_app\nimport logging\n\nlogger = logging.getLogger(name)\n\ndef require_auth(allow_api_key=True, allow_jwt=True):\n    """\n    Flexible authentication decorator that supports both JWT and API Key authentication.\n    \n    Args:\n        allow_api_key: Allow API key authentication (includes legacy support)\n        allow_jwt: Allow JWT authentication\n    """\n    def decorator(f):\n        @wraps(f)\n        def decorated_function(*args, **kwargs):\n            user = None\n            auth_method = None\n            \n            # Try JWT first (Bearer token)\n            if allow_jwt:\n                auth_header = request.headers.get('Authorization', '')\n                if auth_header.startswith('Bearer '):\n                    try:\n                        from flask_jwt_extended import verify_jwt_in_request, get_jwt_identity\n                        from models.user import User\n                        \n                        verify_jwt_in_request()\n                        user_id = get_jwt_identity()\n                        user = User.query.get(user_id)\n                        if user and user.is_active:\n                            auth_method = 'jwt'\n                            logger.info(f"JWT auth successful for user {user.id}")\n                    except Exception as e:\n                        logger.warning(f"JWT verification failed: {str(e)}")\n            \n            # Try API Key if JWT failed\n            if not user and allow_api_key:\n                api_key = request.headers.get('x-api-key')\n                if api_key:\n                    # Try new user API keys first\n                    from models.user import ApiKey\n                    user = ApiKey.verify_key(api_key)\n                    if user:\n                        auth_method = 'api_key'\n                        logger.info(f"API key auth successful for user {user.id}")\n                    else:\n                        # Legacy fallback (static API key)\n                        from utils.config import get_app_config\n                        if api_key == get_app_config().api_key:\n                            # Create temporary "system" user for legacy support\n                            user = type('LegacyUser', (), {\n                                'id': 0,\n                                'email': 'system@legacy.com',\n                                'plan': 'legacy',\n                                'is_active': True,\n                                'api_calls_month': 0,\n                                'audio_minutes_month': 0.0\n                            })()\n                            auth_method = 'legacy'\n                            logger.info("Legacy API key authentication")\n                        else:\n                            logger.warning(f"Invalid API key attempted")\n            \n            if not user:\n                return jsonify({'error': 'Authentication required'}), 401\n            \n            # Set user context for the request\n            g.current_user = user\n            g.auth_method = auth_method\n            \n            return f(*args, **kwargs)\n        \n        return decorated_function\n    return decorator\n\n# Legacy decorator for backward compatibility\ndef require_api_key(f):\n    """Legacy API key decorator - now supports both old and new API keys."""\n    return require_auth(allow_api_key=True, allow_jwt=False)(f)\n\ndef require_jwt(f):\n    """Require JWT authentication only."""\n    return require_auth(allow_api_key=False, allow_jwt=True)(f)\n\ndef require_any_auth(f):\n    """Allow both JWT and API key authentication."""\n    return require_auth(allow_api_key=True, allow_jwt=True)(f)\n\ndef log_usage(service, endpoint, **kwargs):\n    """Log API usage for billing purposes."""\n    try:\n        from models.user import UsageLog\n        from models import db\n        \n        if hasattr(g, 'current_user') and g.current_user.id != 0:  # Skip legacy user\n            usage_log = UsageLog(\n                user_id=g.current_user.id,\n                service=service,\n                endpoint=endpoint,\n                audio_duration_seconds=kwargs.get('audio_duration'),\n                tokens_used=kwargs.get('tokens_used'),\n                characters_processed=kwargs.get('characters_processed'),\n                cost_usd=kwargs.get('cost_usd'),\n                ip_address=request.remote_addr,\n                user_agent=request.headers.get('User-Agent', '')\n            )\n            \n            db.session.add(usage_log)\n            db.session.commit()\n            \n            logger.info(f"Usage logged for user {g.current_user.id}: {service}/{endpoint}")\n    except Exception as e:\n        logger.error(f"Failed to log usage: {str(e)}")\n",
"metadata": {
"lineCount": 118,
"sizeBytes": 4821,
"lastModified": "2025-12-04T21:15:05.272Z"
}
},
"utils/exceptions.py": {
"content": """"Custom exception classes used across the service."""\n\n\nclass ServiceError(RuntimeError):\n    """Base class for domain-specific exceptions."""\n\n\nclass TranscriptionError(ServiceError):\n    """Raised when audio transcription fails."""\n\n\nclass TranslationError(ServiceError):\n    """Raised when translation fails."""\n\n\nclass InvalidRequestError(ServiceError):\n    """Raised when request validation fails."""\n\n\nclass ProcessingError(ServiceError):\n    """Raised when video/audio processing fails."""\n",
"metadata": {
"lineCount": 22,
"sizeBytes": 499,
"lastModified": "2025-10-23T20:06:54.241Z"
}
}
}
}

Bash Check for deployment configuration files
IN
ls -la | grep -E "(wsgi|gunicorn|Procfile|render|requirements)"

OUT
-rw-rw-r--  1 msiddi msiddi    81 Jan 17 16:07 Procfile
-rw-r--r--  1 msiddi msiddi     0 Dec  5 09:36 gunicorn_access.log
-rw-r--r--  1 msiddi msiddi     0 Dec  5 09:36 gunicorn_error.log
-rw-r--r--  1 msiddi msiddi   180 Dec  5 09:38 gunicorn_prod_access.log
-rw-r--r--  1 msiddi msiddi   514 Dec  5 09:41 gunicorn_prod_error.log
-rw-rw-r--  1 msiddi msiddi  1158 Jan 17 16:07 render.yaml
-rw-rw-r--  1 msiddi msiddi  1412 Jan 17 16:07 requirements.txt
-rw-rw-r--  1 msiddi msiddi   312 Jan 17 16:07 wsgi.py
Read wsgi.py
Read requirements.txt
Read Procfile
Read render.yaml
Update Todos

Explore codebase structure and key files

Generate docs/architecture.md

Generate docs/deployment_render.md

Generate docs/runbook.md

Generate docs/security-hardening-todo.md

Identify minimal missing information questions
Perfect! I have thoroughly explored the codebase. Now I'll generate the four comprehensive documentation files.

1. docs/architecture.md

# Architecture Documentation

## Overview

Audio Transcription API is a Flask-based microservice providing multi-provider audio/video transcription, translation, and post-processing capabilities. The system is designed for deployment on Render with PostgreSQL persistence, real-time WebSocket streaming (via Deepgram + SocketIO), and flexible authentication (Auth0 JWT, API keys, legacy session tokens).

**Core Technologies:**
- **Runtime:** Python 3.12
- **Web Framework:** Flask 3.1.0 (application factory pattern)
- **WebSocket:** Flask-SocketIO 5.4.1 with eventlet async mode
- **Database:** PostgreSQL via SQLAlchemy
- **Authentication:** Auth0 (RS256 JWT), Flask-JWT-Extended, API keys (SHA256-hashed), optional session tokens
- **AI Services:** Deepgram (Nova-2 real-time), OpenAI (Whisper, GPT-4o-mini), AssemblyAI, Google Translate, DeepSeek

---

## High-Level Architecture Diagram (Text-Based)

┌─────────────────────────────────────────────────────────────────┐
│                         ENTRY POINTS                             │
├─────────────────────────────────────────────────────────────────┤
│  app.py (dev)  │  wsgi.py (prod - gunicorn eventlet worker)     │
└────────┬────────────────────────────────────────────────────────┘
│
▼
┌─────────────────────────────────────────────────────────────────┐
│            APPLICATION FACTORY (flask_app/init.py)           │
│  • create_app() → (Flask app, SocketIO instance)                │
│  • Configuration loading (utils/config.py)                       │
│  • Database initialization (PostgreSQL + SQLAlchemy)             │
│  • Blueprint registration (REST APIs)                            │
│  • WebSocket handler registration (SocketIO events)             │
│  • Error handler setup (global + Auth0)                         │
│  • CORS configuration (Flask-CORS)                              │
└────────┬────────────────────────────────────────────────────────┘
│
├─────────────────────────────────────────────────────────┐
│                                                         │
▼                                                         ▼
┌──────────────────────┐                               ┌─────────────────────┐
│   REST API LAYER     │                               │  WEBSOCKET LAYER    │
│   (Blueprints)       │                               │  (SocketIO)         │
├──────────────────────┤                               ├─────────────────────┤
│ • /health            │                               │ Namespace:          │
│ • /                  │                               │ /audio-stream       │
│ • /transcriptions    │                               │                     │
│   - /deepgram        │                               │ Events:             │
│   - /whisper         │                               │ • connect           │
│   - /assemblyai      │                               │ • audio_chunk       │
│   - /video           │                               │ • stop_streaming    │
│   - /transcribe-     │                               │ • disconnect        │
│     and-translate    │                               │                     │
│ • /translations      │                               │ Handlers:           │
│   - /openai          │                               │ • audio_stream_     │
│   - /google          │                               │   auth0.py          │
│   - /deepseek        │                               │   (Auth0 JWT +      │
│ • /sentiment         │                               │    fallback session)│
│ • /documents/{fmt}   │                               │ • audio_stream.py   │
│ • /reports/{fmt}     │                               │   (session-only,    │
│ • /utilities         │                               │    deprecated)      │
│   - /audio-duration  │                               └─────────────────────┘
│   - /log-usage       │
│   - /text-file       │
│ • /auth              │
│   (web auth, main)   │
│ • /mobile-auth       │
│   (session, INSECURE)│
│ • /api/me, /api/     │
│   userinfo (Auth0)   │
└──────┬───────────────┘
│
▼
┌──────────────────────────────────────────────────────────────────┐
│                   AUTHENTICATION MIDDLEWARE                       │
├──────────────────────────────────────────────────────────────────┤
│ 1. Auth0 JWT (RS256) - Primary for production                    │
│    • Decorator: @require_auth (flask_app/auth/auth0.py)          │
│    • Validates: issuer, audience, signature, expiry              │
│    • JWKS caching via PyJWKClient                                │
│    • Sets: request.user, request.user_id, g.user                 │
│                                                                   │
│ 2. API Keys (SHA256-hashed)                                      │
│    • Header: x-api-key                                           │
│    • User API keys (models/user.py:ApiKey)                       │
│    • Legacy static key fallback (utils/config.py:API_KEY)        │
│    • Decorator: @require_api_key, @require_any_auth              │
│                                                                   │
│ 3. Session Tokens (DEPRECATED - dev/test ONLY)                   │
│    • Flag: ALLOW_INSECURE_SESSION_AUTH=true (MUST be false prod) │
│    • Endpoint: /mobile-auth/login (NO PASSWORD VALIDATION!)      │
│    • Used by: flask_app/sockets/audio_stream.py                  │
│    • Security Risk: Tokens generated without credential check    │
└──────┬───────────────────────────────────────────────────────────┘
│
▼
┌──────────────────────────────────────────────────────────────────┐
│                      SERVICE LAYER                                │
├──────────────────────────────────────────────────────────────────┤
│ flask_app/services/                                               │
│  • transcription.py                                               │
│    - DeepgramService (Nova-2, diarization, paragraphs)           │
│    - WhisperService (auto-chunking for large files)              │
│    - AssemblyAIService                                            │
│  • translation.py                                                 │
│    - OpenAITranslationService (GPT chunking)                     │
│    - GoogleTranslationService                                    │
│    - DeepSeekTranslationService (webhook integration)            │
│  • video_transcription.py                                        │
│    - VideoTranscriptionService (YouTube URLs + file uploads)     │
│    - Uses: yt-dlp for download, openai-whisper for transcription │
│  • postprocessing.py                                              │
│    - SentimentService (placeholder)                              │
│    - DocumentService (Word/PDF/Excel generation - placeholders)  │
│  • session_manager.py (to confirm)                               │
│    - Session token CRUD for deprecated mobile auth               │
└──────┬───────────────────────────────────────────────────────────┘
│
▼
┌──────────────────────────────────────────────────────────────────┐
│                      CLIENT LAYER                                 │
├──────────────────────────────────────────────────────────────────┤
│ flask_app/clients/                                                │
│  • deepgram.py - Deepgram SDK wrapper                            │
│  • openai.py - OpenAI SDK (Whisper + GPT translation)            │
│  • assemblyai.py - AssemblyAI SDK wrapper                        │
│  • google.py - Google Cloud Translate client                     │
│  • deepseek.py - DeepSeek API client                             │
│  • video_processor.py - yt-dlp + Whisper integration             │
└──────┬───────────────────────────────────────────────────────────┘
│
▼
┌──────────────────────────────────────────────────────────────────┐
│                    PERSISTENCE LAYER                              │
├──────────────────────────────────────────────────────────────────┤
│ PostgreSQL Database (SQLAlchemy ORM)                              │
│                                                                   │
│ models/user.py:                                                   │
│  • User                                                           │
│    - Credentials (email, password_hash via bcrypt)               │
│    - Profile (first_name, last_name, company)                    │
│    - Plan (free/pro/enterprise)                                  │
│    - Usage tracking (api_calls_month, audio_minutes_month)       │
│  • ApiKey                                                         │
│    - key_hash (SHA256), key_prefix (for display)                 │
│    - Metadata (name, last_used, usage_count, expires_at)         │
│  • UsageLog                                                       │
│    - Per-request billing tracking (service, endpoint, costs)     │
│    - Dimensions: audio_duration_seconds, tokens_used, cost_usd   │
└──────────────────────────────────────────────────────────────────┘



---

## Module Boundaries and Responsibilities

### 1. **core/ (Compatibility Shim)**
**Purpose:** Transition layer to remap `import core` → `import flask_app`  
**Mechanism:** `core/__init__.py` sets `__path__ = [flask_app_directory]`  
**Status:** Temporary migration shim. All actual code lives in `flask_app/`.  
**DO NOT add new code to core/** - it's an import redirect only.

### 2. **flask_app/ (Main Application Package)**

#### **flask_app/__init__.py**
- **Application factory:** `create_app(config_override=None) -> (Flask, SocketIO)`
- **Responsibilities:**
  - Load configuration via `utils.config.get_app_config()`
  - Initialize database (SQLAlchemy + create_all)
  - Register blueprints with fallback logic (tries multiple auth variants)
  - Register SocketIO handlers (prefers Auth0 → falls back to session-based)
  - Setup CORS (origins: localhost:3000)
  - Register global error handlers (400/401/404/500, custom exceptions)

#### **flask_app/api/ (REST Blueprints)**
| Blueprint | URL Prefix | Auth Required | Purpose |
|-----------|------------|---------------|---------|
| health | / | No | Health checks, service metadata |
| transcription | /transcriptions | Yes (@require_any_auth) | Audio/video → text (Deepgram/Whisper/AssemblyAI) |
| translation | /translations | Yes (@require_api_key) | Text translation (OpenAI/Google/DeepSeek) |
| postprocessing | / | Yes (@require_api_key) | Sentiment, document/report generation |
| utilities | /utilities | Yes (@require_api_key) | Audio duration calc, usage logging, file creation |
| web_auth (api/auth.py) | /auth | Varies | User registration, login, API key management (JWT-based) |
| mobile_auth (flask_app/api/auth.py) | /mobile-auth | No (INSECURE) | **DEPRECATED** session token login (no password check!) |
| protected (flask_app/api/protected.py) | /api | Yes (@require_auth Auth0) | Auth0 user info endpoints (/api/me, /api/userinfo) |

**Error Handling:**
- Blueprint-specific: `@bp.errorhandler(BadRequest)` → JSON response
- Global: Registered in `register_error_handlers()` for TranscriptionError, TranslationError, HTTPException

#### **flask_app/services/ (Business Logic)**
- **Encapsulates external API calls** (AI providers)
- **Handles complexity:** chunking large files (Whisper), diarization (Deepgram), webhook forwarding (DeepSeek)
- **Error translation:** Wraps provider exceptions → `TranscriptionError`/`TranslationError`
- **Temporary file management:** Creates/cleans temp files for audio processing

#### **flask_app/clients/ (External API Wrappers)**
- **Thin SDK wrappers** around provider APIs
- **Configuration injection** from `utils.config.get_app_config()`
- **No business logic** - pure I/O adapters

#### **flask_app/auth/ (Auth0 Integration)**
- **auth0.py:** JWT verification (RS256, JWKS caching), `@require_auth` decorator, `verify_websocket_token()`
- **Security features:**
  - PyJWKClient caching (avoids repeated JWKS downloads)
  - Token validation: issuer, audience, signature, expiry
  - `ALLOW_INSECURE_SESSION_AUTH` flag (blocks deprecated endpoints in prod)

#### **flask_app/sockets/ (WebSocket Handlers)**
| Handler | Auth Method | Language Selection | Status |
|---------|-------------|-------------------|--------|
| audio_stream_auth0.py | Auth0 JWT + session fallback | Query param: `?lang=it` (30+ languages) | **Active, preferred** |
| audio_stream.py | Session tokens only | Hardcoded Italian (`language="it"`) | **Deprecated** |

**WebSocket Flow (audio_stream_auth0.py):**
1. **connect:** Authenticate via `auth={'token': '...'}` → validate Auth0 JWT → fallback to session if `ALLOW_INSECURE_SESSION_AUTH=true`
2. **Initialize Deepgram:** Create live connection with Nova-2 model, dynamic language (from `?lang=` query param, default `en`)
3. **audio_chunk:** Base64-decode audio → send to Deepgram live stream
4. **Deepgram callbacks:** `on_message` → emit `transcription` event with transcript, is_final, confidence
5. **stop_streaming / disconnect:** Close Deepgram connection, cleanup active_connections dict

### 3. **models/ (Database Schema)**
- **models/__init__.py:** Exports `db` (SQLAlchemy), `bcrypt`, `init_db(app)`
- **models/user.py:** User, ApiKey, UsageLog models (see Persistence Layer diagram)

### 4. **utils/ (Shared Utilities)**
- **config.py:** `get_app_config()` - loads env vars, frozen dataclasses (DeepgramSettings, OpenAISettings, etc.)
- **auth.py:** `@require_auth`, `@require_api_key`, `@require_jwt`, `@require_any_auth` decorators + usage logging
- **exceptions.py:** Custom exceptions (TranscriptionError, TranslationError, InvalidRequestError, ProcessingError)
- **logging.py:** (to confirm) Centralized logging configuration

### 5. **api/ (Top-Level Web Auth Blueprint)**
- **api/auth.py:** User registration, login, profile, API key CRUD (uses Flask-JWT-Extended)
- **Security:** Password validation (8+ chars, letter+number), email validation
- **Mounted at:** `/auth` (separate from `/mobile-auth`)

---

## Request Flows

### REST Flow: Transcription Request (Deepgram)
Client → POST /transcriptions/deepgram
Headers: x-api-key: usr_123_xyz OR Authorization: Bearer <JWT>
Body: multipart/form-data {audio: file, language: 'en', diarize: 'true'}

Flask routing → transcription_bp.deepgram_transcription()

Authentication:
@require_any_auth decorator
→ Try JWT first (via @require_auth logic in utils/auth.py)
→ Fallback to API key (models/user.py:ApiKey.verify_key())
→ If valid: set g.current_user, g.auth_method

Service Layer:
DeepgramService().transcribe(audio_file, language='en', diarize=True)
→ Save to temp file
→ Read file bytes
→ DeepgramClient.transcribe(audio_data, model='nova-2', diarize=True)
→ Parse response (transcript + diarization metadata)
→ Return {transcript, diarization: {speakers_detected: 2, ...}, processing_info}

Response:
200 OK {transcript: "...", diarization: {...}, processing_info: {...}}

Usage Logging:
log_usage(service='deepgram', endpoint='/transcriptions/deepgram', audio_duration=120)
→ UsageLog entry created in PostgreSQL



### WebSocket Flow: Real-Time Audio Streaming
Client connects to wss://<host>/audio-stream?lang=it
Auth: {token: '<Auth0 JWT or session token>'}

SocketIO → handle_connect(auth)
→ authenticate_websocket(auth)
→ Try verify_websocket_token(token) [Auth0 JWT]
→ Fallback: is_valid_session(token) if ALLOW_INSECURE_SESSION_AUTH=true
→ Extract language from request.args.get('lang', 'en')
→ Validate language against SUPPORTED_LANGUAGES (30+ langs)

Initialize Deepgram:
→ DeepgramClient(api_key).listen.live.v("1")
→ Register event handlers:
• on_message → emit('transcription', {transcript, is_final, confidence})
• on_error → emit('error', {message})
→ Start with LiveOptions(model='nova-2', language='it', interim_results=True)

Store connection:
active_connections[request.sid] = {
user_id, auth_type, dg_connection, language, is_deepgram_open
}

Client sends audio chunks:
emit('audio_chunk', {audio_chunk: '<base64_audio>'})
→ handle_audio_chunk(data)
→ base64.b64decode(audio_chunk)
→ dg_connection.send(audio_bytes)

Deepgram streams back transcripts:
on_message callback → emit('transcription', {transcript: "Ciao mondo", is_final: true})

Client stops:
emit('stop_streaming') → dg_connection.finish()
OR disconnect → cleanup active_connections



---

## Configuration Sources

### Environment Variables (Required)
| Variable | Purpose | Default | Validation |
|----------|---------|---------|------------|
| `API_KEY` | Legacy static API key | None | Required (utils/config.py) |
| `DEEPGRAM_API_KEY` | Deepgram SDK auth | None | Required |
| `OPENAI_API_KEY` | OpenAI SDK (Whisper, GPT) | None | Required |
| `ASSEMBLYAI_API_KEY` | AssemblyAI SDK | None | Optional |
| `GOOGLE_APPLICATION_CREDENTIALS` | Path to GCP service account JSON | None | Optional (for Google Translate) |
| `DATABASE_URL` | PostgreSQL connection string | `postgresql://postgres:postgres@localhost:5432/mydb` | Required for prod |
| `JWT_SECRET_KEY` | Flask-JWT-Extended signing | `your-jwt-secret-key-change-in-production` | **MUST change in prod** |
| `SECRET_KEY` | Flask session secret | `your-secret-key-change-in-production` | **MUST change in prod** |
| `AUTH0_DOMAIN` | Auth0 tenant domain | None | Required for Auth0 features |
| `AUTH0_AUDIENCE` | Auth0 API identifier | None | Required for Auth0 JWT validation |
| `AUTH0_REQUEST_TIMEOUT` | Timeout for Auth0 API calls (seconds) | `30` | Optional |
| `ALLOW_INSECURE_SESSION_AUTH` | Enable deprecated session auth | `false` | **MUST be `false` in production** |
| `PORT` | HTTP bind port | `5000` | Auto-set by Render |
| `FLASK_ENV` | Environment (development/production) | development | Controls debug mode |
| `CORS_ORIGINS` / `ALLOWED_ORIGINS` | CORS allowed origins (comma-separated) | `*` | Tighten in prod |
| `LOG_LEVEL` | Logging verbosity | INFO | Optional |

### Configuration Loading Precedence
1. **Environment variables** (via `os.getenv()`)
2. **.env file** (via `python-dotenv` - for local dev)
3. **Hardcoded defaults** (in `utils/config.py` dataclasses)

### Render-Specific (render.yaml)
- `PORT`: Injected by Render platform (binds to 0.0.0.0:$PORT)
- `AUTH0_DOMAIN`, `DEEPGRAM_API_KEY`: Marked `sync: false` (manual secret entry in Render dashboard)
- `JWT_SECRET_KEY`: `generateValue: true` (Render auto-generates on first deploy)

---

## Key Architectural Decisions

### Why Application Factory Pattern?
- **Testability:** Can create isolated app instances with `config_override`
- **Blueprint isolation:** Each API module is independently mountable
- **Deferred initialization:** Database, SocketIO, blueprints registered post-construction

### Why core/ Shim?
- **Migration in progress:** Transitioning from `flask_app` to `core` namespace
- **Backward compatibility:** Existing imports `from core import X` work without mass refactor
- **Temporary solution:** DO NOT add new code to `core/`

### Why Multiple Auth Methods?
- **Auth0 (primary):** Enterprise-grade for production web/mobile apps
- **API Keys:** External integrations (Make.com, webhooks, scripts)
- **Session Tokens (deprecated):** Legacy mobile app support - **REMOVE IN FUTURE**

### Why Eventlet for SocketIO?
- **Real-time requirement:** Deepgram live streaming needs persistent WebSocket connections
- **Gunicorn compatibility:** `-k eventlet` worker class required (not default sync workers)
- **Single worker:** `-w 1` to avoid connection state issues across workers

### Why Dual WebSocket Handlers?
- **Graceful migration:** `audio_stream_auth0.py` adds Auth0 support while maintaining fallback
- **Feature parity:** Both support Deepgram live streaming
- **Deprecation path:** `audio_stream.py` will be removed when mobile app migrates to Auth0

---

## Observability Hooks

### Logging
- **Framework:** Python `logging` module
- **Levels:** INFO (default), DEBUG (verbose), WARNING (auth failures), ERROR (exceptions)
- **Key log points:**
  - Authentication decisions (JWT success/fail, API key verification)
  - WebSocket lifecycle (connect, disconnect, Deepgram errors)
  - Service calls (transcription start/complete, external API failures)
  - Usage tracking (logged to database + stdout)

### Health Check
- **Endpoint:** `GET /health`
- **Response:** `{"status": "healthy", "service": "Audio Transcription API", "version": "1.0.0"}`
- **Used by:** Render health monitoring (render.yaml: `healthCheckPath: /health`)

### Usage Tracking
- **Database:** `UsageLog` table records per-request metrics
- **Fields:** service, endpoint, audio_duration_seconds, tokens_used, cost_usd, timestamp
- **Trigger:** `utils.auth.log_usage()` called by decorators when `g.current_user` exists

---

## Deployment Architecture (Render)

┌────────────────────────────────────────────────────────────┐
│                    Render Platform                          │
├────────────────────────────────────────────────────────────┤
│  Web Service: audio-transcription-api                       │
│  Region: Oregon                                             │
│  Plan: Starter                                              │
│  Runtime: python                                            │
│                                                             │
│  Build:                                                     │
│    pip install -r requirements.txt                          │
│                                                             │
│  Start:                                                     │
│    gunicorn -k eventlet -w 1 wsgi:application \             │
│      --bind 0.0.0.0:$PORT \                                 │
│      --log-level info \                                     │
│      --access-logfile - \                                   │
│      --error-logfile -                                      │
│                                                             │
│  Health Check: /health (every 30s)                          │
│                                                             │
│  Auto-Deploy: main branch (on git push)                     │
└────────────────────────────────────────────────────────────┘
│
▼
┌────────────────────────────────────────────────────────────┐
│              External Dependencies                          │
├────────────────────────────────────────────────────────────┤
│  • PostgreSQL Database (Render managed or external)         │
│  • Auth0 (auth0.com) - JWT issuer                          │
│  • Deepgram API (deepgram.com) - Transcription             │
│  • OpenAI API (openai.com) - Whisper, GPT                  │
│  • AssemblyAI API (assemblyai.com) - Optional              │
│  • Google Cloud Translate API - Optional                   │
│  • DeepSeek API - Optional                                 │
│  • External webhooks (Make.com) - For DeepSeek integration │
└────────────────────────────────────────────────────────────┘



---

## Security Notes

1. **JWT Secret Rotation:** `JWT_SECRET_KEY` is static post-deployment. Rotate manually if leaked (requires env var update + restart).
2. **CORS Origins:** Currently allows `localhost:3000` + production frontend. Tighten in prod via `CORS_ORIGINS` env var.
3. **Database Credentials:** `DATABASE_URL` must use SSL in production (PostgreSQL `?sslmode=require`).
4. **Session Token Risk:** `ALLOW_INSECURE_SESSION_AUTH=true` bypasses authentication. NEVER enable in prod.
5. **API Key Storage:** User API keys are SHA256-hashed. Plaintext key shown ONCE on generation.
6. **Auth0 JWKS Caching:** PyJWKClient caches public keys locally (avoids JWKS endpoint hammering).

---

## Future Considerations

1. **Remove core/ shim:** Complete migration to direct `flask_app` imports.
2. **Deprecate session auth:** Remove `flask_app/api/auth.py` (mobile-auth) and `audio_stream.py` after mobile app migrates to Auth0.
3. **Rate limiting:** Add per-user API throttling (via Flask-Limiter or Redis).
4. **Metrics:** Export Prometheus metrics (request counts, latency, Deepgram usage).
5. **Database migrations:** Implement Alembic/Flask-Migrate for schema versioning (currently using `db.create_all()`).
6. **Postprocessing placeholders:** Implement real sentiment analysis, document generation (currently stubs).
Update Todos

Explore codebase structure and key files

Generate docs/architecture.md

Generate docs/deployment_render.md

Generate docs/runbook.md

Generate docs/security-hardening-todo.md

Identify minimal missing information questions
2. docs/deployment_render.md

# Render Deployment Guide

## Overview

This Flask application is designed for deployment on Render.com as a **Web Service** with PostgreSQL persistence, WebSocket support, and integration with external AI services. The application uses **gunicorn with eventlet workers** to support real-time SocketIO connections.

---

## Boot Process on Render

### 1. **Build Phase**
```bash
# Executed by: render.yaml buildCommand
pip install -r requirements.txt
Dependencies Installed (key packages):

Flask 3.1.0 + Flask-SocketIO 5.4.1
gunicorn 23.0.0 + eventlet 0.36.1 (WebSocket support)
deepgram-sdk 3.10.0 (real-time transcription)
openai 1.61.1 (Whisper, GPT)
PostgreSQL driver: psycopg2-binary 2.9.9
Auth: PyJWT[crypto] 2.10.1, Flask-JWT-Extended 4.6.0
Video processing: yt-dlp 2024.11.4, openai-whisper 20240930
Build Notes:

Requirements duplicated lines 1-32 and 33-64 (cleanup recommended but non-blocking)
Heavy dependencies: transformers (4.48.1), pandas (2.2.3) - expect 2-3 min build time
ffmpeg required for video processing (Render provides in base image)
2. Start Phase

# Executed by: render.yaml startCommand
gunicorn -k eventlet -w 1 wsgi:application \
  --bind 0.0.0.0:$PORT \
  --log-level info \
  --access-logfile - \
  --error-logfile -
Startup Sequence:

gunicorn loads wsgi.py
wsgi.py imports from core import create_app (→ redirects to flask_app/__init__.py)
create_app() executes:
Load config from env vars (utils/config.py:get_app_config())
Initialize PostgreSQL connection (SQLAlchemy)
Create database tables (db.create_all() if not exist)
Register REST blueprints (health, transcriptions, translations, etc.)
Register SocketIO handlers (prefers audio_stream_auth0.py → falls back to audio_stream.py)
Setup CORS for allowed origins
Register error handlers (global + Auth0)
SocketIO initialized with eventlet async_mode
Application exported as wsgi:application for gunicorn
Gunicorn binds to 0.0.0.0:$PORT (PORT injected by Render)
Health check endpoint /health becomes available
Critical Worker Configuration:

-k eventlet: REQUIRED for WebSocket support (default sync workers will fail)
-w 1: Single worker to avoid connection state issues (SocketIO active_connections dict is in-memory)
Scaling: For high load, use Redis-based SocketIO message queue (not currently implemented)
3. Health Monitoring

# render.yaml configuration
healthCheckPath: /health
Health Check Behavior:

Endpoint: GET /health
Response: {"status": "healthy", "service": "Audio Transcription API", "version": "1.0.0"}
Frequency: Every 30 seconds (Render default)
Failure threshold: 3 consecutive failures → container restart
Startup grace period: 60 seconds before health checks begin
What Render Monitors:

HTTP 200 response from /health
Response time < 30s
If database connection fails during startup, app may start but fail on first API call (health endpoint does NOT test DB connectivity)
Required Environment Variables
Secrets (Must Configure in Render Dashboard)
Variable	Purpose	How to Set	Validation
AUTH0_DOMAIN	Auth0 tenant (e.g., yourapp.us.auth0.com)	Render Dashboard → Environment	Required for Auth0 JWT validation. Missing = 500 on protected routes.
AUTH0_AUDIENCE	Auth0 API identifier (e.g., https://api.yourapp.com)	Render Dashboard → Environment	Required for JWT audience claim validation.
DEEPGRAM_API_KEY	Deepgram API key for transcription	Render Dashboard → Environment (sync: false in render.yaml)	Required. Missing = TranscriptionError on /transcriptions/deepgram.
OPENAI_API_KEY	OpenAI API key (Whisper, GPT)	Render Dashboard → Environment	Required. Missing = config load failure at startup.
DATABASE_URL	PostgreSQL connection string	Auto-injected if using Render PostgreSQL service	Required for production. Format: postgresql://user:pass@host:5432/dbname?sslmode=require
JWT_SECRET_KEY	Flask-JWT-Extended signing key	generateValue: true in render.yaml (auto-generated)	Auto-generated on first deploy. Rotate manually if compromised.
SECRET_KEY	Flask session secret	Manual entry	Must set manually. Default is insecure placeholder.
Optional Secrets
Variable	Purpose	Default if Missing
ASSEMBLYAI_API_KEY	AssemblyAI transcription	AssemblyAI endpoints will fail (graceful degradation)
GOOGLE_APPLICATION_CREDENTIALS	Path to GCP service account JSON	Google Translate will fail. Set to /opt/render/project/src/google/google-credentials.json if using.
Configuration Variables (Set in render.yaml)
Variable	Value in render.yaml	Purpose
FLASK_ENV	production	Disables debug mode, uses production error handling
FLASK_APP	app.py	Entry point hint (not critical for gunicorn)
AUTH0_REQUEST_TIMEOUT	30	Timeout for Auth0 userinfo API calls (seconds)
ALLOW_INSECURE_SESSION_AUTH	false	CRITICAL SECURITY: Blocks deprecated /mobile-auth endpoints. NEVER set to true in production.
CORS_ORIGINS	https://meeting-streamer.vercel.app/	CORS allowed origins (comma-separated)
LOG_LEVEL	INFO	Logging verbosity (DEBUG/INFO/WARNING/ERROR)
PORT	(Auto-injected by Render)	HTTP bind port
Runtime Dependencies
External Services (Required)
PostgreSQL Database

How to connect:
Option A: Render managed PostgreSQL (auto-injects DATABASE_URL)
Option B: External database (set DATABASE_URL manually with SSL: ?sslmode=require)
Schema initialization:
Tables auto-created on first boot via db.create_all() in flask_app/__init__.py:init_database()
Manual migration script: scripts/init_db.py (to confirm existence)
Failure mode: If DB unreachable, app starts but all authenticated endpoints return 500 (SQLAlchemy connection errors)
Auth0 (auth0.com)

Required for:
Protected routes: /api/me, /api/userinfo, /api/protected/test
WebSocket connections (when audio_stream_auth0.py is active)
Configuration: Set AUTH0_DOMAIN, AUTH0_AUDIENCE in Render dashboard
JWKS endpoint: https://{AUTH0_DOMAIN}/.well-known/jwks.json (must be publicly accessible)
Failure mode:
Missing env vars → 500 on protected routes
Auth0 down → JWT validation fails with "Token verification failed" (401)
Caching: PyJWKClient caches JWKS keys locally (reduces Auth0 API calls)
Deepgram API (deepgram.com)

Required for:
/transcriptions/deepgram
WebSocket real-time transcription (/audio-stream)
API key: Set DEEPGRAM_API_KEY (no default)
Failure mode: Missing key → TranscriptionError on endpoint calls
OpenAI API (openai.com)

Required for:
/transcriptions/whisper
/translations/openai
Video transcription (whisper model)
API key: Set OPENAI_API_KEY (no default)
Failure mode: Missing key → config load failure at startup (app won't boot)
External Services (Optional)
Service	Used By	Failure Impact
AssemblyAI	/transcriptions/assemblyai	Endpoint returns 500 if key missing
Google Cloud Translate	/translations/google	Endpoint returns 500 if credentials missing
DeepSeek API	/translations/deepseek	Endpoint returns 500 if API unreachable
Make.com Webhooks	DeepSeek translation forwarding	Silent failure (logs error, returns success to client)
Google Sheets API	/utilities/log-usage (billing tracking)	Silent failure (logs warning, continues without logging)
System Dependencies (Provided by Render)
Python 3.12 (specified in runtime or Render default)
ffmpeg (for audio/video processing via pydub, yt-dlp, whisper)
System packages: Already available in Render's Python base image
Logs and Observability
Log Destinations

# render.yaml: Logs streamed to stdout/stderr
--access-logfile -   # HTTP access logs → stdout
--error-logfile -    # Errors → stderr
Render Logging:

Access: Render Dashboard → Logs tab (real-time stream)
Retention: Last 7 days (Starter plan - to confirm)
Search: Limited to Render UI (no full-text search)
What to Monitor
Log Pattern	Meaning	Action
Token verified successfully for user: auth0|123	Auth0 JWT auth success	Normal
JWT verification failed: Token has expired	Expired token	Client needs to refresh token
⚠️ SECURITY WARNING: ALLOW_INSECURE_SESSION_AUTH is enabled	Insecure auth enabled	FIX IMMEDIATELY (set to false)
WebSocket connected: user_id=X, auth_type=auth0	SocketIO connection established	Normal
Deepgram error: ...	Transcription service failure	Check Deepgram API status, key validity
Database initialization failed: ...	DB connection error at startup	Check DATABASE_URL, PostgreSQL status
Connection rejected: Invalid or expired authentication token	WebSocket auth failure	Client needs valid Auth0 token
Health check requested	Render health ping	Normal (every 30s)
Error Logging
Application errors: Logged via Python logging module (level: INFO default)
Gunicorn errors: Startup failures, worker crashes logged to stderr
Database errors: SQLAlchemy exceptions logged with full traceback
Usage Tracking
Database: UsageLog table records per-request metrics (user_id, service, endpoint, duration, cost)
Query: SELECT * FROM usage_logs WHERE user_id = X ORDER BY created_at DESC;
Billing: Aggregate by month: SELECT SUM(cost_usd) FROM usage_logs WHERE user_id = X AND created_at > '2025-01-01';
Deployment Workflow
Automated Deploy (Git Push)

git push origin main
Render Workflow:

Detects push to main branch (autoDeploy: true)
Clones repository
Runs buildCommand: pip install -r requirements.txt
Runs startCommand: gunicorn -k eventlet ...
Health check at /health (60s grace period)
If healthy → routes traffic to new container
Old container drained and shut down
Rollback Strategy (see next section)

Manual Deploy
Render Dashboard → Services → audio-transcription-api → Manual Deploy → Deploy latest commit
Rollback Strategy
Automatic Rollback (Health Check Failure)
Trigger: 3 consecutive failed health checks within 90 seconds
Action: Render keeps old container running, stops new deployment
Result: Service continues on previous version
Manual Rollback
Via Render Dashboard:

Go to: Services → audio-transcription-api → Deploys tab
Find previous successful deploy
Click "Redeploy" on that commit
Via Git Revert:


git revert HEAD  # Revert last commit
git push origin main
Creates a new commit that undoes changes
Triggers auto-deploy to previous state
Emergency Rollback (Database Schema Change):

Problem: New deploy included database migration that broke old code
Solution:
Suspend service in Render (stops accepting traffic)
Manually revert database migration (connect via psql $DATABASE_URL)
Redeploy previous commit
Resume service
Rollback Testing Checklist
 Health check still passes (curl https://yourapp.onrender.com/health)
 Authentication works (test /api/me with valid Auth0 token)
 Transcription works (test /transcriptions/deepgram with sample audio)
 WebSocket connects (test SocketIO handshake)
 Database queries succeed (check logs for SQLAlchemy errors)
Configuration Checklist (Pre-Deploy)
Environment Variables (Render Dashboard)
 AUTH0_DOMAIN = <your-tenant>.us.auth0.com
 AUTH0_AUDIENCE = https://api.<yourapp>.com
 DEEPGRAM_API_KEY = <deepgram_key>
 OPENAI_API_KEY = <openai_key>
 DATABASE_URL = Auto-injected OR manual with ?sslmode=require
 JWT_SECRET_KEY = Auto-generated on first deploy
 SECRET_KEY = Strong random value (not default placeholder)
 ALLOW_INSECURE_SESSION_AUTH = false (verify in render.yaml)
Optional Variables
 ASSEMBLYAI_API_KEY (if using AssemblyAI)
 GOOGLE_APPLICATION_CREDENTIALS (if using Google Translate)
Service Configuration (render.yaml)
 runtime: python (correct)
 plan: starter (or higher for production load)
 region: oregon (or closest to users)
 healthCheckPath: /health (set)
 autoDeploy: true (for CI/CD)
Database Setup
 PostgreSQL service created in Render (or external DB configured)
 DATABASE_URL injected (check Environment tab)
 SSL mode enabled (?sslmode=require if external)
External Services
 Auth0 application created, API identifier matches AUTH0_AUDIENCE
 Auth0 allowed callback URLs include frontend URL
 Deepgram API key active, quota available
 OpenAI API key active, billing enabled
Common Deployment Issues
Symptom	Likely Cause	Fix
Build fails: "No module named 'X'"	Missing dependency in requirements.txt	Add package, redeploy
Health check fails immediately	PORT env var not used	Ensure --bind 0.0.0.0:$PORT in startCommand
502 Bad Gateway after deploy	App crashed during startup	Check Render logs for Python traceback
WebSocket fails to connect	Wrong worker class (sync instead of eventlet)	Verify -k eventlet in startCommand
Database errors on first deploy	Tables not created	Check logs for db.create_all() errors
Auth0 endpoints return 500	Missing AUTH0_DOMAIN or AUTH0_AUDIENCE	Set env vars in dashboard
Transcription endpoints fail	Missing DEEPGRAM_API_KEY or OPENAI_API_KEY	Set API keys
CORS errors from frontend	Incorrect CORS_ORIGINS	Update to match frontend URL
"ALLOW_INSECURE_SESSION_AUTH" warning in logs	Security flag not set to false	Verify render.yaml, redeploy
Performance Tuning
Current Bottlenecks
Single worker: -w 1 limits concurrency (one request at a time blocks)
In-memory connection state: SocketIO active_connections dict not shared across workers
Synchronous external API calls: Deepgram, OpenAI calls block gunicorn worker
Scaling Recommendations
Horizontal Scaling (Multiple Instances):

Requires Redis for SocketIO message queue (redis://...)
Update flask_app/__init__.py: socketio = SocketIO(app, message_queue='redis://...')
Increase worker count: -w 4 (after Redis setup)
Vertical Scaling (Larger Instance):

Render plan: Starter → Standard (more CPU/RAM)
Helps with ML model loading (whisper, transformers)
Caching:

Enable Redis for PyJWKClient caching (Auth0 JWKS keys)
Cache frequent transcriptions (duplicate audio detection)
Async I/O:

Migrate blocking calls to async (aiohttp, asyncio)
Requires Flask async views (Flask 2.0+) or Sanic/FastAPI migration
Security Hardening for Production
Secrets Rotation:

Rotate JWT_SECRET_KEY every 90 days (invalidates all JWT tokens)
Rotate SECRET_KEY (invalidates Flask sessions)
Rotate API keys (Deepgram, OpenAI) annually
Database Security:

Use DATABASE_URL with SSL: ?sslmode=require
Limit database user permissions (no DROP, CREATE beyond initial setup)
Enable connection pooling (SQLAlchemy default: 5 connections)
CORS Tightening:

Change CORS_ORIGINS from * to specific frontend URLs
Remove localhost:3000 in production
Rate Limiting:

Implement Flask-Limiter (not currently used)
Example: 100 requests/minute per user
Monitoring:

Enable Render metrics (CPU, memory, request rate)
Set up alerts for health check failures
Monitor Auth0 dashboard for anomalous login patterns
Maintenance Procedures
Updating Dependencies

# Local testing
pip install <package>==<new_version>
pip freeze > requirements.txt
git add requirements.txt
git commit -m "chore: update dependencies"
git push origin main
Testing Checklist:

 Run tests locally: pytest
 Verify health check: /health
 Test auth: /api/me with Auth0 token
 Test transcription: /transcriptions/deepgram
 Monitor Render logs post-deploy (first 5 minutes)
Database Migrations
Current: db.create_all() (only adds new tables, doesn't alter existing)
Recommended: Implement Flask-Migrate (Alembic)
Manual Migration:

# Connect to production DB
psql $DATABASE_URL

# Run schema changes
ALTER TABLE users ADD COLUMN new_field VARCHAR(100);

# Verify in app logs
Log Rotation
Render automatically rotates logs (no action needed)
Download historical logs: Render Dashboard → Logs → Download (last 7 days)
Emergency Contacts & Resources
Resource	URL/Contact	Purpose
Render Dashboard	https://dashboard.render.com	Service management, logs, environment vars
Render Status	https://status.render.com	Platform outages
Auth0 Dashboard	https://manage.auth0.com	User management, application settings
Deepgram Status	https://status.deepgram.com	API outages
OpenAI Status	https://status.openai.com	API outages
PostgreSQL Connection	psql $DATABASE_URL	Direct database access
Application Logs	Render Dashboard → Logs	Real-time error monitoring
Post-Deploy Verification
Run these checks after every deploy:


# 1. Health check
curl https://yourapp.onrender.com/health
# Expected: {"status": "healthy", ...}

# 2. Root endpoint (API documentation)
curl https://yourapp.onrender.com/
# Expected: {"service": "Audio Transcription API", "endpoints": {...}}

# 3. Auth0 protected route (requires valid token)
curl -H "Authorization: Bearer <AUTH0_JWT>" \
  https://yourapp.onrender.com/api/me
# Expected: {"user": {...}, "user_id": "auth0|123"}

# 4. Transcription endpoint (requires API key)
curl -X POST -H "x-api-key: usr_123_xyz" \
  -F "audio=@test_audio.wav" \
  https://yourapp.onrender.com/transcriptions/deepgram
# Expected: {"transcript": "...", "processing_info": {...}}

# 5. WebSocket connection (requires SocketIO client)
# Test via frontend or wscat:
wscat -c "wss://yourapp.onrender.com/audio-stream?lang=en" \
  --header "Authorization: Bearer <AUTH0_JWT>"
# Expected: Connection established, receives {"message": "Successfully connected"}
Troubleshooting Guide
App Won't Start

Check Render logs for:
- "Missing required environment variables: X, Y"
  → Set missing env vars in dashboard
- "ImportError: No module named 'X'"
  → Add to requirements.txt, redeploy
- "sqlalchemy.exc.OperationalError: could not connect to server"
  → Check DATABASE_URL, PostgreSQL service status
WebSocket Connections Fail

Check:
- Client using wss:// (not ws://)
- Auth token provided in handshake: {token: '...'}
- Render logs for "Connection rejected: ..." messages
- ALLOW_INSECURE_SESSION_AUTH=false (if using Auth0 only)
High Memory Usage

Causes:
- ML models loaded (whisper, transformers) - each ~500MB
- Active WebSocket connections (~10MB each)
- Large file uploads buffered in memory

Solutions:
- Upgrade Render plan (more RAM)
- Limit max file size (currently 100MB for video)
- Restart service to clear memory leaks
Slow Response Times

Check:
- Render metrics (CPU usage, request queue)
- External API latency (Deepgram, OpenAI - check status pages)
- Database query performance (enable SQLAlchemy query logging)
- Single worker bottleneck (scale to Redis + multiple workers)

Update Todos

Explore codebase structure and key files

Generate docs/architecture.md

Generate docs/deployment_render.md

Generate docs/runbook.md

Generate docs/security-hardening-todo.md

Identify minimal missing information questions
3. docs/runbook.md

# Operational Runbook

## Overview

This runbook provides step-by-step debugging procedures for common failure scenarios in the Audio Transcription API. Use these playbooks when investigating production incidents.

---

## Table of Contents

1. [How to Debug a Failed Transcription](#1-how-to-debug-a-failed-transcription)
2. [How to Debug a Failed Translation](#2-how-to-debug-a-failed-translation)
3. [How to Debug WebSocket Audio Streaming](#3-how-to-debug-websocket-audio-streaming)
4. [Common Failure Modes](#4-common-failure-modes)

---

## 1. How to Debug a Failed Transcription

### Symptoms
- HTTP 400/500 response from `/transcriptions/deepgram`, `/transcriptions/whisper`, or `/transcriptions/assemblyai`
- Empty transcript returned
- Client timeout waiting for response
- Error: "TranscriptionError: ..."

### Investigation Steps

#### Step 1: Identify the Service Provider
Request endpoint determines provider:
• /transcriptions/deepgram → DeepgramService
• /transcriptions/whisper → WhisperService (OpenAI)
• /transcriptions/assemblyai → AssemblyAIService
• /transcriptions/video → VideoTranscriptionService (Whisper)



#### Step 2: Check Render Logs
```bash
# Access Render Dashboard → Logs tab
# Search for error patterns:

Pattern: "Deepgram transcription failed: ..."
Location: flask_app/services/transcription.py:DeepgramService.transcribe()

Pattern: "Whisper transcription failed: ..."
Location: flask_app/services/transcription.py:WhisperService.transcribe()

Pattern: "AssemblyAI transcription failed: ..."
Location: flask_app/services/transcription.py:AssemblyAIService.transcribe()
Step 3: Verify API Keys

# Check environment variables in Render Dashboard:
DEEPGRAM_API_KEY = *********** (set?)
OPENAI_API_KEY = *********** (set?)
ASSEMBLYAI_API_KEY = *********** (set?)

# Test key validity (local):
curl -H "Authorization: Token $DEEPGRAM_API_KEY" \
  https://api.deepgram.com/v1/listen \
  -X POST \
  -F "audio=@test.wav"

# Expected: Valid transcription OR specific error (invalid key, quota exceeded)
Step 4: Verify Audio File Format

# Common issues:
• File too large (Whisper max: 25MB per chunk, auto-chunking enabled)
• Unsupported format (accepts: wav, mp3, m4a, flac, ogg, webm)
• Corrupted file (ffmpeg fails to read)

# Test locally:
ffprobe test_audio.wav
# Check: codec, sample_rate, duration

# Whisper expects: 16kHz sample rate (auto-converted by service)
# Deepgram accepts: any sample rate
Step 5: Check Provider Service Status

Deepgram: https://status.deepgram.com
OpenAI: https://status.openai.com
AssemblyAI: https://status.assemblyai.com

If provider is down:
→ Retry with different provider (e.g., switch Deepgram → Whisper)
Step 6: Inspect Service-Specific Errors
Deepgram Errors

# File: flask_app/clients/deepgram.py
# Common errors:

1. "Invalid API key"
   → Check DEEPGRAM_API_KEY
   
2. "Unsupported language: xyz"
   → Verify language code in request (e.g., 'en', 'es', 'fr')
   → See supported languages in Deepgram docs
   
3. "Audio file too short" (< 0.5s)
   → Check audio file duration with ffprobe
   
4. "Rate limit exceeded"
   → Check Deepgram dashboard for quota
   → Implement retry with exponential backoff (to be added)
Whisper Errors

# File: flask_app/clients/openai.py
# Common errors:

1. "File size exceeds 25MB limit"
   → Should not occur (auto-chunking implemented)
   → Check logs for chunking errors
   
2. "Invalid audio format"
   → ffmpeg conversion failed
   → Check audio file codec: ffprobe test.wav
   
3. "OpenAI API error: 429 Too Many Requests"
   → Rate limit hit (60 RPM for Whisper API)
   → Retry after 60 seconds
   
4. "Insufficient quota"
   → Check OpenAI billing dashboard
   → Add credits or upgrade plan
AssemblyAI Errors

# File: flask_app/clients/assemblyai.py
# Common errors:

1. "Upload failed"
   → Network issue or AssemblyAI outage
   → Check status.assemblyai.com
   
2. "Transcription timeout"
   → Large file took > 10 minutes (to confirm timeout value)
   → Check AssemblyAI dashboard for job status
   
3. "Invalid API key"
   → Check ASSEMBLYAI_API_KEY
Step 7: Test End-to-End

# Minimal test case:
curl -X POST https://yourapp.onrender.com/transcriptions/deepgram \
  -H "x-api-key: YOUR_API_KEY" \
  -F "audio=@short_test.wav" \
  -F "language=en"

# Expected success response:
{
  "transcript": "Hello world",
  "processing_info": {
    "service": "deepgram",
    "model_used": "nova-2",
    "language_requested": "en",
    "diarization_enabled": false
  },
  "confidence": 0.95
}

# Expected error response:
{
  "error": "Deepgram transcription failed: [specific error]"
}
Resolution Patterns
Error	Root Cause	Fix
"Missing required environment variables: DEEPGRAM_API_KEY"	Config issue	Set env var in Render dashboard
"Failed to save audio file: [Errno 28] No space left on device"	Disk full	Restart service (clears /tmp), upgrade instance
"TranscriptionError: Connection timeout"	Provider API slow/down	Retry, check provider status page
Empty transcript returned	Silent audio file	Verify audio has speech content
"Invalid language code"	Client sent unsupported language	Return 400 with list of supported languages
2. How to Debug a Failed Translation
Symptoms
HTTP 400/500 response from /translations/openai, /translations/google, or /translations/deepseek
Empty translation returned
Error: "TranslationError: ..."
Investigation Steps
Step 1: Identify Translation Provider

Endpoint mapping:
• /translations/openai → OpenAITranslationService (GPT-4o-mini)
• /translations/google → GoogleTranslationService (Google Cloud Translate)
• /translations/deepseek → DeepSeekTranslationService (+ webhook integration)
Step 2: Check Render Logs

# Search patterns:

"OpenAI translation failed: ..."
Location: flask_app/services/translation.py:OpenAITranslationService.translate()

"Google translation failed: ..."
Location: flask_app/services/translation.py:GoogleTranslationService.translate()

"DeepSeek translation failed: ..."
Location: flask_app/services/translation.py:DeepSeekTranslationService.translate()
Step 3: Verify Configuration
OpenAI Translation

# Check:
OPENAI_API_KEY = *********** (set?)

# Test:
curl https://api.openai.com/v1/chat/completions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model": "gpt-4o-mini", "messages": [{"role": "user", "content": "Translate to Spanish: Hello"}]}'

# Expected: Valid translation OR error (invalid key, quota)
Google Translation

# Check:
GOOGLE_APPLICATION_CREDENTIALS = /path/to/service-account.json

# Test:
gcloud auth activate-service-account \
  --key-file=$GOOGLE_APPLICATION_CREDENTIALS
gcloud projects list

# Expected: Service account has access to projects

# Verify API enabled:
gcloud services list --enabled | grep translate
# Expected: translate.googleapis.com ENABLED
DeepSeek Translation

# Check:
# No API key env var (DeepSeek API key hardcoded in client? - to confirm)

# Test webhook integration:
curl -X POST https://hook.eu2.make.com/... \
  -d "translation=test&transcription=test&fileName=test.wav"

# Expected: 200 OK from Make.com webhook
Step 4: Check Request Payload

# Common issues:

1. Empty text:
   {"text": ""}
   → Returns 400: "Text cannot be empty"

2. Missing target_language:
   {"text": "Hello"}  # Missing target_language
   → Returns 400: "Missing required field: target_language"

3. Unsupported language pair (Google):
   {"text": "Hello", "target_language": "zzzz"}
   → Google API error: "Invalid language code"

4. Text too long (OpenAI):
   • Max tokens: ~8000 for GPT-4o-mini
   • Auto-chunking implemented (to confirm)
   • Check logs for "chunks_processed" count
Step 5: Test Provider-Specific Issues
OpenAI Translation Errors

# File: flask_app/clients/openai.py

1. "OpenAI API error: 429 Too Many Requests"
   → Rate limit: 10,000 TPM (tokens per minute)
   → Retry with exponential backoff
   
2. "Context length exceeded"
   → Text + translation prompt > 8K tokens
   → Check chunking logic in OpenAITranslationService
   
3. "Model overloaded"
   → OpenAI capacity issue
   → Retry or switch to Google Translate
Google Translation Errors

# File: flask_app/clients/google.py

1. "Service account not found"
   → GOOGLE_APPLICATION_CREDENTIALS path wrong
   → Verify file exists: ls -la $GOOGLE_APPLICATION_CREDENTIALS
   
2. "Permission denied"
   → Service account lacks Cloud Translation API permission
   → Add role: Cloud Translation API User
   
3. "Quota exceeded"
   → Monthly character limit hit
   → Check GCP billing dashboard
DeepSeek Translation Errors

# File: flask_app/clients/deepseek.py + services/translation.py

1. "Translation failed: [specific error]"
   → Check DeepSeek API status (to confirm status page URL)
   
2. "Failed to send request to external service"
   → Webhook (Make.com) unreachable
   → Check webhook URL in code (hardcoded?)
   → Verify Make.com scenario is active
   
3. "Webhook request failed: 500"
   → Make.com scenario error
   → Check Make.com logs for execution history
Step 6: Test End-to-End

# OpenAI translation:
curl -X POST https://yourapp.onrender.com/translations/openai \
  -H "x-api-key: YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"text": "Hello world", "source_language": "en", "target_language": "es"}'

# Expected:
{
  "translated_text": "Hola mundo",
  "source_language": "en",
  "target_language": "es"
}

# Google translation:
curl -X POST https://yourapp.onrender.com/translations/google \
  -H "x-api-key: YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"text": "Hello world", "target_language": "es"}'

# Expected:
{
  "translated_text": "Hola mundo",
  "detected_source_language": "en"
}
Resolution Patterns
Error	Root Cause	Fix
"Missing OPENAI_API_KEY"	Config missing	Set in Render dashboard
"Google Cloud credentials not found"	File path wrong	Upload service account JSON to /opt/render/project/src/google/
"Invalid target_language"	Client sent bad language code	Return 400 with supported language list
"Webhook request failed"	Make.com down or scenario disabled	Reactivate scenario, check Make.com status
Empty translation	Provider API issue	Retry with different provider
3. How to Debug WebSocket Audio Streaming
Symptoms
Client cannot connect to wss://.../audio-stream
Connection established but no transcription events received
Connection drops after few seconds
Error: "Connection rejected: ..."
Investigation Steps
Step 1: Verify WebSocket Handler

# Check Render logs for handler registration:

Pattern: "WebSocket handlers (Auth0-enabled) registered successfully"
→ Using audio_stream_auth0.py (PREFERRED)

Pattern: "WebSocket handlers (session-based) registered successfully"
→ Using audio_stream.py (DEPRECATED)

Pattern: "WebSocket handlers not found: ..."
→ No handler registered (critical failure)
Step 2: Test Connection Handshake

# Using wscat (install: npm install -g wscat):

# With Auth0 JWT:
wscat -c "wss://yourapp.onrender.com/audio-stream?lang=en" \
  -H "Authorization: Bearer <AUTH0_JWT_TOKEN>"

# Or via SocketIO handshake auth:
# (requires SocketIO client library - see client code)

# Expected on success:
Connected
< {"message": "Successfully connected to audio streaming service", "user_id": "auth0|123", "auth_type": "auth0", "language": "en", "timestamp": "..."}

# Expected on auth failure:
Connection rejected
< {"message": "Connection rejected: Invalid or expired authentication token", "timestamp": "..."}
Step 3: Check Authentication Issues
Auth0 JWT Validation

# Decode JWT to inspect claims (use jwt.io or):
echo "<JWT_TOKEN>" | cut -d'.' -f2 | base64 -d | jq .

# Verify:
• "iss": "https://<AUTH0_DOMAIN>/"  (matches AUTH0_DOMAIN env var)
• "aud": "<AUTH0_AUDIENCE>"  (matches AUTH0_AUDIENCE env var)
• "exp": <timestamp>  (not expired: exp > current Unix time)
• "sub": "auth0|123"  (user ID present)

# Common failures:
1. Token expired → Client needs to refresh token
2. Wrong audience → AUTH0_AUDIENCE mismatch
3. Invalid signature → JWKS key rotation issue (clear PyJWKClient cache - restart service)
Session Token Validation (Deprecated)

# Only works if ALLOW_INSECURE_SESSION_AUTH=true

# Check Render logs:
"⚠️ SECURITY WARNING: ALLOW_INSECURE_SESSION_AUTH is enabled"
→ Session fallback active (BAD in production)

"Session token fallback disabled (secure mode)"
→ Session tokens rejected (GOOD in production)

# Test session token:
# First login to get token:
curl -X POST https://yourapp.onrender.com/mobile-auth/login \
  -H "Content-Type: application/json" \
  -d '{"username": "testuser", "password": "ignored"}'  # NO PASSWORD CHECK!

# Response:
{"auth_token": "session_xyz123", "user_id": "testuser", "expires_at": "..."}

# Then use in WebSocket:
wscat -c "wss://yourapp.onrender.com/audio-stream?lang=en" \
  --connect-option '{"auth": {"token": "session_xyz123"}}'
Step 4: Check Deepgram Integration

# Render logs patterns:

Pattern: "Deepgram connection opened"
→ Deepgram live connection established

Pattern: "Deepgram error: ..."
→ Deepgram API issue (key invalid, quota exceeded, service down)

Pattern: "Failed to start Deepgram connection"
→ LiveOptions configuration error or API key missing

# Verify Deepgram API key:
curl -H "Authorization: Token $DEEPGRAM_API_KEY" \
  https://api.deepgram.com/v1/projects

# Expected: List of projects OR error (invalid key)
Step 5: Test Audio Streaming

// Client-side test (JavaScript):

const socket = io('wss://yourapp.onrender.com/audio-stream?lang=it', {
  auth: { token: '<AUTH0_JWT_TOKEN>' }
});

socket.on('connected', (data) => {
  console.log('Connected:', data);
  // Start sending audio chunks
});

socket.on('transcription', (data) => {
  console.log('Transcript:', data.transcript);
  console.log('Is final:', data.is_final);
  console.log('Confidence:', data.confidence);
});

socket.on('error', (data) => {
  console.error('Error:', data.message);
});

// Send audio chunk (Base64-encoded PCM 16kHz):
socket.emit('audio_chunk', {
  audio_chunk: '<base64_audio_data>',
  timestamp: new Date().toISOString()
});
Step 6: Verify Language Selection

# Language passed via query parameter:
wss://yourapp.onrender.com/audio-stream?lang=it  # Italian
wss://yourapp.onrender.com/audio-stream?lang=en  # English
wss://yourapp.onrender.com/audio-stream  # Default: en

# Check Render logs:
"Language set to 'it' for user auth0|123"
→ Correct language selected

"Invalid language 'xyz' requested by user ... Defaulting to 'en'"
→ Unsupported language code (check SUPPORTED_LANGUAGES list)

# Supported languages (30+):
en, es, fr, it, de, pt, nl, hi, ja, ko, zh, sv, no, da, fi, pl, ru, tr, ar, el, he, cs, uk, ro, hu, id, ms, th, vi
Step 7: Check Connection State Management

# Render logs patterns:

"WebSocket connected: user_id=X, auth_type=auth0"
→ Connection added to active_connections dict

"WebSocket disconnected: user_id=X"
→ Connection removed from active_connections

"Audio chunk received from unknown connection: ..."
→ Connection not in active_connections (client reconnect needed)

"Deepgram connection not open, cannot send audio"
→ is_deepgram_open=False (Deepgram failed to start or crashed)
Common WebSocket Errors
Error	Cause	Fix
"Connection rejected: No authentication token provided"	Client didn't send auth: {token}	Add auth parameter to SocketIO connection
"Connection rejected: Invalid or expired authentication token"	JWT expired or invalid	Client needs to refresh Auth0 token
"Transcription service error"	Deepgram API failure	Check DEEPGRAM_API_KEY, Deepgram status
"Invalid audio data format"	Base64 decode failed	Verify audio_chunk is valid Base64 string
"Connection not initialized"	Client sent audio before receiving 'connected' event	Wait for 'connected' before sending chunks
No transcription events received	Silent audio or wrong encoding	Verify: 16kHz sample rate, linear16 PCM encoding
Connection drops after 30s	Render timeout (to confirm)	Send periodic keepalive pings OR audio chunks
Resolution Patterns
Symptom	Root Cause	Fix
Cannot connect	Missing Auth0 token	Get token from Auth0 login flow
Connects but no transcripts	Wrong audio format	Ensure 16kHz, linear16, mono PCM
Transcripts in wrong language	Query param missing/wrong	Add ?lang=it to WebSocket URL
Random disconnects	Deepgram error	Check Deepgram API status, key quota
Memory leak (connections not cleaned up)	Disconnect handler not running	Check logs for disconnect events, restart service
4. Common Failure Modes
Database Connection Failures
Symptoms
500 errors on all authenticated endpoints
Logs: "sqlalchemy.exc.OperationalError: could not connect to server"
App starts but first API call fails
Investigation

# Check DATABASE_URL:
echo $DATABASE_URL  # In Render dashboard → Environment

# Test connection (from local or SSH):
psql "$DATABASE_URL"

# Common issues:
1. PostgreSQL service down → Check Render dashboard for DB status
2. Wrong connection string → Verify host, port, username, password
3. SSL required but not in URL → Add ?sslmode=require
4. Connection pool exhausted → Restart service, check for connection leaks
Resolution

# If database is down:
1. Check Render DB service status
2. Restart DB service if needed
3. Wait for DB health check to pass
4. Restart web service to reconnect

# If connection string wrong:
1. Render Dashboard → Database → Connection String
2. Copy correct DATABASE_URL
3. Update in Web Service → Environment
4. Trigger manual deploy (restart)
Auth0 Configuration Issues
Symptoms
401 errors on /api/me, /api/userinfo
Logs: "AUTH0_DOMAIN environment variable not set"
Logs: "Token verification failed"
Investigation

# Check env vars:
AUTH0_DOMAIN = *********** (set?)
AUTH0_AUDIENCE = *********** (set?)

# Verify Auth0 application settings:
1. Go to Auth0 Dashboard → Applications → Your App
2. Check:
   • Domain matches AUTH0_DOMAIN env var
   • Identifier (Audience) matches AUTH0_AUDIENCE
   • Signing Algorithm = RS256 (NOT HS256)
   • Token Endpoint Authentication Method = None (for SPAs) or Post (for web apps)

# Test JWKS endpoint:
curl https://<AUTH0_DOMAIN>/.well-known/jwks.json

# Expected: JSON with public keys
Resolution

# If env vars missing:
1. Render Dashboard → Environment → Add Variable
2. Set AUTH0_DOMAIN (without https://)
3. Set AUTH0_AUDIENCE (API identifier from Auth0)
4. Trigger manual deploy

# If JWT validation fails:
1. Verify algorithm is RS256 (not HS256)
2. Check token expiration (decode JWT at jwt.io)
3. Verify audience claim matches AUTH0_AUDIENCE
4. Clear PyJWKClient cache (restart service)
External API Failures
Symptoms
Specific service fails (Deepgram, OpenAI, Google) while others work
Logs: "Connection timeout", "429 Too Many Requests", "Service Unavailable"
Investigation

# Check service status pages:
Deepgram: https://status.deepgram.com
OpenAI: https://status.openai.com
Google Cloud: https://status.cloud.google.com

# Check API quotas:
Deepgram: Dashboard → Usage
OpenAI: Dashboard → Usage Limits
Google Cloud: Console → APIs & Services → Quotas

# Test API connectivity (from Render shell):
# Deepgram:
curl -H "Authorization: Token $DEEPGRAM_API_KEY" \
  https://api.deepgram.com/v1/projects

# OpenAI:
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"

# Google Translate:
curl -X POST https://translation.googleapis.com/language/translate/v2 \
  -H "Authorization: Bearer $(gcloud auth print-access-token)" \
  -d "q=hello&target=es"
Resolution

# If service is down:
→ Wait for recovery (check status page for ETA)
→ Switch to alternative provider (e.g., Deepgram → Whisper)

# If quota exceeded:
Deepgram: Upgrade plan or wait for monthly reset
OpenAI: Add credits or upgrade tier
Google Cloud: Request quota increase

# If API key invalid:
1. Regenerate key in provider dashboard
2. Update env var in Render
3. Trigger manual deploy
Configuration Drift
Symptoms
Works locally but fails in production
Works in staging but fails in production
Sudden failures after deploy with "no code changes"
Investigation

# Compare environment variables:
# Local (.env file):
cat .env

# Render production:
Render Dashboard → Environment → View All

# Check for:
• Missing env vars (present locally but not in Render)
• Different values (e.g., wrong API keys)
• Typos in variable names

# Compare dependency versions:
# Local:
pip freeze | grep Flask

# Render (check build logs):
Render Dashboard → Logs → Filter for "Collecting Flask..."
Resolution

# Sync env vars:
1. Create checklist from .env.example (if exists)
2. Verify each var in Render dashboard
3. Add missing vars
4. Trigger manual deploy

# Lock dependency versions:
# In requirements.txt, use exact versions:
Flask==3.1.0  # NOT Flask>=3.0
deepgram-sdk==3.10.0  # NOT deepgram-sdk
Memory/Resource Exhaustion
Symptoms
App crashes after running for hours/days
Logs: "MemoryError", "Out of memory"
Render kills process: "Process exited with code 137" (OOM killed)
Investigation

# Check Render metrics:
Dashboard → Metrics → Memory Usage

# Look for:
• Steadily increasing memory (memory leak)
• Sudden spikes during specific operations
• Correlation with active WebSocket connections

# Likely causes:
1. WebSocket connections not cleaned up (active_connections dict growing)
2. Temporary files not deleted (check /tmp)
3. ML models loaded multiple times (whisper, transformers)
4. Large file uploads buffered in memory
Resolution

# Short-term:
Restart service to clear memory

# Long-term:
1. Upgrade Render plan (more RAM)
2. Add connection cleanup logging:
   • Log active_connections.keys() on each connect/disconnect
   • Alert if > 100 connections
3. Implement connection timeouts (disconnect idle clients)
4. Add file size limits (reject uploads > 100MB)
5. Use streaming file uploads (not in-memory buffering)
CORS Errors
Symptoms
Frontend gets "CORS policy blocked" error
OPTIONS preflight request fails
Request succeeds in Postman/curl but fails in browser
Investigation

# Check CORS configuration:
# File: flask_app/__init__.py

CORS(app, origins=["http://localhost:3000", "http://127.0.0.1:3000"],
     supports_credentials=True)

# Verify frontend URL matches:
Frontend URL: https://meeting-streamer.vercel.app
CORS origins: Should include https://meeting-streamer.vercel.app

# Test OPTIONS request:
curl -X OPTIONS https://yourapp.onrender.com/transcriptions/deepgram \
  -H "Origin: https://meeting-streamer.vercel.app" \
  -H "Access-Control-Request-Method: POST" \
  -v

# Expected headers in response:
Access-Control-Allow-Origin: https://meeting-streamer.vercel.app
Access-Control-Allow-Methods: POST, OPTIONS
Access-Control-Allow-Headers: x-api-key, Content-Type
Resolution

# Update CORS origins:
# File: flask_app/__init__.py
CORS(app, origins=[
  "http://localhost:3000",  # Local dev
  "https://meeting-streamer.vercel.app",  # Production frontend
  "https://staging.vercel.app"  # Staging
], supports_credentials=True)

# Or use environment variable:
origins = os.getenv("CORS_ORIGINS", "*").split(",")
CORS(app, origins=origins, supports_credentials=True)

# Set in Render:
CORS_ORIGINS = https://meeting-streamer.vercel.app,http://localhost:3000

# Redeploy to apply changes
Emergency Procedures
Critical Incident Response
Severity 1: Complete Service Outage

1. Check Render status: https://status.render.com
2. Check health endpoint: curl https://yourapp.onrender.com/health
3. If health fails: Check Render logs for crash/panic
4. If Render issue: Monitor status page, no action needed
5. If app issue:
   a. Identify error in logs (last 50 lines before crash)
   b. Check recent deploys (within last 24h)
   c. Rollback to previous working version
   d. Notify team with incident details
Severity 2: Degraded Service (One Feature Down)

1. Identify failing feature (transcription, translation, WebSocket)
2. Check external service status (Deepgram, OpenAI, Auth0)
3. If external outage: Switch to alternative provider OR wait
4. If configuration issue: Fix env var, redeploy
5. Document workaround for users
Severity 3: Performance Degradation

1. Check Render metrics (CPU, memory, request queue)
2. Check database slow query log (if accessible)
3. Check external API latency (Deepgram status page)
4. If high load: Consider scaling plan or adding rate limiting
5. If database slow: Restart DB service, add indexes
On-Call Checklist

□ Access to Render dashboard (login credentials saved)
□ Access to Auth0 dashboard
□ Access to external service dashboards (Deepgram, OpenAI)
□ Rollback procedure tested
□ Recent backup of database available (automated by Render)
□ Emergency contact list updated (team members, providers)
□ Incident response runbook reviewed (this document)
Maintenance Tasks
Weekly
 Review Render logs for WARNING/ERROR patterns
 Check external service usage (Deepgram, OpenAI quotas)
 Verify database backups are running (Render automated backups)
Monthly
 Review and rotate API keys (if leaked)
 Update dependencies (security patches)
 Review Auth0 user logs for anomalies
 Database cleanup (old UsageLog entries if > 1M rows)
Quarterly
 Audit user permissions (active API keys)
 Review CORS origins (remove deprecated URLs)
 Performance testing (load test with JMeter/Locust)
 Disaster recovery drill (test database restore)

Update Todos

Explore codebase structure and key files

Generate docs/architecture.md

Generate docs/deployment_render.md

Generate docs/runbook.md

Generate docs/security-hardening-todo.md

Identify minimal missing information questions
4. docs/security-hardening-todo.md

# Security Hardening Action Plan

## Purpose

This document identifies **concrete security vulnerabilities** in the current codebase and provides **actionable remediation steps**. **NO CODE CHANGES** are included here - this is a prioritized backlog for future security hardening work.

---

## Critical Priority (Fix Within 7 Days)

### 1. JWT Expiration Policy Missing
**Risk Level:** CRITICAL  
**Location:** [flask_app/__init__.py:42](flask_app/__init__.py#L42)  
**Current State:**
```python
app.config['JWT_ACCESS_TOKEN_EXPIRES'] = False  # Tokens don't expire by default
Vulnerability:

JWT tokens issued via /auth/login NEVER expire
Stolen/leaked tokens remain valid indefinitely
No mechanism to revoke compromised tokens
Violates OWASP A07:2021 (Identification and Authentication Failures)
Impact:

If an attacker obtains a JWT token (e.g., via XSS, MITM, or client compromise), they have permanent API access as that user
No way to force re-authentication for compromised accounts
Compliance violations (PCI DSS, SOC 2 require token expiration)
Remediation Steps:

Change JWT_ACCESS_TOKEN_EXPIRES to timedelta(hours=1) for short-lived access tokens
Implement refresh token pattern:
Add JWT_REFRESH_TOKEN_EXPIRES = timedelta(days=30)
Create /auth/refresh endpoint to exchange refresh token for new access token
Store refresh tokens in database with revocation capability
Add token revocation table:
TokenBlacklist model with jti (JWT ID) and revoked_at timestamp
Check blacklist in @require_jwt decorator before accepting token
Add /auth/logout endpoint that blacklists the current token
Add admin endpoint /auth/revoke-user-tokens/{user_id} to revoke all tokens for a user
Testing:

Verify tokens expire after 1 hour (should get 401 "Token has expired")
Test refresh token flow (exchange old token for new)
Test logout (token should be rejected after logout)
2. Insecure Session Authentication System
Risk Level: CRITICAL

Location: flask_app/api/auth.py

Current State:

Endpoint /mobile-auth/login generates session tokens WITHOUT verifying passwords
Code comment: # ⚠️ SECURITY ISSUE: No password validation!
Only blocked when ALLOW_INSECURE_SESSION_AUTH=false (env var gate)
Vulnerability:


# From flask_app/api/auth.py:78-80
username = data.get('username')
# ⚠️ SECURITY ISSUE: No password validation!
# This allows ANYONE to create a session for ANY username
session_data = session_manager.create_session(username, expires_hours=24)
Impact:

COMPLETE AUTHENTICATION BYPASS when ALLOW_INSECURE_SESSION_AUTH=true
Attacker can impersonate any user by sending {"username": "victim@email.com"}
No audit trail of unauthorized access (just looks like normal login)
Mobile app using this endpoint has NO real authentication
Remediation Steps:

IMMEDIATE (Production): Verify ALLOW_INSECURE_SESSION_AUTH=false in Render dashboard
Short-term (This Sprint):
Migrate mobile app to Auth0 authentication
Remove endpoints: /mobile-auth/login, /mobile-auth/logout, /mobile-auth/verify
Delete file: flask_app/api/auth.py (mobile auth blueprint)
Remove session manager code: flask_app/services/session_manager.py
Remove WebSocket handler: flask_app/sockets/audio_stream.py (session-only version)
Testing:
Confirm mobile app can authenticate via Auth0
Verify WebSocket connections use Auth0 JWT tokens
Ensure /mobile-auth/* endpoints return 404 after removal
Workaround (If Mobile App Cannot Migrate Yet):

Keep endpoints but add real password verification:

# Lookup user in database
user = User.query.filter_by(email=username).first()
if not user or not user.check_password(password):
    return jsonify({'error': 'Invalid credentials'}), 401
Add rate limiting (5 failed attempts = 15 min lockout)
Log all failed login attempts to detect brute force
3. CORS Policy Too Permissive (WebSocket)
Risk Level: HIGH

Location: flask_app/init.py:59-62

Current State:


socketio = SocketIO(
    app,
    cors_allowed_origins="*",  # Allow all origins for WebSocket
    ...
)
Vulnerability:

WebSocket endpoint /audio-stream accepts connections from ANY origin
Enables Cross-Site WebSocket Hijacking (CSWSH)
Attacker can create malicious site that connects to victim's WebSocket and steals real-time transcriptions
Attack Scenario:

User authenticates to your app, gets Auth0 token (stored in localStorage)
User visits attacker's site: evil.com
Attacker's JavaScript reads token from localStorage (if same-domain cookie not used) OR tricks user into pasting token
Attacker connects to wss://yourapp.onrender.com/audio-stream with stolen token
Attacker receives victim's audio transcriptions in real-time
Impact:

Data exfiltration (transcriptions, user IDs)
Privacy violation (eavesdropping on audio streams)
Compliance violation (GDPR, HIPAA if handling sensitive data)
Remediation Steps:

Immediate Fix:

ALLOWED_ORIGINS = [
    "https://meeting-streamer.vercel.app",  # Production frontend
    "https://staging.vercel.app",           # Staging
    "http://localhost:3000",                # Local dev
    "http://127.0.0.1:3000"                 # Local dev
]
socketio = SocketIO(
    app,
    cors_allowed_origins=ALLOWED_ORIGINS,
    ...
)
Use Environment Variable:
Set SOCKETIO_ORIGINS env var in Render
Read in code: cors_allowed_origins=os.getenv("SOCKETIO_ORIGINS", "").split(",")
Add Origin Validation in WebSocket Handler:

# In handle_connect():
origin = request.headers.get('Origin')
if origin not in ALLOWED_ORIGINS:
    logger.warning(f"Rejected connection from unauthorized origin: {origin}")
    return False
Testing:
Verify connection works from allowed origins
Verify connection fails from http://localhost:8000 (not in whitelist)
Check Render logs for "Rejected connection from unauthorized origin" messages
4. Hardcoded Secrets in Configuration Defaults
Risk Level: HIGH

Location: flask_app/init.py:40-41

Current State:


app.config['JWT_SECRET_KEY'] = os.getenv('JWT_SECRET_KEY', 'your-jwt-secret-key-change-in-production')
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'your-secret-key-change-in-production')
Vulnerability:

If env vars not set, app uses publicly visible default secrets from GitHub repo
Attacker can forge JWT tokens using default secret
Attacker can decrypt Flask session cookies
Impact:

Complete authentication bypass (forge admin JWT tokens)
Session hijacking (decrypt and modify session cookies)
Persistence across restarts (default secrets don't change)
Remediation Steps:

Remove Defaults:

JWT_SECRET_KEY = os.getenv('JWT_SECRET_KEY')
SECRET_KEY = os.getenv('SECRET_KEY')

if not JWT_SECRET_KEY or not SECRET_KEY:
    raise RuntimeError("CRITICAL: JWT_SECRET_KEY and SECRET_KEY must be set in environment variables")

app.config['JWT_SECRET_KEY'] = JWT_SECRET_KEY
app.config['SECRET_KEY'] = SECRET_KEY
Production Verification:
Check Render dashboard: Both secrets should be set and non-default
JWT_SECRET_KEY should use generateValue: true (already in render.yaml)
SECRET_KEY should be manually set to random value: openssl rand -base64 32
Rotate Secrets:
Generate new SECRET_KEY: openssl rand -base64 32
Update in Render dashboard
Warning: This invalidates all existing sessions (users logged out)
Testing:
Start app locally without env vars → should crash with "CRITICAL: ..." error
Start with env vars → should boot normally
High Priority (Fix Within 30 Days)
5. Missing Rate Limiting
Risk Level: HIGH

Affected Endpoints: All public endpoints (especially /auth/login, /auth/register, transcription endpoints)

Current State: No rate limiting implemented

Vulnerability:

Brute force attacks on /auth/login (unlimited password attempts)
Credential stuffing (attacker tries stolen username/password pairs)
Denial of Service (flood API with requests)
Resource exhaustion (expensive transcription API calls)
Attack Scenarios:

Brute Force:

for password in passwords.txt; do
  curl -X POST /auth/login -d "{\"email\": \"admin@example.com\", \"password\": \"$password\"}"
done
API Abuse:

while true; do
  curl -X POST /transcriptions/deepgram -F "audio=@large.wav" -H "x-api-key: stolen_key"
done
Remediation Steps:

Add Flask-Limiter Dependency:

# In requirements.txt:
Flask-Limiter==3.5.0
Configure Global Limits:

from flask_limiter import Limiter
from flask_limiter.util import get_remote_address

limiter = Limiter(
    app=app,
    key_func=get_remote_address,  # Rate limit by IP
    default_limits=["1000 per day", "100 per hour"],
    storage_uri="memory://"  # Use Redis in production: "redis://..."
)
Add Endpoint-Specific Limits:

@bp.route('/login', methods=['POST'])
@limiter.limit("5 per minute")  # Max 5 login attempts per minute
def login():
    ...

@bp.route('/transcriptions/deepgram', methods=['POST'])
@limiter.limit("10 per minute")  # Max 10 transcriptions per minute
def deepgram_transcription():
    ...
Use Redis for Distributed Rate Limiting:
Add to Render: Redis service (or external Redis)
Update storage_uri="redis://<redis_url>"
Required for multi-worker setups
Testing:
Make 6 login requests in 1 minute → 6th should return 429 Too Many Requests
Check response headers: X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset
6. No Input Validation for File Uploads
Risk Level: HIGH

Location: All transcription endpoints accepting file uploads

Current Issues:

No MIME type validation (accepts any file with .wav extension)
File size limits only enforced in specific services (not globally)
Malicious filenames not sanitized (e.g., ../../etc/passwd.wav)
Vulnerability:

Path Traversal: Attacker uploads file named ../../../tmp/evil.py → overwrite system files
Resource Exhaustion: Upload 10GB file → fills disk, crashes service
Malware Upload: Upload executable disguised as .wav → execute on server (if video processing bug)
Remediation Steps:

Add File Validation Decorator:

def validate_audio_upload(max_size_mb=100, allowed_extensions={'.wav', '.mp3', '.m4a', '.flac', '.ogg'}):
    def decorator(f):
        @wraps(f)
        def wrapper(*args, **kwargs):
            if 'audio' not in request.files:
                return jsonify({'error': 'No audio file provided'}), 400
            
            file = request.files['audio']
            
            # Validate filename
            if not file.filename:
                return jsonify({'error': 'No filename provided'}), 400
            
            # Check extension
            ext = Path(file.filename).suffix.lower()
            if ext not in allowed_extensions:
                return jsonify({'error': f'Unsupported file type: {ext}'}), 400
            
            # Sanitize filename (prevent path traversal)
            secure_name = secure_filename(file.filename)
            if secure_name != file.filename:
                logger.warning(f"Rejected malicious filename: {file.filename}")
                return jsonify({'error': 'Invalid filename'}), 400
            
            # Check file size
            file.seek(0, os.SEEK_END)
            size_bytes = file.tell()
            file.seek(0)  # Reset file pointer
            
            if size_bytes > max_size_mb * 1024 * 1024:
                return jsonify({'error': f'File too large (max {max_size_mb}MB)'}), 413
            
            return f(*args, **kwargs)
        return wrapper
    return decorator

# Usage:
@bp.route('/transcriptions/deepgram', methods=['POST'])
@validate_audio_upload(max_size_mb=100)
def deepgram_transcription():
    ...
Add MIME Type Validation:

import magic  # pip install python-magic

# Check actual file type (not just extension)
file_type = magic.from_buffer(file.read(2048), mime=True)
file.seek(0)

allowed_mimes = {'audio/wav', 'audio/mpeg', 'audio/mp4', 'audio/flac', 'audio/ogg'}
if file_type not in allowed_mimes:
    return jsonify({'error': f'Invalid file type: {file_type}'}), 400
Global File Size Limit (Nginx/Gunicorn):
Gunicorn: Add --limit-request-line 8190 --limit-request-fields 100
Nginx (if using reverse proxy): client_max_body_size 100M;
Testing:
Upload file named ../../etc/passwd.wav → should be rejected
Upload 101MB file → should return 413 File too large
Upload .exe file renamed to .wav → should be rejected (MIME check)
7. Error Messages Leak Implementation Details
Risk Level: MEDIUM

Location: Multiple error handlers (global + blueprint-specific)

Current State:


except Exception as e:
    logger.error(f"Unexpected error in Deepgram transcription: {e}")
    return jsonify({'error': 'Internal server error'}), 500
Vulnerability:

Error messages in logs include full stack traces (good for debugging, bad if logs leaked)
Some endpoints return raw exception messages to client (e.g., database errors)
Exposes technology stack, file paths, SQL queries to attackers
Examples:


# Bad - Leaks file path:
{"error": "File not found: /opt/render/project/src/temp/audio_12345.wav"}

# Bad - Leaks database schema:
{"error": "column users.secret_field does not exist"}

# Good - Generic message:
{"error": "Failed to process audio file"}
Remediation Steps:

Create Error Message Sanitizer:

def sanitize_error_for_client(error: Exception, debug=False):
    """Return safe error message for client."""
    if debug:
        return str(error)  # Full details in dev
    
    # Production: generic messages
    error_map = {
        'FileNotFoundError': 'File not found',
        'PermissionError': 'Access denied',
        'SQLAlchemyError': 'Database error',
        'TranscriptionError': 'Transcription failed',
        'TranslationError': 'Translation failed',
    }
    
    error_type = type(error).__name__
    return error_map.get(error_type, 'Internal server error')
Update Error Handlers:

@bp.errorhandler(Exception)
def handle_generic_error(error):
    # Log full details (for debugging)
    logger.error(f"Error in {request.path}: {error}", exc_info=True)
    
    # Return sanitized message to client
    safe_message = sanitize_error_for_client(error, debug=app.debug)
    return jsonify({'error': safe_message}), 500
Audit Existing Error Returns:
Search codebase for: return jsonify({'error': str(e)})
Replace with sanitized messages
Testing:
Trigger error in production mode → response should be generic
Trigger same error in dev mode (FLASK_ENV=development) → response should include details
Check logs → should have full stack trace even in production
8. Database Connection String in Logs
Risk Level: MEDIUM

Location: Application startup logs, SQLAlchemy debug mode

Current State:

If DATABASE_URL misconfigured, error logs may print full connection string (including password)
Example: sqlalchemy.exc.OperationalError: could not connect to server at postgresql://user:PASSWORD@host:5432/db
Vulnerability:

Database credentials leaked in logs
If logs exported to third-party service (Datadog, Splunk), credentials exposed
Render logs accessible to all team members (credential sprawl)
Remediation Steps:

Add Log Sanitizer:

import re
import logging

class SensitiveDataFilter(logging.Filter):
    """Remove sensitive data from log messages."""
    
    PATTERNS = [
        (re.compile(r'postgresql://[^:]+:([^@]+)@'), r'postgresql://***:REDACTED@'),
        (re.compile(r'api[_-]?key["\']?\s*[:=]\s*["\']?([a-zA-Z0-9_-]+)'), r'api_key=REDACTED'),
        (re.compile(r'Bearer ([a-zA-Z0-9_\-\.]+)'), r'Bearer REDACTED'),
        (re.compile(r'token["\']?\s*[:=]\s*["\']?([a-zA-Z0-9_-]+)'), r'token=REDACTED'),
    ]
    
    def filter(self, record):
        message = record.getMessage()
        for pattern, replacement in self.PATTERNS:
            message = pattern.sub(replacement, message)
        record.msg = message
        return True

# Apply to all loggers:
logging.basicConfig(level=logging.INFO)
for handler in logging.root.handlers:
    handler.addFilter(SensitiveDataFilter())
Disable SQLAlchemy Echo in Production:

# In flask_app/__init__.py:
app.config['SQLALCHEMY_ECHO'] = app.debug  # Only echo SQL in dev mode
Testing:
Trigger database connection error → check logs for password redaction
Enable debug mode → verify SQL queries logged
Production mode → verify no SQL queries in logs
Medium Priority (Fix Within 60 Days)
9. No API Key Rotation Policy
Risk Level: MEDIUM

Current State:

User API keys never expire (expires_at is nullable and usually NULL)
No mechanism to force rotation
Leaked keys remain valid indefinitely
Remediation Steps:

Add expires_at default (1 year from creation):

# In models/user.py:ApiKey
expires_at = db.Column(db.DateTime, default=lambda: datetime.utcnow() + timedelta(days=365))
Check expiration in verify_key():

if api_key.expires_at and api_key.expires_at < datetime.utcnow():
    logger.warning(f"Expired API key used: {api_key.id}")
    return None
Add endpoint /auth/api-keys/{id}/renew to extend expiration
Email users 30 days before key expiration
Create admin dashboard to audit key ages
10. Missing HTTPS Enforcement
Risk Level: MEDIUM (if Render doesn't enforce)

Current State:

No explicit HTTPS redirect in app code
Relies on Render platform to enforce HTTPS
Remediation Steps:

Add Flask-Talisman for security headers:

from flask_talisman import Talisman

Talisman(app,
         force_https=True,
         strict_transport_security=True,
         content_security_policy=None)  # Configure CSP separately
Add security headers:

@app.after_request
def set_security_headers(response):
    response.headers['X-Content-Type-Options'] = 'nosniff'
    response.headers['X-Frame-Options'] = 'DENY'
    response.headers['X-XSS-Protection'] = '1; mode=block'
    response.headers['Referrer-Policy'] = 'strict-origin-when-cross-origin'
    return response
Verify in Render: Auto-HTTPS enabled (should be default)
11. SQL Injection Risk (Low but Present)
Risk Level: MEDIUM

Current State:

Using SQLAlchemy ORM (prevents most SQL injection)
No raw SQL queries found in codebase (good)
But: If future developer adds raw queries, risk increases
Preventive Actions:

Add linting rule to detect raw SQL:

# In .pylintrc or bandit config:
[bandit]
exclude = tests/*
tests = B608  # Flag db.execute() with string interpolation
Document safe query patterns:

# SAFE - Parameterized query:
db.session.execute("SELECT * FROM users WHERE id = :id", {"id": user_id})

# UNSAFE - String interpolation:
db.session.execute(f"SELECT * FROM users WHERE id = {user_id}")  # NEVER DO THIS
Add code review checklist item: "No raw SQL with user input"
12. Deepgram API Key in WebSocket Logs
Risk Level: LOW (but fix for hygiene)

Location: utils/config.py - API keys may appear in logs during config loading

Current State:

If config load fails, error message may include DEEPGRAM_API_KEY=sk_...
Remediation:

Apply SensitiveDataFilter (from item #8) to all loggers
Mask API keys in config repr: DeepgramSettings(api_key='sk_***...')
Low Priority (Fix When Convenient)
13. No Content Security Policy (CSP)
Risk Level: LOW (API-only, no HTML served)

Recommendation: Add CSP header if serving any HTML (e.g., Swagger docs):


response.headers['Content-Security-Policy'] = "default-src 'none'"
14. Database Credentials Shared Across Environments
Risk Level: LOW (organizational risk)

Recommendation:

Use separate PostgreSQL databases for dev/staging/prod
Never use production DATABASE_URL locally
Rotate production DB password quarterly
15. No API Request Signing
Risk Level: LOW (nice-to-have for high-security scenarios)

Recommendation:

Implement HMAC request signing for API keys (like AWS Signature V4)
Prevents replay attacks and man-in-the-middle tampering
Example: X-Signature: HMAC-SHA256(API_SECRET, request_body + timestamp)
Security Audit Checklist
After implementing fixes, verify:

 JWT tokens expire (check exp claim in decoded token)
 Session auth endpoints removed OR properly secured with password verification
 CORS origins whitelist enforced (test from disallowed origin → connection rejected)
 Rate limiting active (make 100 requests in 1 minute → some return 429)
 File upload validation (upload malicious filename → rejected)
 Error messages sanitized (trigger error in production → no stack traces in response)
 API keys expire after 1 year (check expires_at in database)
 HTTPS enforced (access via http:// → redirects to https://)
 Security headers present (curl -I https://yourapp.onrender.com | grep X-Frame-Options)
 Secrets not in default config (start app without env vars → crash with error)
 Logs sanitized (trigger DB error → check logs for password redaction)
Compliance Mapping
Requirement	OWASP Top 10	Action Items	Status
Token expiration	A07:2021 Auth Failures	#1 (JWT expiry)	Not Fixed
Authentication bypass	A07:2021 Auth Failures	#2 (Session auth)	Not Fixed
CORS policy	A05:2021 Security Misconfig	#3 (WebSocket CORS)	Not Fixed
Secret management	A02:2021 Cryptographic Failures	#4 (Hardcoded secrets)	Not Fixed
Rate limiting	A05:2021 Security Misconfig	#5 (DoS protection)	Not Fixed
File upload validation	A03:2021 Injection	#6 (Path traversal)	Not Fixed
Information disclosure	A05:2021 Security Misconfig	#7 (Error messages)	Not Fixed
Credential logging	A09:2021 Logging Failures	#8 (Log sanitization)	Not Fixed
Next Steps
Prioritize fixes based on risk level and effort
Create GitHub issues for each action item (link to this doc)
Assign ownership for each fix
Set deadlines based on priority tiers
Schedule security review after all critical items fixed
Pen test after all high priority items fixed
Update this doc as fixes are deployed (mark "Status: Fixed")

Update Todos

Explore codebase structure and key files

Generate docs/architecture.md

Generate docs/deployment_render.md

Generate docs/runbook.md

Generate docs/security-hardening-todo.md

Identify minimal missing information questions
Perfect! I've generated all four documentation files. Now let me identify the minimal missing information to ask you.

Missing Information Questions (Max 5)
Based on my documentation generation, here are the ONLY questions needed to ensure accuracy:

1. Session Manager Implementation
Question: Does flask_app/services/session_manager.py exist and implement the session token storage (in-memory dict, database, or Redis)?

Why it matters: Affects the deprecation timeline for session auth and whether there's cleanup code to remove.

Label in docs: Currently marked "to confirm"

2. Database Migration Strategy
Question: Do you have scripts/init_db.py for manual database initialization, or rely solely on db.create_all() in flask_app/__init__.py?

Why it matters: Determines if there's a migration script to document in the runbook vs. auto-migrations.

Label in docs: Currently marked "to confirm"

3. DeepSeek API Key Location
Question: Is the DeepSeek API key hardcoded in flask_app/clients/deepseek.py or loaded from an environment variable? If env var, what's the name?

Why it matters: Security documentation needs to know if this is a leaked secret or properly externalized.

Label in docs: Currently marked "to confirm in clients/deepseek.py"

4. Render Log Retention
Question: What is the actual log retention period on Render for the Starter plan (7 days, 30 days, other)?

Why it matters: Operational runbook advises when to export logs before they're auto-deleted.

Label in docs: Currently listed as "Last 7 days (Starter plan - to confirm)"

5. OpenAI Translation Chunking
Question: Is automatic chunking implemented in OpenAITranslationService.translate() for texts exceeding token limits, similar to WhisperService?

Why it matters: Runbook debugging steps differ if large texts fail vs. auto-chunk.

Label in docs: Currently marked "Auto-chunking implemented (to confirm)"

Documentation Complete!
All four documents are ready to paste into your ./docs directory:

✅ docs/architecture.md - High-level architecture, module boundaries, request flows, configuration
✅ docs/deployment_render.md - Render deployment guide, environment variables, rollback procedures
✅ docs/runbook.md - Debugging runbooks for transcription, translation, WebSocket, common failures
✅ docs/security-hardening-todo.md - Prioritized security issues with concrete remediation steps
No code was changed as requested. All documentation is based on "what exists" in the current codebase.

Would you like me to:

Answer the 5 questions above based on further code exploration?
Create the actual files in ./docs (you mentioned not to write unless explicitly asked)?
Refine any specific section of the documentation?